[2024-09-19 14:08:34,593][test.py][line:34][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped_Short/0/', batch_size=128, model_path='/data/ylh/MyExps/MOFV2/checkpoints/AtLV3/AtLV3_epoch_38.pth', device='2', mode='test', top_k=5, parallel_model=False, test_name='AtLV3', num_workers=20, log_name='log/test/test_AtLV3_2024_09_19_14:08:26.log')
[2024-09-19 14:08:34,595][test.py][line:35][INFO] ---------------model---------------
AtLV3(
  (embed): Embedding(851, 63)
  (att): TransformerEncoder(
    (positionEnbeding): PositionEmbedding()
    (encoder_layers): ModuleList(
      (0-15): 16 x EncoderLayer(
        (mha): MultiHeadAttention(
          (WQ): Linear(in_features=64, out_features=64, bias=True)
          (WK): Linear(in_features=64, out_features=64, bias=True)
          (WV): Linear(in_features=64, out_features=64, bias=True)
          (scaled_dot_product_attn): ScaledDotProductAttention()
          (linear): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0, inplace=False)
        (layernorm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (ffn): FeedForwardNetwork(
          (linear1): Linear(in_features=64, out_features=512, bias=True)
          (linear2): Linear(in_features=512, out_features=64, bias=True)
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (dropout2): Dropout(p=0, inplace=False)
        (layernorm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=64, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=230, bias=True)
  )
)
[2024-09-19 14:08:34,595][test.py][line:36][INFO] ---------------device---------------
cuda:2
[2024-09-19 14:08:34,595][test.py][line:37][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-09-19 14:11:38,412][test.py][line:78][INFO] ---------------performance---------------
total_num:142729
error:2.580346
total_acc:0.340715616941452
f1_score:0.1716611683368683
top5_acc:0.7242816686630249
head_acc:0.381635633525331
medium_acc:0.19159739589215133
tail_add:0.14988790809067465

[2024-09-19 14:11:38,413][test.py][line:89][INFO] ---------------per_class_acc---------------
[0.34789547, 0.5239559, 0.0, 0.42787734, 0.30375805, 0.055555556, 0.051787917, 0.022727273, 0.2861205, 0.032786883, 0.19224212, 0.20353982, 0.07740289, 0.436028, 0.36441758, 0.65217394, 0.0, 0.18621974, 0.6191293, 0.08971553, 0.0, 0.0, 0.17322835, 0.0, 0.0, 0.02631579, 0.05882353, 0.0, 0.13080476, 0.028169014, 0.0942029, 0.0, 0.2537495, 0.058064517, 0.0, 0.14409222, 0.016949153, 0.09090909, 0.0, 0.08163265, 0.0, 0.10526316, 0.11141754, 0.10810811, 0.041533545, 0.06944445, 0.26666668, 0.0, 0.0, 0.14814815, 0.0, 0.10829103, 0.07042254, 0.0078125, 0.0066225166, 0.108523026, 0.014084507, 0.08757062, 0.015037594, 0.26405868, 0.55246913, 0.48865384, 0.14968815, 0.0, 0.22330096, 0.0, 0.0, 0.0, 0.20634921, 0.21768707, 0.083333336, 0.17209302, 0.012738854, 0.26573426, 0.0, 0.08262712, 0.016129032, 0.1496437, 0.03731343, 0.10236221, 0.04310345, 0.25212464, 0.0, 0.0, 0.13363029, 0.14264265, 0.2465374, 0.37389034, 0.0, 0.13461539, 0.022222223, 0.16462168, 0.0, 0.10377359, 0.021276595, 0.094827585, 0.041666668, 0.39215687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016393442, 1.0, 0.0, 0.0, 0.05263158, 0.08695652, 0.061032865, 0.0, 0.0, 0.18705036, 0.0752, 0.0, 0.0952381, 0.060606062, 0.07446808, 0.0, 0.0, 0.09195402, 0.12753624, 0.41025642, 0.44680852, 0.33333334, 0.071428575, 0.0, 0.16483517, 0.23595506, 0.24796748, 0.2, 0.0, 0.0, 0.071428575, 0.0, 0.097826086, 0.03508772, 0.08219178, 0.19130434, 0.2361111, 0.14285715, 0.1978022, 0.15789473, 0.12113402, 0.29533678, 0.33659217, 0.3517018, 0.56763446, 0.33333334, 0.018518519, 0.0, 0.14492753, 0.0, 0.054973822, 0.15261044, 0.0, 0.0, 0.09615385, 0.05945946, 0.203125, 0.15310077, 0.0, 0.3127572, 0.2857143, 0.23636363, 0.4025559, 0.21710527, 0.0, 0.118309855, 0.25072047, 0.0, 0.0, 0.112021856, 0.0, 0.16666667, 0.16834171, 0.33333334, 0.20408164, 0.032, 0.025, 0.0, 0.28865978, 0.0, 0.0, 0.0, 0.041666668, 0.13636364, 0.0, 0.045454547, 0.06818182, 0.21212122, 0.5423729, 0.02631579, 0.22651933, 0.0, 0.41379312, 0.23809524, 0.6061644, 0.5970149, 0.0, 0.12, 0.041666668, 0.3272727, 0.421875, 0.82051283, 0.112676054, 0.0, 0.0, 0.2857143, 0.61290324, 0.55172414, 0.0, 0.42424244, 0.071428575, 0.0, 0.09090909, 0.63190186, 0.47887325, 0.14583333, 0.5068493, 0.6692913, 0.3974359, 0.18421052, 0.375, 0.63529414, 0.2857143, 0.53409094, 0.41666666, 0.13636364, 0.13559322]
