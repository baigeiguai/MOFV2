[2024-10-23 21:27:18,484][train_con.py][line:89][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0', train_name='HopeV1_SupConLoss', model_path=None, learning_rate=0.0005, min_learning_rate=1e-06, start_scheduler_step=10, weight_decay=1e-05, momentum=0.99, batch_size=128, class_num=230, epoch_num=120, model_save_path='/data/ylh/MyExps/MOFV2/checkpoints/HopeV1_SupConLoss', device='2', scheduler_T=None, num_workers=20, log_name='log/train//train_HopeV1_SupConLoss_2024_10_23_21:27:11.log')
[2024-10-23 21:27:18,486][train_con.py][line:90][INFO] ---------------model---------------
HopeV1_Con(
  (conv_module): ResTcn(
    (intensity_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (TCN): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(2, 32, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (2): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (10): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (12): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (14): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (16): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (18): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (20): Dropout(p=0.25, inplace=False)
      (21): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (22): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (23): Dropout(p=0.25, inplace=False)
      (24): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (25): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (26): Dropout(p=0.25, inplace=False)
      (27): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (28): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (29): Flatten(start_dim=1, end_dim=-1)
    )
  )
  (att): AttentionModule(
    (embed): Embedding(850, 15)
    (patch_conv): PatchConvModule(
      (conv): Sequential(
        (0): Conv2d(1, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (1): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
        (2): Conv2d(2, 4, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (3): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
        (4): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (5): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
        (6): Conv2d(8, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
      )
    )
    (att): TransformerEncoder(
      (positionEnbeding): PositionEmbedding()
      (encoder_layers): ModuleList(
        (0-7): 8 x EncoderLayer(
          (mha): MultiHeadAttention(
            (WQ): Linear(in_features=32, out_features=32, bias=True)
            (WK): Linear(in_features=32, out_features=32, bias=True)
            (WV): Linear(in_features=32, out_features=32, bias=True)
            (scaled_dot_product_attn): ScaledDotProductAttention()
            (linear): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout1): Dropout(p=0.25, inplace=False)
          (layernorm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (ffn): FeedForwardNetwork(
            (linear1): Linear(in_features=32, out_features=256, bias=True)
            (linear2): Linear(in_features=256, out_features=32, bias=True)
            (relu): LeakyReLU(negative_slope=0.01)
          )
          (dropout2): Dropout(p=0.25, inplace=False)
          (layernorm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
  )
  (cls_sp): Sequential(
    (0): Linear(in_features=1056, out_features=230, bias=True)
  )
  (cls_cs): Sequential(
    (0): Linear(in_features=1056, out_features=7, bias=True)
  )
  (cls_lt): Sequential(
    (0): Linear(in_features=1056, out_features=6, bias=True)
  )
)
[2024-10-23 21:27:18,487][train_con.py][line:91][INFO] ---------------device---------------
cuda:2
[2024-10-23 21:27:18,487][train_con.py][line:92][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 1e-05
)
[2024-10-23 21:27:18,487][train_con.py][line:93][INFO] ---------------lossfn---------------
SupConLoss()
[2024-10-23 21:27:18,487][train_con.py][line:94][INFO] ---------------seed---------------
3407
[2024-10-23 21:27:18,490][train_con.py][line:106][INFO] ---------------epoch 1---------------
lr: [0.0005]
[2024-10-23 21:49:45,553][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.004415031273154329,error_sp: 0.3852222285216084,error_cs: 0.45862102930325793,error_lt: 0.48066609734280935
[2024-10-23 21:56:58,949][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.38784861939148557
[2024-10-23 21:56:59,906][train_con.py][line:106][INFO] ---------------epoch 2---------------
lr: [0.0005]
[2024-10-23 22:19:26,012][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0043087435847837495,error_sp: 0.3700487387846716,error_cs: 0.44075039694186535,error_lt: 0.4818239105334828
[2024-10-23 22:26:40,330][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.37355232587499015
[2024-10-23 22:26:40,741][train_con.py][line:106][INFO] ---------------epoch 3---------------
lr: [0.0005]
[2024-10-23 22:50:49,759][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.004265410999045232,error_sp: 0.36227146975411817,error_cs: 0.43458232191038426,error_lt: 0.48276948107748613
[2024-10-23 22:58:11,022][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3606401533549511
[2024-10-23 22:58:11,420][train_con.py][line:106][INFO] ---------------epoch 4---------------
lr: [0.0005]
[2024-10-23 23:20:39,132][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.004222145802180259,error_sp: 0.35363128589600085,error_cs: 0.4300968874553293,error_lt: 0.48291553366522716
[2024-10-23 23:28:15,140][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.35516867152982934
[2024-10-23 23:28:15,541][train_con.py][line:106][INFO] ---------------epoch 5---------------
lr: [0.0005]
[2024-10-23 23:50:42,551][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.004186532950192399,error_sp: 0.3470113113268007,error_cs: 0.42673141512600005,error_lt: 0.48221712767707636
[2024-10-23 23:57:59,776][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3780600828149198
[2024-10-23 23:57:59,784][train_con.py][line:106][INFO] ---------------epoch 6---------------
lr: [0.0005]
[2024-10-24 00:20:37,544][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.004152657473753202,error_sp: 0.3410961870087547,error_cs: 0.4237142101313651,error_lt: 0.48098681475752314
[2024-10-24 00:28:00,873][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.354217554501257
[2024-10-24 00:28:01,263][train_con.py][line:106][INFO] ---------------epoch 7---------------
lr: [0.0005]
[2024-10-24 00:50:26,749][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.004125947745565652,error_sp: 0.33685714795940885,error_cs: 0.4212280721556537,error_lt: 0.47969907286850455
[2024-10-24 00:57:44,293][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.35219978868710117
[2024-10-24 00:57:44,671][train_con.py][line:106][INFO] ---------------epoch 8---------------
lr: [0.0005]
[2024-10-24 01:20:10,523][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.004091459309608703,error_sp: 0.33150406681602784,error_cs: 0.4182123498728345,error_lt: 0.47772135049395575
[2024-10-24 01:27:26,264][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3808605794223834
[2024-10-24 01:27:26,272][train_con.py][line:106][INFO] ---------------epoch 9---------------
lr: [0.0005]
[2024-10-24 01:49:51,719][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.004055973327699669,error_sp: 0.32605037879208704,error_cs: 0.4149512043280631,error_lt: 0.4757903880161211
[2024-10-24 01:57:08,622][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.40147649197977203
[2024-10-24 01:57:08,630][train_con.py][line:106][INFO] ---------------epoch 10---------------
lr: [0.0005]
[2024-10-24 02:19:33,291][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.004025378999855624,error_sp: 0.32063144105945207,error_cs: 0.4127457924352458,error_lt: 0.4742364367104888
[2024-10-24 02:26:47,756][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3476350219604603
[2024-10-24 02:26:48,133][train_con.py][line:106][INFO] ---------------epoch 11---------------
lr: [0.0005]
[2024-10-24 02:49:29,732][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0039912499783861435,error_sp: 0.3144067350242819,error_cs: 0.41079998842730603,error_lt: 0.47216824198202845
[2024-10-24 02:56:52,605][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3042072941678863
[2024-10-24 02:56:53,268][train_con.py][line:106][INFO] ---------------epoch 12---------------
lr: [0.0004997965249680259]
[2024-10-24 03:19:19,130][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003960737132693756,error_sp: 0.30855870642224137,error_cs: 0.4092155976986187,error_lt: 0.4704468073629127
[2024-10-24 03:26:36,665][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3234659820504176
[2024-10-24 03:26:36,675][train_con.py][line:106][INFO] ---------------epoch 13---------------
lr: [0.0004992881174058898]
[2024-10-24 03:49:02,648][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0039346378764340915,error_sp: 0.30378806765729227,error_cs: 0.40761855670384,error_lt: 0.4689847106624728
[2024-10-24 03:56:20,249][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3315279766381739
[2024-10-24 03:56:20,258][train_con.py][line:106][INFO] ---------------epoch 14---------------
lr: [0.0004985769605169176]
[2024-10-24 04:18:45,064][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003907915571673104,error_sp: 0.2993404621980628,error_cs: 0.4057459622198433,error_lt: 0.46728822175072904
[2024-10-24 04:26:01,751][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3326998773793679
[2024-10-24 04:26:01,759][train_con.py][line:106][INFO] ---------------epoch 15---------------
lr: [0.0004976636342292746]
[2024-10-24 04:48:28,317][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.00388681043706712,error_sp: 0.29560908070949715,error_cs: 0.4042708841222731,error_lt: 0.46616313820035454
[2024-10-24 04:55:43,585][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3806841309515374
[2024-10-24 04:55:43,592][train_con.py][line:106][INFO] ---------------epoch 16---------------
lr: [0.0004965488833632431]
[2024-10-24 05:18:09,005][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003864958188488266,error_sp: 0.29182063986835693,error_cs: 0.40294911915365317,error_lt: 0.4647176709710335
[2024-10-24 05:25:27,488][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.2912860696915514
[2024-10-24 05:25:27,863][train_con.py][line:106][INFO] ---------------epoch 17---------------
lr: [0.0004952336170236509]
[2024-10-24 05:47:53,818][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003840927829070987,error_sp: 0.2879014411608969,error_cs: 0.4011020498299028,error_lt: 0.4632748299689026
[2024-10-24 05:55:08,710][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.35515476334526036
[2024-10-24 05:55:08,717][train_con.py][line:106][INFO] ---------------epoch 18---------------
lr: [0.0004937189078583101]
[2024-10-24 06:17:33,936][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0038231739030817084,error_sp: 0.28499380664068613,error_cs: 0.39977885379448547,error_lt: 0.46217948359626526
[2024-10-24 06:24:51,287][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3168043417702392
[2024-10-24 06:24:51,293][train_con.py][line:106][INFO] ---------------epoch 19---------------
lr: [0.0004920059911830646]
[2024-10-24 06:47:17,335][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0038051106641647514,error_sp: 0.28160452485223364,error_cs: 0.39871174420999445,error_lt: 0.4612169015587381
[2024-10-24 06:54:36,023][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.2778788369459686
[2024-10-24 06:54:36,644][train_con.py][line:106][INFO] ---------------epoch 20---------------
lr: [0.000490096263974162]
[2024-10-24 07:17:02,177][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003784699200325296,error_sp: 0.2782458696504452,error_cs: 0.39722207654019637,error_lt: 0.45994179044662586
[2024-10-24 07:24:17,601][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3188847362162164
[2024-10-24 07:24:17,608][train_con.py][line:106][INFO] ---------------epoch 21---------------
lr: [0.000487991283728773]
[2024-10-24 07:46:43,077][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0037714018960158606,error_sp: 0.2762736624855459,error_cs: 0.3960683778020906,error_lt: 0.4590785002935853
[2024-10-24 07:54:00,453][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.33862141221960035
[2024-10-24 07:54:00,460][train_con.py][line:106][INFO] ---------------epoch 22---------------
lr: [0.00048569276719458496]
[2024-10-24 08:16:25,803][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0037488794452556224,error_sp: 0.2722446114856158,error_cs: 0.39470619177437505,error_lt: 0.45771300448922847
[2024-10-24 08:23:40,977][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3233580446926862
[2024-10-24 08:23:40,985][train_con.py][line:106][INFO] ---------------epoch 23---------------
lr: [0.0004832025889695062]
[2024-10-24 08:46:06,791][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0037387540362925726,error_sp: 0.2705609235886117,error_cs: 0.3941725991210159,error_lt: 0.45689266014384716
[2024-10-24 08:53:23,937][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.33959071792351425
[2024-10-24 08:53:23,944][train_con.py][line:106][INFO] ---------------epoch 24---------------
lr: [0.00048052277997262424]
[2024-10-24 09:15:48,814][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0037278197292559107,error_sp: 0.26868499031566423,error_cs: 0.3935222908947038,error_lt: 0.45613860970275427
[2024-10-24 09:23:04,429][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.2640759712242139
[2024-10-24 09:23:04,802][train_con.py][line:106][INFO] ---------------epoch 25---------------
lr: [0.0004776555257876631]
[2024-10-24 09:45:30,407][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0037122134766115838,error_sp: 0.2659670033697915,error_cs: 0.3922625989012731,error_lt: 0.45543441246490934
[2024-10-24 09:52:47,006][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.25559330235889055
[2024-10-24 09:52:47,388][train_con.py][line:106][INFO] ---------------epoch 26---------------
lr: [0.0004746031648802909]
[2024-10-24 10:15:12,333][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0036990912746846308,error_sp: 0.2635374763565668,error_cs: 0.39181998715849187,error_lt: 0.45436989291907415
[2024-10-24 10:22:30,078][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3126669098038851
[2024-10-24 10:22:30,600][train_con.py][line:106][INFO] ---------------epoch 27---------------
lr: [0.0004713681866907318]
[2024-10-24 10:44:55,957][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003681522012525424,error_sp: 0.26016858176963725,error_cs: 0.3906222257264018,error_lt: 0.4536657705572504
[2024-10-24 10:52:14,292][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.2460456363370885
[2024-10-24 10:52:14,668][train_con.py][line:106][INFO] ---------------epoch 28---------------
lr: [0.00046795322960323796]
[2024-10-24 11:14:40,892][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003670569512160113,error_sp: 0.2583769583659777,error_cs: 0.389739410649281,error_lt: 0.4530544597275403
[2024-10-24 11:21:59,008][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.29853043164115833
[2024-10-24 11:21:59,015][train_con.py][line:106][INFO] ---------------epoch 29---------------
lr: [0.00046436107879407575]
[2024-10-24 11:44:24,526][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003657939384783145,error_sp: 0.25620414985520656,error_cs: 0.3889778620549399,error_lt: 0.45219977516036386
[2024-10-24 11:51:42,308][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.26446684983913465
[2024-10-24 11:51:42,314][train_con.py][line:106][INFO] ---------------epoch 30---------------
lr: [0.0004605946639597827]
[2024-10-24 12:14:07,616][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.0036497491779807416,error_sp: 0.2544375299157933,error_cs: 0.38883491325875563,error_lt: 0.45165228558094395
[2024-10-24 12:21:24,015][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.34734432985997876
[2024-10-24 12:21:24,022][train_con.py][line:106][INFO] ---------------epoch 31---------------
lr: [0.00045665705692754695]
[2024-10-24 12:43:48,356][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003641912840805062,error_sp: 0.25288006665966845,error_cs: 0.38847051531790416,error_lt: 0.4512232427006817
[2024-10-24 12:51:03,151][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.23837218547327496
[2024-10-24 12:51:03,536][train_con.py][line:106][INFO] ---------------epoch 32---------------
lr: [0.0004525514691496573]
[2024-10-24 13:13:28,762][train_con.py][line:136][INFO] [training]total_num: 142618.0,error: 0.003627823882557769,error_sp: 0.25039971415234435,error_cs: 0.3873494936098752,error_lt: 0.4505979293542513
[2024-10-24 13:20:46,377][train_con.py][line:179][INFO] [testing]total_number: 0,error: 0.3703376540274565
[2024-10-24 13:20:46,384][train_con.py][line:106][INFO] ---------------epoch 33---------------
lr: [0.00044828124908406856]
