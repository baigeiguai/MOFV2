[2024-09-02 15:03:13,320][train.py][line:77][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0', train_name='AttDistil2', model_path=None, learning_rate=0.0001, min_learning_rate=1e-05, start_scheduler_step=50, weight_decay=1e-05, momentum=0.99, batch_size=32, class_num=230, epoch_num=200, model_save_path='/data/ylh/MyExps/MOFV2/AttDistil_2', device='1,3,5,7', scheduler_T=None, num_workers=20, refer_model_path='./checkpoints/RawConv/RawConv_epoch_93.pth', log_name='log/train//train_AttDistil2_2024_09_02_15:03:08.log')
[2024-09-02 15:03:13,322][train.py][line:78][INFO] ---------------model---------------
DataParallel(
  (module): AttDistil(
    (embed): Embedding(8500, 64)
    (encoder): TransformerEncoder(
      (positionEnbeding): PositionEmbedding()
      (encoder_layers): ModuleList(
        (0-23): 24 x EncoderLayer(
          (mha): MultiHeadAttention(
            (WQ): Linear(in_features=640, out_features=640, bias=True)
            (WK): Linear(in_features=640, out_features=640, bias=True)
            (WV): Linear(in_features=640, out_features=640, bias=True)
            (scaled_dot_product_attn): ScaledDotProductAttention()
            (linear): Linear(in_features=640, out_features=640, bias=True)
          )
          (dropout1): Dropout(p=0, inplace=False)
          (layernorm1): LayerNorm((640,), eps=1e-06, elementwise_affine=True)
          (ffn): FeedForwardNetwork(
            (linear1): Linear(in_features=640, out_features=1024, bias=True)
            (linear2): Linear(in_features=1024, out_features=640, bias=True)
            (relu): LeakyReLU(negative_slope=0.01)
          )
          (dropout2): Dropout(p=0, inplace=False)
          (layernorm2): LayerNorm((640,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
    (to_features): Linear(in_features=640, out_features=1024, bias=True)
    (to_cls): Linear(in_features=1024, out_features=230, bias=True)
  )
)
[2024-09-02 15:03:13,322][train.py][line:79][INFO] ---------------device---------------
cuda:1
[2024-09-02 15:03:13,323][train.py][line:80][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 1e-05
)
[2024-09-02 15:03:13,323][train.py][line:81][INFO] ---------------lossfn---------------
CrossEntropyLoss(),L1Loss()
[2024-09-02 15:03:13,323][train.py][line:82][INFO] ---------------seed---------------
3407
[2024-09-02 15:03:13,326][train.py][line:94][INFO] ---------------epoch 1---------------
lr: [0.0001]
[2024-09-02 15:47:52,153][train.py][line:122][INFO] [training]total_num:142618.0, error:4.046356775053513, cls_error:3.7899228045483215, distil_error:0.2564339716034177 
[2024-09-02 16:02:32,033][train.py][line:168][INFO] [testing]total_number: 142618,error: 3.773545237905663,total_acc: 0.06614172458648682
[2024-09-02 16:02:33,376][train.py][line:94][INFO] ---------------epoch 2---------------
lr: [0.0001]
[2024-09-02 16:47:00,035][train.py][line:122][INFO] [training]total_num:142618.0, error:3.9699261665451058, cls_error:3.771834454175392, distil_error:0.1980917157812251 
[2024-09-02 17:01:40,381][train.py][line:168][INFO] [testing]total_number: 142618,error: 3.767081397355244,total_acc: 0.06608562916517258
[2024-09-02 17:01:41,206][train.py][line:94][INFO] ---------------epoch 3---------------
lr: [0.0001]
[2024-09-02 17:46:10,380][train.py][line:122][INFO] [training]total_num:142618.0, error:3.9560021116101187, cls_error:3.7694822884695505, distil_error:0.18651982371137882 
[2024-09-02 18:00:51,450][train.py][line:168][INFO] [testing]total_number: 142618,error: 3.7663910686435664,total_acc: 0.06538445502519608
[2024-09-02 18:00:52,282][train.py][line:94][INFO] ---------------epoch 4---------------
lr: [0.0001]
[2024-09-02 18:45:17,087][train.py][line:122][INFO] [training]total_num:142618.0, error:3.9489343563181527, cls_error:3.768161729619067, distil_error:0.18077262712635875 
[2024-09-02 18:59:57,234][train.py][line:168][INFO] [testing]total_number: 142618,error: 3.767231848130944,total_acc: 0.06608562916517258
[2024-09-02 18:59:57,242][train.py][line:94][INFO] ---------------epoch 5---------------
lr: [0.0001]
[2024-09-02 19:44:21,966][train.py][line:122][INFO] [training]total_num:142618.0, error:3.944770738963158, cls_error:3.767364502861081, distil_error:0.1774062313620121 
[2024-09-02 19:58:59,214][train.py][line:168][INFO] [testing]total_number: 142618,error: 3.765529646988838,total_acc: 0.06608562916517258
[2024-09-02 19:59:00,096][train.py][line:94][INFO] ---------------epoch 6---------------
lr: [0.0001]
[2024-09-02 20:43:24,701][train.py][line:122][INFO] [training]total_num:142618.0, error:3.941612008064451, cls_error:3.766328937530945, distil_error:0.17528307005616178 
[2024-09-02 20:58:05,119][train.py][line:168][INFO] [testing]total_number: 142618,error: 3.7694426746671774,total_acc: 0.06538445502519608
[2024-09-02 20:58:05,126][train.py][line:94][INFO] ---------------epoch 7---------------
lr: [0.0001]
