[2024-10-28 16:05:24,562][train_sub.py][line:56][INFO] cls num list:[5013 9433   75 9261 4497   18 2432  175 5626   61 2345  903 3526 9425
 9425   22   38 2148 9325  913   31   18  126   33    2   75   17    8
 4112   70  275   89 7400  155    5  694   58   21    0   98    0   38
 1812   36  313   72   15   37   10   54   26  590   70  256  151 1888
  496  353  133 4498 9396 5199  481    0  102   66    0    0   62  588
   72  214  157  143   28  472   61  421  133  126  116  705   16   47
  449  666  360 1914    3   51   45  978    4  105   46  927   47  101
    1    3    3   13   17   60    1   53   11   18   23  213    2   17
  138  624    3   20   32   94   16   55   87  344   78   47   30  112
   20   91   88  246   70   10   25   28   49   92   56   73  115   72
  126  273  113  388  385  715  617 4443    6   54   13  483   11  381
  249    2    9   51  185  128  516   29  242   48  384  312  912   12
  355  346   40   30  365   16   23  397   15  146  125   40   24   96
    1    7   18   47   21    7   22   88   65   59   38  181   10   57
   83  292   67   12   25   23   54   64  428   70   13    2   35   30
   29   24   33   14   21   21  163   70   48  146  127   77   38   16
  340   41   88   71   22   58]
[2024-10-28 16:05:24,570][train_sub.py][line:70][INFO] cluster_number:[100, 188, 1, 185, 89, 1, 48, 3, 112, 1, 46, 18, 70, 188, 188, 1, 1, 42, 186, 18, 1, 1, 2, 1, 1, 1, 1, 1, 82, 1, 5, 1, 148, 3, 1, 13, 1, 1, 0, 1, 0, 1, 36, 1, 6, 1, 1, 1, 1, 1, 1, 11, 1, 5, 3, 37, 9, 7, 2, 89, 187, 103, 9, 0, 2, 1, 0, 0, 1, 11, 1, 4, 3, 2, 1, 9, 1, 8, 2, 2, 2, 14, 1, 1, 8, 13, 7, 38, 1, 1, 1, 19, 1, 2, 1, 18, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 12, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 2, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 5, 2, 7, 7, 14, 12, 88, 1, 1, 1, 9, 1, 7, 4, 1, 1, 1, 3, 2, 10, 1, 4, 1, 7, 6, 18, 1, 7, 6, 1, 1, 7, 1, 1, 7, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 6, 1, 1, 1, 1, 1]
[2024-10-28 16:05:27,101][train_sub.py][line:100][INFO] ---------------args---------------
Namespace(data_path='./data/All_Wrapped', train_name='Hope_SubClass_AG', model_path=None, learning_rate=0.0005, min_learning_rate=1e-06, start_scheduler_step=0, weight_decay=4e-05, momentum=0.99, batch_size=768, class_num=230, epoch_num=150, model_save_path='./checkpoints/Hope_SubClass_AG', device='0', scheduler_T=None, num_workers=20, cluster_limit=50, warm_epoch=40, epoch_step=10, log_name='log/train//train_Hope_SubClass_AG_2024_10_28_16:02:56.log', cls_num_list=array([5013, 9433,   75, 9261, 4497,   18, 2432,  175, 5626,   61, 2345,
        903, 3526, 9425, 9425,   22,   38, 2148, 9325,  913,   31,   18,
        126,   33,    2,   75,   17,    8, 4112,   70,  275,   89, 7400,
        155,    5,  694,   58,   21,    0,   98,    0,   38, 1812,   36,
        313,   72,   15,   37,   10,   54,   26,  590,   70,  256,  151,
       1888,  496,  353,  133, 4498, 9396, 5199,  481,    0,  102,   66,
          0,    0,   62,  588,   72,  214,  157,  143,   28,  472,   61,
        421,  133,  126,  116,  705,   16,   47,  449,  666,  360, 1914,
          3,   51,   45,  978,    4,  105,   46,  927,   47,  101,    1,
          3,    3,   13,   17,   60,    1,   53,   11,   18,   23,  213,
          2,   17,  138,  624,    3,   20,   32,   94,   16,   55,   87,
        344,   78,   47,   30,  112,   20,   91,   88,  246,   70,   10,
         25,   28,   49,   92,   56,   73,  115,   72,  126,  273,  113,
        388,  385,  715,  617, 4443,    6,   54,   13,  483,   11,  381,
        249,    2,    9,   51,  185,  128,  516,   29,  242,   48,  384,
        312,  912,   12,  355,  346,   40,   30,  365,   16,   23,  397,
         15,  146,  125,   40,   24,   96,    1,    7,   18,   47,   21,
          7,   22,   88,   65,   59,   38,  181,   10,   57,   83,  292,
         67,   12,   25,   23,   54,   64,  428,   70,   13,    2,   35,
         30,   29,   24,   33,   14,   21,   21,  163,   70,   48,  146,
        127,   77,   38,   16,  340,   41,   88,   71,   22,   58]))
[2024-10-28 16:05:27,107][train_sub.py][line:101][INFO] ---------------model---------------
HopeV1_Sub(
  (conv_module): ResTcn(
    (intensity_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (TCN): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(2, 32, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (2): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (10): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (12): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (14): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (16): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (18): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (20): Dropout(p=0.25, inplace=False)
      (21): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (22): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (23): Dropout(p=0.25, inplace=False)
      (24): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (25): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (26): Dropout(p=0.25, inplace=False)
      (27): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (28): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (29): Flatten(start_dim=1, end_dim=-1)
    )
  )
  (att): AttentionModule(
    (embed): Embedding(850, 15)
    (patch_conv): PatchConvModule(
      (conv): Sequential(
        (0): Conv2d(1, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (1): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
        (2): Conv2d(2, 4, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (3): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
        (4): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (5): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
        (6): Conv2d(8, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
      )
    )
    (att): TransformerEncoder(
      (positionEnbeding): PositionEmbedding()
      (encoder_layers): ModuleList(
        (0-7): 8 x EncoderLayer(
          (mha): MultiHeadAttention(
            (WQ): Linear(in_features=32, out_features=32, bias=True)
            (WK): Linear(in_features=32, out_features=32, bias=True)
            (WV): Linear(in_features=32, out_features=32, bias=True)
            (scaled_dot_product_attn): ScaledDotProductAttention()
            (linear): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout1): Dropout(p=0.25, inplace=False)
          (layernorm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (ffn): FeedForwardNetwork(
            (linear1): Linear(in_features=32, out_features=256, bias=True)
            (linear2): Linear(in_features=256, out_features=32, bias=True)
            (relu): LeakyReLU(negative_slope=0.01)
          )
          (dropout2): Dropout(p=0.25, inplace=False)
          (layernorm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
  )
  (sp_cls): Sequential(
    (0): Linear(in_features=1056, out_features=230, bias=True)
  )
  (cluster_cls): Sequential(
    (0): Linear(in_features=1056, out_features=2837, bias=True)
  )
)
[2024-10-28 16:05:27,107][train_sub.py][line:102][INFO] ---------------device---------------
cuda:0
[2024-10-28 16:05:27,107][train_sub.py][line:103][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 4e-05
)
[2024-10-28 16:05:27,107][train_sub.py][line:104][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-10-28 16:05:27,107][train_sub.py][line:105][INFO] ---------------seed---------------
3407
[2024-10-28 16:05:27,151][train_sub.py][line:116][INFO] ---------------epoch 1---------------
lr: [0.0005]
[2024-10-28 16:14:39,951][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 3.3559269097543534
[2024-10-28 16:17:28,646][train_sub.py][line:219][INFO] test_acc:0.031153149902820587,test_err:5.587580898115712
[2024-10-28 16:17:28,943][train_sub.py][line:116][INFO] ---------------epoch 2---------------
lr: [0.0004998905670543902]
[2024-10-28 16:26:39,642][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.633941126126115
[2024-10-28 16:29:28,030][train_sub.py][line:219][INFO] test_acc:0.026798861101269722,test_err:5.745103657886546
[2024-10-28 16:29:28,033][train_sub.py][line:116][INFO] ---------------epoch 3---------------
lr: [0.0004996170656864676]
[2024-10-28 16:38:38,582][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.14822853636998
[2024-10-28 16:41:26,963][train_sub.py][line:219][INFO] test_acc:0.015615140087902546,test_err:5.8320003600530725
[2024-10-28 16:41:26,965][train_sub.py][line:116][INFO] ---------------epoch 4---------------
lr: [0.0004992343413213054]
[2024-10-28 16:50:37,465][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.8701243176255176
[2024-10-28 16:53:25,513][train_sub.py][line:219][INFO] test_acc:0.03739359602332115,test_err:5.066929310880681
[2024-10-28 16:53:25,654][train_sub.py][line:116][INFO] ---------------epoch 5---------------
lr: [0.0004987425618186622]
[2024-10-28 17:02:36,198][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.6917180925287225
[2024-10-28 17:05:23,121][train_sub.py][line:219][INFO] test_acc:0.06007656827569008,test_err:4.380019924333019
[2024-10-28 17:05:23,232][train_sub.py][line:116][INFO] ---------------epoch 6---------------
lr: [0.0004981419428734715]
[2024-10-28 17:14:33,818][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.5518973636370834
[2024-10-28 17:17:21,273][train_sub.py][line:219][INFO] test_acc:0.0872260183095932,test_err:4.264373563951062
[2024-10-28 17:17:21,391][train_sub.py][line:116][INFO] ---------------epoch 7---------------
lr: [0.0004974327479212248]
[2024-10-28 17:26:31,969][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.4068971455738108
[2024-10-28 17:29:20,031][train_sub.py][line:219][INFO] test_acc:0.15818479657173157,test_err:3.4566722082835373
[2024-10-28 17:29:20,145][train_sub.py][line:116][INFO] ---------------epoch 8---------------
lr: [0.0004966152880224123]
[2024-10-28 17:38:30,728][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.3271054369147106
[2024-10-28 17:41:17,356][train_sub.py][line:219][INFO] test_acc:0.14953932166099548,test_err:3.6103862927805994
[2024-10-28 17:41:17,358][train_sub.py][line:116][INFO] ---------------epoch 9---------------
lr: [0.0004956899217260752]
[2024-10-28 17:50:27,955][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.2243178852142826
[2024-10-28 17:53:16,529][train_sub.py][line:219][INFO] test_acc:0.1671738475561142,test_err:3.5568572119359048
[2024-10-28 17:53:31,365][train_sub.py][line:116][INFO] ---------------epoch 10---------------
lr: [0.000494657054912527]
[2024-10-28 18:02:41,976][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.1284525913576926
[2024-10-28 18:05:30,024][train_sub.py][line:219][INFO] test_acc:0.4734745919704437,test_err:1.70570408849306
[2024-10-28 18:05:30,150][train_sub.py][line:116][INFO] ---------------epoch 11---------------
lr: [0.0004935171406153129]
[2024-10-28 18:14:40,680][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.077346110215751
[2024-10-28 18:17:28,353][train_sub.py][line:219][INFO] test_acc:0.3941928744316101,test_err:2.075389963644807
[2024-10-28 18:17:28,355][train_sub.py][line:116][INFO] ---------------epoch 12---------------
lr: [0.0004922706788224885]
[2024-10-28 18:26:38,908][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.0609049848330918
[2024-10-28 18:29:26,677][train_sub.py][line:219][INFO] test_acc:0.341373473405838,test_err:2.430592841358595
[2024-10-28 18:29:26,679][train_sub.py][line:116][INFO] ---------------epoch 13---------------
lr: [0.0004909182162573005]
[2024-10-28 18:38:37,469][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.9577595575522351
[2024-10-28 18:41:26,013][train_sub.py][line:219][INFO] test_acc:0.4572564363479614,test_err:1.9666648132185782
[2024-10-28 18:41:26,015][train_sub.py][line:116][INFO] ---------------epoch 14---------------
lr: [0.0004894603461383684]
[2024-10-28 18:50:36,507][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.9060975954096805
[2024-10-28 18:53:21,946][train_sub.py][line:219][INFO] test_acc:0.17185768485069275,test_err:3.7132700143321866
[2024-10-28 18:53:21,948][train_sub.py][line:116][INFO] ---------------epoch 15---------------
lr: [0.00048789770791947157]
[2024-10-28 19:02:32,390][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8603598584410965
[2024-10-28 19:05:19,437][train_sub.py][line:219][INFO] test_acc:0.13863608241081238,test_err:4.58328116260549
[2024-10-28 19:05:19,439][train_sub.py][line:116][INFO] ---------------epoch 16---------------
lr: [0.000486230987009057]
[2024-10-28 19:14:29,914][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8078319558533289
[2024-10-28 19:17:17,701][train_sub.py][line:219][INFO] test_acc:0.12270540744066238,test_err:5.441478483459001
[2024-10-28 19:17:17,702][train_sub.py][line:116][INFO] ---------------epoch 17---------------
lr: [0.00048446091446958706]
[2024-10-28 19:26:28,111][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.7740392896436876
[2024-10-28 19:29:16,614][train_sub.py][line:219][INFO] test_acc:0.12933851778507233,test_err:5.033851531564548
[2024-10-28 19:29:16,616][train_sub.py][line:116][INFO] ---------------epoch 18---------------
lr: [0.00048258826669686516]
[2024-10-28 19:38:27,088][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.7126256272356998
[2024-10-28 19:41:14,940][train_sub.py][line:219][INFO] test_acc:0.5297718644142151,test_err:1.5604893600427976
[2024-10-28 19:41:15,053][train_sub.py][line:116][INFO] ---------------epoch 19---------------
lr: [0.00048061386507947373]
[2024-10-28 19:50:25,652][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.7051031813826613
[2024-10-28 19:53:14,372][train_sub.py][line:219][INFO] test_acc:0.5691006779670715,test_err:1.3927424146283058
[2024-10-28 19:55:05,586][train_sub.py][line:116][INFO] ---------------epoch 20---------------
lr: [0.00047853857563847865]
[2024-10-28 20:04:16,160][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.6933711763992104
[2024-10-28 20:07:03,442][train_sub.py][line:219][INFO] test_acc:0.07882595807313919,test_err:6.968288824763349
[2024-10-28 20:07:03,445][train_sub.py][line:116][INFO] ---------------epoch 21---------------
lr: [0.0004763633086475541]
[2024-10-28 20:16:13,995][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.6145764624559751
[2024-10-28 20:19:02,092][train_sub.py][line:219][INFO] test_acc:0.18055926263332367,test_err:4.090726769098672
[2024-10-28 20:19:02,094][train_sub.py][line:116][INFO] ---------------epoch 22---------------
lr: [0.00047408901823369935]
[2024-10-28 20:28:12,916][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.5942786613138773
[2024-10-28 20:30:59,753][train_sub.py][line:219][INFO] test_acc:0.40191981196403503,test_err:2.3321151022789297
[2024-10-28 20:30:59,755][train_sub.py][line:116][INFO] ---------------epoch 23---------------
lr: [0.0004717167019587168]
[2024-10-28 20:40:10,210][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.5422729031052641
[2024-10-28 20:42:56,838][train_sub.py][line:219][INFO] test_acc:0.7973818182945251,test_err:0.6227980464776998
[2024-10-28 20:42:56,951][train_sub.py][line:116][INFO] ---------------epoch 24---------------
lr: [0.0004692474003816405]
[2024-10-28 20:52:07,387][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.5225664325939712
[2024-10-28 20:54:54,549][train_sub.py][line:219][INFO] test_acc:0.07023657858371735,test_err:7.466404143200125
[2024-10-28 20:54:54,550][train_sub.py][line:116][INFO] ---------------epoch 25---------------
lr: [0.00046668219660230274]
[2024-10-28 21:04:05,104][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.4922982976641706
[2024-10-28 21:06:52,852][train_sub.py][line:219][INFO] test_acc:0.18806181848049164,test_err:4.495940060384812
[2024-10-28 21:06:52,855][train_sub.py][line:116][INFO] ---------------epoch 26---------------
lr: [0.00046402221578624073]
[2024-10-28 21:16:03,426][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.46268922459053735
[2024-10-28 21:18:51,494][train_sub.py][line:219][INFO] test_acc:0.5453729629516602,test_err:1.5965784129596525
[2024-10-28 21:18:51,679][train_sub.py][line:116][INFO] ---------------epoch 27---------------
lr: [0.0004612686246711525]
[2024-10-28 21:28:02,241][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.43208198313431073
[2024-10-28 21:30:49,246][train_sub.py][line:219][INFO] test_acc:0.8380148410797119,test_err:0.4736467464476503
[2024-10-28 21:32:55,532][train_sub.py][line:116][INFO] ---------------epoch 28---------------
lr: [0.0004584226310551163]
[2024-10-28 21:42:06,126][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.40567724550923995
[2024-10-28 21:44:53,871][train_sub.py][line:219][INFO] test_acc:0.2703655958175659,test_err:3.766336007223975
[2024-10-28 21:44:53,873][train_sub.py][line:116][INFO] ---------------epoch 29---------------
lr: [0.0004554854832668007]
[2024-10-28 21:54:04,430][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.3814926725882356
[2024-10-28 21:56:51,050][train_sub.py][line:219][INFO] test_acc:0.8343336582183838,test_err:0.48425331307194563
[2024-10-28 21:56:51,052][train_sub.py][line:116][INFO] ---------------epoch 30---------------
lr: [0.00045245846961789485]
[2024-10-28 22:06:01,585][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.40296744322904976
[2024-10-28 22:08:49,263][train_sub.py][line:219][INFO] test_acc:0.12022325396537781,test_err:5.080271871500118
[2024-10-28 22:08:49,265][train_sub.py][line:116][INFO] ---------------epoch 31---------------
lr: [0.00044934291783800133]
[2024-10-28 22:17:59,783][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.3580447401731245
[2024-10-28 22:20:47,800][train_sub.py][line:219][INFO] test_acc:0.8313747048377991,test_err:0.48351834462555027
[2024-10-28 22:20:47,802][train_sub.py][line:116][INFO] ---------------epoch 32---------------
lr: [0.0004461401944922381]
[2024-10-28 22:29:58,302][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.31971512782958245
[2024-10-28 22:32:46,049][train_sub.py][line:219][INFO] test_acc:0.11855445802211761,test_err:6.0047506683616225
[2024-10-28 22:32:46,051][train_sub.py][line:116][INFO] ---------------epoch 33---------------
lr: [0.0004428517043818066]
[2024-10-28 22:41:56,595][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.2937779240710761
[2024-10-28 22:44:43,722][train_sub.py][line:219][INFO] test_acc:0.8283596634864807,test_err:0.5098119118371077
[2024-10-28 22:44:43,724][train_sub.py][line:116][INFO] ---------------epoch 34---------------
lr: [0.00043947888992778547]
[2024-10-28 22:53:54,264][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.2837367330988248
[2024-10-28 22:56:41,690][train_sub.py][line:219][INFO] test_acc:0.8603963255882263,test_err:0.39860483668043567
[2024-10-28 22:56:41,805][train_sub.py][line:116][INFO] ---------------epoch 35---------------
lr: [0.00043602323053842544]
[2024-10-28 23:05:52,312][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.2870695393091889
[2024-10-28 23:08:38,723][train_sub.py][line:219][INFO] test_acc:0.08970116078853607,test_err:8.883969579012163
[2024-10-28 23:08:38,725][train_sub.py][line:116][INFO] ---------------epoch 36---------------
lr: [0.0004324862419602176]
[2024-10-28 23:17:49,265][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.2501966705726039
[2024-10-28 23:20:36,199][train_sub.py][line:219][INFO] test_acc:0.13862206041812897,test_err:5.470199793256739
[2024-10-28 23:20:36,201][train_sub.py][line:116][INFO] ---------------epoch 37---------------
lr: [0.0004288694756130224]
[2024-10-28 23:29:46,761][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.22877283730814535
[2024-10-28 23:32:34,646][train_sub.py][line:219][INFO] test_acc:0.8809337019920349,test_err:0.32889692611762034
[2024-10-28 23:32:34,770][train_sub.py][line:116][INFO] ---------------epoch 38---------------
lr: [0.0004251745179095524]
[2024-10-28 23:41:45,360][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.2303946483679997
[2024-10-28 23:44:33,876][train_sub.py][line:219][INFO] test_acc:0.06376474350690842,test_err:8.063575014632235
[2024-10-28 23:44:33,878][train_sub.py][line:116][INFO] ---------------epoch 39---------------
lr: [0.000421402989559502]
[2024-10-28 23:53:44,442][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.2115638925824114
[2024-10-28 23:56:31,794][train_sub.py][line:219][INFO] test_acc:0.20935645699501038,test_err:5.840948441977142
[2024-10-28 23:56:31,795][train_sub.py][line:116][INFO] ---------------epoch 40---------------
lr: [0.00041755654485863545]
[2024-10-29 00:05:42,336][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.2027926376109482
[2024-10-29 00:08:29,982][train_sub.py][line:219][INFO] test_acc:0.9068841338157654,test_err:0.25289613627002483
[2024-10-29 00:10:17,837][train_sub.py][line:116][INFO] ---------------epoch 41---------------
lr: [0.000413636870963142]
[2024-10-29 00:10:17,837][train_sub.py][line:122][INFO] cluster starts
[2024-10-29 00:13:15,826][train_sub.py][line:125][INFO] cluster ends
[2024-10-29 00:22:26,549][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 4.112644819803135
[2024-10-29 00:25:13,499][train_sub.py][line:219][INFO] test_acc:0.10547056049108505,test_err:7.658859564412024
[2024-10-29 00:25:13,501][train_sub.py][line:116][INFO] ---------------epoch 42---------------
lr: [0.0004096456871495748]
[2024-10-29 00:34:24,001][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.093516687552134
[2024-10-29 00:37:09,358][train_sub.py][line:219][INFO] test_acc:0.4342649579048157,test_err:2.8983652075972928
[2024-10-29 00:37:09,360][train_sub.py][line:116][INFO] ---------------epoch 43---------------
lr: [0.0004055847440607014]
[2024-10-29 00:46:19,969][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.5265966865324205
[2024-10-29 00:49:06,433][train_sub.py][line:219][INFO] test_acc:0.8234724998474121,test_err:0.5463504563586445
[2024-10-29 00:49:06,435][train_sub.py][line:116][INFO] ---------------epoch 44---------------
lr: [0.0004014558229375957]
[2024-10-29 00:58:16,922][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.280776979461793
[2024-10-29 01:01:04,660][train_sub.py][line:219][INFO] test_acc:0.8912339210510254,test_err:0.31973326153131904
[2024-10-29 01:01:04,662][train_sub.py][line:116][INFO] ---------------epoch 45---------------
lr: [0.0003972607348383054]
[2024-10-29 01:10:15,208][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.091234947725009
[2024-10-29 01:13:03,360][train_sub.py][line:219][INFO] test_acc:0.8775330185890198,test_err:0.4263152931516449
[2024-10-29 01:13:03,362][train_sub.py][line:116][INFO] ---------------epoch 46---------------
lr: [0.00039300131984344185]
[2024-10-29 01:22:14,072][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.9552636559932463
[2024-10-29 01:25:01,488][train_sub.py][line:219][INFO] test_acc:0.9410523176193237,test_err:0.16839911444963868
[2024-10-29 01:25:30,129][train_sub.py][line:116][INFO] ---------------epoch 47---------------
lr: [0.00038867944624903817]
[2024-10-29 01:34:40,865][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8677602567339456
[2024-10-29 01:37:28,101][train_sub.py][line:219][INFO] test_acc:0.9260191321372986,test_err:0.21149944424659253
[2024-10-29 01:37:28,103][train_sub.py][line:116][INFO] ---------------epoch 48---------------
lr: [0.00038429700974702813]
[2024-10-29 01:46:38,805][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.7573639276207135
[2024-10-29 01:49:24,607][train_sub.py][line:219][INFO] test_acc:0.9329327344894409,test_err:0.20038191421941343
[2024-10-29 01:49:24,610][train_sub.py][line:116][INFO] ---------------epoch 49---------------
lr: [0.000379855932593711]
[2024-10-29 01:58:35,301][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.6739773493941112
[2024-10-29 02:01:23,159][train_sub.py][line:219][INFO] test_acc:0.9624731540679932,test_err:0.10845999293885525
[2024-10-29 02:01:23,273][train_sub.py][line:116][INFO] ---------------epoch 50---------------
lr: [0.0003753581627665587]
[2024-10-29 02:10:33,990][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.6087773038494971
[2024-10-29 02:13:21,372][train_sub.py][line:219][INFO] test_acc:0.9884586930274963,test_err:0.03683866910205814
[2024-10-29 02:13:21,500][train_sub.py][line:116][INFO] ---------------epoch 51---------------
lr: [0.0003708056731097427]
[2024-10-29 02:13:21,500][train_sub.py][line:122][INFO] cluster starts
[2024-10-29 02:16:18,228][train_sub.py][line:125][INFO] cluster ends
[2024-10-29 02:25:28,926][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 4.466040835585646
[2024-10-29 02:28:16,569][train_sub.py][line:219][INFO] test_acc:0.8861364126205444,test_err:0.3311806671541705
[2024-10-29 02:28:16,787][train_sub.py][line:116][INFO] ---------------epoch 52---------------
lr: [0.0003662004604687508]
[2024-10-29 02:37:27,648][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.545730237678815
[2024-10-29 02:40:15,078][train_sub.py][line:219][INFO] test_acc:0.32675397396087646,test_err:5.213465195589809
[2024-10-29 02:40:15,080][train_sub.py][line:116][INFO] ---------------epoch 53---------------
lr: [0.00036154454481447467]
[2024-10-29 02:49:25,769][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.047138520786839
[2024-10-29 02:52:14,232][train_sub.py][line:219][INFO] test_acc:0.9656354784965515,test_err:0.09981894216960877
[2024-10-29 02:52:14,234][train_sub.py][line:116][INFO] ---------------epoch 54---------------
lr: [0.00035683996835715197]
[2024-10-29 03:01:24,929][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8435984385269945
[2024-10-29 03:04:13,028][train_sub.py][line:219][INFO] test_acc:0.8372645974159241,test_err:0.5720355684183017
[2024-10-29 03:04:13,030][train_sub.py][line:116][INFO] ---------------epoch 55---------------
lr: [0.00035208879465055333]
[2024-10-29 03:13:23,825][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.7182674321436113
[2024-10-29 03:16:12,258][train_sub.py][line:219][INFO] test_acc:0.9784669280052185,test_err:0.06204877028452052
[2024-10-29 03:16:12,260][train_sub.py][line:116][INFO] ---------------epoch 56---------------
lr: [0.0003472931076868026]
[2024-10-29 03:25:22,883][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.6223256011163035
[2024-10-29 03:28:10,508][train_sub.py][line:219][INFO] test_acc:0.6837496161460876,test_err:1.4335676191039184
[2024-10-29 03:28:10,510][train_sub.py][line:116][INFO] ---------------epoch 57---------------
lr: [0.0003424550109822331]
[2024-10-29 03:37:21,268][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.5430242393606453
[2024-10-29 03:40:08,575][train_sub.py][line:219][INFO] test_acc:0.9925044775009155,test_err:0.02596869885527794
[2024-10-29 03:40:08,733][train_sub.py][line:116][INFO] ---------------epoch 58---------------
lr: [0.00033757662665467614]
[2024-10-29 03:49:19,411][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.5010474827340854
[2024-10-29 03:52:07,613][train_sub.py][line:219][INFO] test_acc:0.9634407758712769,test_err:0.10703480775578834
[2024-10-29 03:52:07,615][train_sub.py][line:116][INFO] ---------------epoch 59---------------
lr: [0.00033266009449258745]
[2024-10-29 04:01:18,335][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.44248450779786674
[2024-10-29 04:04:05,151][train_sub.py][line:219][INFO] test_acc:0.98927903175354,test_err:0.033496793553856534
[2024-10-29 04:04:05,153][train_sub.py][line:116][INFO] ---------------epoch 60---------------
lr: [0.00032770757101642273]
[2024-10-29 04:13:15,885][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.4060807250520235
[2024-10-29 04:16:02,757][train_sub.py][line:219][INFO] test_acc:0.8611325621604919,test_err:0.5504568115094087
[2024-10-29 04:16:02,759][train_sub.py][line:116][INFO] ---------------epoch 61---------------
lr: [0.0003227212285326682]
[2024-10-29 04:16:02,759][train_sub.py][line:122][INFO] cluster starts
[2024-10-29 04:18:59,427][train_sub.py][line:125][INFO] cluster ends
[2024-10-29 04:28:10,076][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 4.698834702532778
[2024-10-29 04:30:57,420][train_sub.py][line:219][INFO] test_acc:0.952418327331543,test_err:0.14570772899214618
[2024-10-29 04:30:57,422][train_sub.py][line:116][INFO] ---------------epoch 62---------------
lr: [0.0003177032541809456]
[2024-10-29 04:40:08,130][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.6882003481670091
[2024-10-29 04:42:54,607][train_sub.py][line:219][INFO] test_acc:0.9713500142097473,test_err:0.08629555330343885
[2024-10-29 04:42:54,609][train_sub.py][line:116][INFO] ---------------epoch 63---------------
lr: [0.00031265584897460845]
[2024-10-29 04:52:05,304][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.110682499665086
[2024-10-29 04:54:53,225][train_sub.py][line:219][INFO] test_acc:0.9837958812713623,test_err:0.0494565499648552
[2024-10-29 04:54:53,227][train_sub.py][line:116][INFO] ---------------epoch 64---------------
lr: [0.0003075812268352476]
[2024-10-29 05:04:03,938][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8799801090712188
[2024-10-29 05:06:51,603][train_sub.py][line:219][INFO] test_acc:0.9936053156852722,test_err:0.023424347600510334
[2024-10-29 05:06:51,718][train_sub.py][line:116][INFO] ---------------epoch 65---------------
lr: [0.00030248161362153315]
[2024-10-29 05:16:02,476][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.7336105056988296
[2024-10-29 05:18:50,940][train_sub.py][line:219][INFO] test_acc:0.996662437915802,test_err:0.0135327710823897
[2024-10-29 05:18:51,052][train_sub.py][line:116][INFO] ---------------epoch 66---------------
lr: [0.00029735924615281436]
[2024-10-29 05:28:01,768][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.6488829783854946
[2024-10-29 05:30:49,395][train_sub.py][line:219][INFO] test_acc:0.9053695797920227,test_err:0.31656787525086355
[2024-10-29 05:30:49,397][train_sub.py][line:116][INFO] ---------------epoch 67---------------
lr: [0.00029221637122791026]
[2024-10-29 05:40:00,138][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.5569986659352497
[2024-10-29 05:42:48,293][train_sub.py][line:219][INFO] test_acc:0.9879117608070374,test_err:0.03661594062053751
[2024-10-29 05:42:48,295][train_sub.py][line:116][INFO] ---------------epoch 68---------------
lr: [0.00028705524463951577]
[2024-10-29 05:51:59,023][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.48918647935954473
[2024-10-29 05:54:46,819][train_sub.py][line:219][INFO] test_acc:0.9841744899749756,test_err:0.045896656027155106
[2024-10-29 05:54:46,821][train_sub.py][line:116][INFO] ---------------epoch 69---------------
lr: [0.00028187813018466014]
[2024-10-29 06:03:57,534][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.4438813078788019
[2024-10-29 06:06:46,035][train_sub.py][line:219][INFO] test_acc:0.9935211539268494,test_err:0.02068785839195874
[2024-10-29 06:06:46,037][train_sub.py][line:116][INFO] ---------------epoch 70---------------
lr: [0.00027668729867164684]
[2024-10-29 06:15:56,805][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.39907286292122257
[2024-10-29 06:18:44,207][train_sub.py][line:219][INFO] test_acc:0.6972121596336365,test_err:1.5921571145024431
[2024-10-29 06:18:44,209][train_sub.py][line:116][INFO] ---------------epoch 71---------------
lr: [0.0002714850269239149]
[2024-10-29 06:18:44,209][train_sub.py][line:122][INFO] cluster starts
[2024-10-29 06:21:40,909][train_sub.py][line:125][INFO] cluster ends
[2024-10-29 06:30:51,596][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 4.584539286551937
[2024-10-29 06:33:39,345][train_sub.py][line:219][INFO] test_acc:0.3040219247341156,test_err:5.267583073146882
[2024-10-29 06:33:39,349][train_sub.py][line:116][INFO] ---------------epoch 72---------------
lr: [0.0002662735967812525]
[2024-10-29 06:42:50,098][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.5105219002692931
[2024-10-29 06:45:37,955][train_sub.py][line:219][INFO] test_acc:0.9888162612915039,test_err:0.0377941392962971
[2024-10-29 06:45:37,957][train_sub.py][line:116][INFO] ---------------epoch 73---------------
lr: [0.00026105529409880716]
[2024-10-29 06:54:48,719][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8765022290009324
[2024-10-29 06:57:35,600][train_sub.py][line:219][INFO] test_acc:0.9973635673522949,test_err:0.011746126175132049
[2024-10-29 06:57:35,713][train_sub.py][line:116][INFO] ---------------epoch 74---------------
lr: [0.00025583240774432317]
[2024-10-29 07:06:46,500][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.657818329270168
[2024-10-29 07:09:33,894][train_sub.py][line:219][INFO] test_acc:0.9983872771263123,test_err:0.008090573704584943
[2024-10-29 07:09:34,005][train_sub.py][line:116][INFO] ---------------epoch 75---------------
lr: [0.00025060722859405283]
[2024-10-29 07:18:44,779][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.5314789403189895
[2024-10-29 07:21:33,452][train_sub.py][line:219][INFO] test_acc:0.9967395663261414,test_err:0.012166007578070025
[2024-10-29 07:21:33,454][train_sub.py][line:116][INFO] ---------------epoch 76---------------
lr: [0.0002453820485277764]
[2024-10-29 07:30:44,269][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.44435105528882757
[2024-10-29 07:33:32,438][train_sub.py][line:219][INFO] test_acc:0.9981138706207275,test_err:0.007556346598267805
[2024-10-29 07:33:32,721][train_sub.py][line:116][INFO] ---------------epoch 77---------------
lr: [0.00024015915942337247]
[2024-10-29 07:42:43,462][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.38687731277558113
[2024-10-29 07:45:29,869][train_sub.py][line:219][INFO] test_acc:0.9857171177864075,test_err:0.04350657568745671
[2024-10-29 07:45:29,871][train_sub.py][line:116][INFO] ---------------epoch 78---------------
lr: [0.00023494085215137813]
[2024-10-29 07:54:40,667][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.3474647035842301
[2024-10-29 07:57:27,319][train_sub.py][line:219][INFO] test_acc:0.9946430325508118,test_err:0.017149791017741774
[2024-10-29 07:57:27,321][train_sub.py][line:116][INFO] ---------------epoch 79---------------
lr: [0.0002297294155699824]
[2024-10-29 08:06:38,063][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.30405432891140705
[2024-10-29 08:09:26,316][train_sub.py][line:219][INFO] test_acc:0.9992567300796509,test_err:0.0037974392678108257
[2024-10-29 08:09:26,427][train_sub.py][line:116][INFO] ---------------epoch 80---------------
lr: [0.00022452713552088455]
[2024-10-29 08:18:37,169][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.278253233480838
[2024-10-29 08:21:24,514][train_sub.py][line:219][INFO] test_acc:0.9868179559707642,test_err:0.038784039447183276
[2024-10-29 08:21:24,516][train_sub.py][line:116][INFO] ---------------epoch 81---------------
lr: [0.00021933629382646835]
[2024-10-29 08:21:24,516][train_sub.py][line:122][INFO] cluster starts
[2024-10-29 08:24:21,127][train_sub.py][line:125][INFO] cluster ends
[2024-10-29 08:33:31,859][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 4.58270235471828
[2024-10-29 08:36:19,848][train_sub.py][line:219][INFO] test_acc:0.9871264696121216,test_err:0.04293094000964355
[2024-10-29 08:36:19,850][train_sub.py][line:116][INFO] ---------------epoch 82---------------
lr: [0.0002141591672887178]
[2024-10-29 08:45:30,537][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.4800475355117553
[2024-10-29 08:48:19,207][train_sub.py][line:219][INFO] test_acc:0.9896857142448425,test_err:0.03326747012495186
[2024-10-29 08:48:19,209][train_sub.py][line:116][INFO] ---------------epoch 83---------------
lr: [0.00020899802669032414]
[2024-10-29 08:57:29,926][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.7779804830269147
[2024-10-29 09:00:17,702][train_sub.py][line:219][INFO] test_acc:0.9697163105010986,test_err:0.08807355553157106
[2024-10-29 09:00:17,704][train_sub.py][line:116][INFO] ---------------epoch 84---------------
lr: [0.00020385513579841013]
[2024-10-29 09:09:28,473][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.555327100619193
[2024-10-29 09:12:15,740][train_sub.py][line:219][INFO] test_acc:0.9524534344673157,test_err:0.15075687629086065
[2024-10-29 09:12:15,742][train_sub.py][line:116][INFO] ---------------epoch 85---------------
lr: [0.00019873275037131643]
[2024-10-29 09:21:26,439][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.435841782278912
[2024-10-29 09:24:15,302][train_sub.py][line:219][INFO] test_acc:0.9795327186584473,test_err:0.058566124396395844
[2024-10-29 09:24:15,304][train_sub.py][line:116][INFO] ---------------epoch 86---------------
lr: [0.00019363311716887293]
[2024-10-29 09:33:26,094][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.360706419553808
[2024-10-29 09:36:13,838][train_sub.py][line:219][INFO] test_acc:0.9995512366294861,test_err:0.0021692990990867587
[2024-10-29 09:36:13,961][train_sub.py][line:116][INFO] ---------------epoch 87---------------
lr: [0.00018855847296659863]
