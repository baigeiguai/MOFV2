[2024-09-12 10:45:55,446][train.py][line:68][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0', train_name='BackViT', model_path=None, learning_rate=0.0005, min_learning_rate=1e-06, start_scheduler_step=0, weight_decay=1e-06, momentum=0.99, batch_size=256, class_num=230, epoch_num=200, model_save_path='/data/ylh/MyExps/MOFV2/checkpoints/BackViT', device='1,3,5,7', scheduler_T=None, num_workers=20, log_name='log/train//train_BackViT_2024_09_12_10:45:49.log')
[2024-09-12 10:45:55,450][train.py][line:69][INFO] ---------------model---------------
DataParallel(
  (module): RetryViT(
    (project): Linear(in_features=40, out_features=128, bias=True)
    (transformers): TransformerEncoder(
      (positionEnbeding): PositionEmbedding()
      (encoder_layers): ModuleList(
        (0-31): 32 x EncoderLayer(
          (mha): MultiHeadAttention(
            (WQ): Linear(in_features=128, out_features=128, bias=True)
            (WK): Linear(in_features=128, out_features=128, bias=True)
            (WV): Linear(in_features=128, out_features=128, bias=True)
            (scaled_dot_product_attn): ScaledDotProductAttention()
            (linear): Linear(in_features=128, out_features=128, bias=True)
          )
          (dropout1): Dropout(p=0, inplace=False)
          (layernorm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (ffn): FeedForwardNetwork(
            (linear1): Linear(in_features=128, out_features=512, bias=True)
            (linear2): Linear(in_features=512, out_features=128, bias=True)
            (relu): LeakyReLU(negative_slope=0.01)
          )
          (dropout2): Dropout(p=0, inplace=False)
          (layernorm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
    (cls): Linear(in_features=128, out_features=230, bias=True)
  )
)
[2024-09-12 10:45:55,450][train.py][line:70][INFO] ---------------device---------------
cuda:1
[2024-09-12 10:45:55,450][train.py][line:71][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 1e-06
)
[2024-09-12 10:45:55,450][train.py][line:72][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-09-12 10:45:55,450][train.py][line:73][INFO] ---------------seed---------------
3407
[2024-09-12 10:45:55,454][train.py][line:85][INFO] ---------------epoch 1---------------
lr: [0.0005]
[2024-09-12 10:51:47,809][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.8030340099501734
[2024-09-12 10:54:58,511][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.775227132486587,total_acc: 0.06608562916517258
[2024-09-12 10:54:59,184][train.py][line:85][INFO] ---------------epoch 2---------------
lr: [0.0004999384415069868]
[2024-09-12 11:00:49,194][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.776930847017652
[2024-09-12 11:03:47,657][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.775370041250974,total_acc: 0.06614172458648682
[2024-09-12 11:03:47,821][train.py][line:85][INFO] ---------------epoch 3---------------
lr: [0.0004997845709043126]
[2024-09-12 11:08:53,820][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.7736689175908076
[2024-09-12 11:11:46,000][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.7719096657273647,total_acc: 0.06608562916517258
[2024-09-12 11:11:46,185][train.py][line:85][INFO] ---------------epoch 4---------------
lr: [0.0004995692082490166]
[2024-09-12 11:16:51,751][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.7690465963868043
[2024-09-12 11:19:42,636][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.7712561006930163,total_acc: 0.06493569910526276
[2024-09-12 11:19:42,801][train.py][line:85][INFO] ---------------epoch 5---------------
lr: [0.0004992924066757998]
[2024-09-12 11:24:52,204][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.770715740641445
[2024-09-12 11:27:46,132][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.7698670368896057,total_acc: 0.06538445502519608
[2024-09-12 11:27:46,308][train.py][line:85][INFO] ---------------epoch 6---------------
lr: [0.0004989542344784963]
[2024-09-12 11:32:56,232][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.76952217213953
[2024-09-12 11:35:53,428][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.7692836758969337,total_acc: 0.06608562916517258
[2024-09-12 11:35:53,602][train.py][line:85][INFO] ---------------epoch 7---------------
lr: [0.0004985547750932208]
[2024-09-12 11:41:01,353][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.773295896900932
[2024-09-12 11:43:52,452][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.7693604683917794,total_acc: 0.06614172458648682
[2024-09-12 11:43:52,460][train.py][line:85][INFO] ---------------epoch 8---------------
lr: [0.0004980941270777829]
[2024-09-12 11:48:58,519][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.7713469644770314
[2024-09-12 11:51:49,700][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.7701520038778433,total_acc: 0.06588228791952133
[2024-09-12 11:51:49,707][train.py][line:85][INFO] ---------------epoch 9---------------
lr: [0.0004975724040873667]
[2024-09-12 11:56:53,919][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.7686812931935965
[2024-09-12 11:59:44,409][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.76906393330068,total_acc: 0.06493569910526276
[2024-09-12 11:59:44,596][train.py][line:85][INFO] ---------------epoch 10---------------
lr: [0.0004969897348464891]
[2024-09-12 12:04:49,374][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.7701414750461613
[2024-09-12 12:07:39,382][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.7689807878484243,total_acc: 0.06588228791952133
[2024-09-12 12:07:39,546][train.py][line:85][INFO] ---------------epoch 11---------------
lr: [0.0004963462631172379]
[2024-09-12 12:12:44,161][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.767347871526528
[2024-09-12 12:15:34,796][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.7686637821631757,total_acc: 0.06608562916517258
[2024-09-12 12:15:34,963][train.py][line:85][INFO] ---------------epoch 12---------------
lr: [0.000495642147663799]
[2024-09-12 12:20:39,691][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.768782558457864
