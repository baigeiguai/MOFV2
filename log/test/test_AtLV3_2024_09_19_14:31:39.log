[2024-09-19 14:31:46,663][test.py][line:34][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped_Short/0/', batch_size=128, model_path='/data/ylh/MyExps/MOFV2/checkpoints/AtLV3/AtLV3_epoch_44.pth', device='2', mode='test', top_k=5, parallel_model=False, test_name='AtLV3', num_workers=20, log_name='log/test/test_AtLV3_2024_09_19_14:31:39.log')
[2024-09-19 14:31:46,665][test.py][line:35][INFO] ---------------model---------------
AtLV3(
  (embed): Embedding(851, 63)
  (att): TransformerEncoder(
    (positionEnbeding): PositionEmbedding()
    (encoder_layers): ModuleList(
      (0-15): 16 x EncoderLayer(
        (mha): MultiHeadAttention(
          (WQ): Linear(in_features=64, out_features=64, bias=True)
          (WK): Linear(in_features=64, out_features=64, bias=True)
          (WV): Linear(in_features=64, out_features=64, bias=True)
          (scaled_dot_product_attn): ScaledDotProductAttention()
          (linear): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0, inplace=False)
        (layernorm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (ffn): FeedForwardNetwork(
          (linear1): Linear(in_features=64, out_features=512, bias=True)
          (linear2): Linear(in_features=512, out_features=64, bias=True)
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (dropout2): Dropout(p=0, inplace=False)
        (layernorm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=64, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=230, bias=True)
  )
)
[2024-09-19 14:31:46,665][test.py][line:36][INFO] ---------------device---------------
cuda:2
[2024-09-19 14:31:46,665][test.py][line:37][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-09-19 14:38:11,422][test.py][line:78][INFO] ---------------performance---------------
total_num:142729
error:2.674048
total_acc:0.33937743306159973
f1_score:0.18905290961265564
top5_acc:0.7245128750801086
head_acc:0.3721426012962312
medium_acc:0.2212849599036783
tail_add:0.18042219139079937

[2024-09-19 14:38:11,423][test.py][line:89][INFO] ---------------per_class_acc---------------
[0.3528825, 0.38933644, 0.013157895, 0.3473332, 0.34978876, 0.055555556, 0.11878339, 0.07386363, 0.4322019, 0.032786883, 0.15686275, 0.14269912, 0.09810037, 0.387439, 0.40016973, 0.65217394, 0.0, 0.22113594, 0.59457433, 0.1487965, 0.0, 0.0, 0.19685039, 0.0, 0.0, 0.065789476, 0.11764706, 0.0, 0.26914662, 0.028169014, 0.0942029, 0.0, 0.27104446, 0.08387097, 0.0, 0.2017291, 0.0, 0.09090909, 0.0, 0.1122449, 0.0, 0.078947365, 0.21897407, 0.054054055, 0.08945687, 0.125, 0.26666668, 0.054054055, 0.0, 0.16666667, 0.0, 0.17597292, 0.14084508, 0.01171875, 0.03311258, 0.08840656, 0.046277665, 0.14971751, 0.015037594, 0.27228272, 0.5433163, 0.36153847, 0.13097712, 0.0, 0.19417475, 0.07575758, 0.0, 0.0, 0.15873016, 0.24829932, 0.041666668, 0.13023256, 0.006369427, 0.2027972, 0.0, 0.13347457, 0.032258064, 0.18527316, 0.014925373, 0.03937008, 0.060344826, 0.3385269, 0.0, 0.0, 0.17594655, 0.12912913, 0.1468144, 0.34986946, 0.0, 0.115384616, 0.022222223, 0.25562373, 0.0, 0.13207547, 0.021276595, 0.12176724, 0.0625, 0.49019608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16393442, 1.0, 0.0, 0.0, 0.0, 0.04347826, 0.09859155, 0.0, 0.0, 0.2086331, 0.1696, 0.0, 0.0952381, 0.18181819, 0.15957446, 0.0, 0.035714287, 0.13793103, 0.07536232, 0.5, 0.34042552, 0.4, 0.15178572, 0.0, 0.35164836, 0.2247191, 0.18292683, 0.4, 0.1, 0.0, 0.10714286, 0.04, 0.14130434, 0.03508772, 0.10958904, 0.14782609, 0.2361111, 0.13492064, 0.22344323, 0.20175439, 0.21907216, 0.3316062, 0.2877095, 0.36142626, 0.547828, 0.33333334, 0.018518519, 0.0, 0.13457558, 0.0, 0.21465969, 0.16465864, 0.0, 0.0, 0.07692308, 0.08648649, 0.234375, 0.22093023, 0.13793103, 0.34979424, 0.24489796, 0.3012987, 0.38658148, 0.32456142, 0.0, 0.16338028, 0.17867436, 0.025, 0.032258064, 0.19125684, 0.0625, 0.20833333, 0.18592964, 0.53333336, 0.20408164, 0.072, 0.05, 0.08, 0.2783505, 0.0, 0.0, 0.0, 0.083333336, 0.45454547, 0.0, 0.13636364, 0.045454547, 0.3181818, 0.6101695, 0.05263158, 0.3038674, 0.0, 0.39655173, 0.5119048, 0.6438356, 0.41791046, 0.23076923, 0.08, 0.20833333, 0.36363637, 0.234375, 0.78088576, 0.22535211, 0.15384616, 0.0, 0.2857143, 0.38709676, 0.55172414, 0.20833333, 0.18181819, 0.14285715, 0.0, 0.09090909, 0.5766871, 0.52112675, 0.25, 0.67808217, 0.4488189, 0.41025642, 0.34210527, 0.3125, 0.8147059, 0.35714287, 0.57954544, 0.4027778, 0.22727273, 0.3559322]
