[2024-07-02 16:50:29,412][train.py][line:70][INFO] ---------------args---------------
Namespace(data_path='../MOF/data/Pymatgen_Wrapped/1/', train_name='ResTcn_8500', model_path=None, learning_rate=0.0001, min_learning_rate=1e-05, start_scheduler_step=50, weight_decay=1e-05, momentum=0.99, batch_size=256, class_num=230, epoch_num=200, model_save_path='./checkpoints/ResTcn_8500_2', device='3', scheduler_T=None, num_workers=20, log_name='log/train//train_ResTcn_8500_2024_07_02_16:50:27.log')
[2024-07-02 16:50:29,414][train.py][line:71][INFO] ---------------model---------------
ResTcn(
  (conv): ModuleList(
    (0): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(2, 32, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (1): Sequential(
      (0): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (2): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (3): Sequential(
      (0): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (4): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (5): Sequential(
      (0): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (6): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (7): Sequential(
      (0): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (8): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (9): Sequential(
      (0): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (10): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (11-12): 2 x Sequential(
      (0): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
  )
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): Linear(in_features=512, out_features=230, bias=True)
  )
)
[2024-07-02 16:50:29,414][train.py][line:72][INFO] ---------------device---------------
cuda:3
[2024-07-02 16:50:29,415][train.py][line:73][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 1e-05
)
[2024-07-02 16:50:29,415][train.py][line:74][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-07-02 16:50:29,415][train.py][line:75][INFO] ---------------seed---------------
15381969818975641440
[2024-07-02 16:50:29,420][train.py][line:87][INFO] ---------------epoch 1---------------
lr: [0.0001]
[2024-07-02 16:51:47,368][train.py][line:105][INFO] [training]total_num: 142617.0,error: 3.1297853084871523
[2024-07-02 16:52:29,809][train.py][line:143][INFO] [testing]total_number: 142617,error: 11.787030584131564,total_acc: 0.004522602539509535
[2024-07-02 16:52:30,096][train.py][line:87][INFO] ---------------epoch 2---------------
lr: [0.0001]
[2024-07-02 16:53:57,573][train.py][line:105][INFO] [training]total_num: 142617.0,error: 2.6364453682339963
[2024-07-02 16:54:47,505][train.py][line:143][INFO] [testing]total_number: 142617,error: 35.47875255377614,total_acc: 0.04588513448834419
[2024-07-02 16:55:28,932][train.py][line:87][INFO] ---------------epoch 3---------------
lr: [0.0001]
[2024-07-02 16:56:51,663][train.py][line:105][INFO] [training]total_num: 142617.0,error: 2.427582157054841
[2024-07-02 16:57:42,119][train.py][line:143][INFO] [testing]total_number: 142617,error: 12.467978146781855,total_acc: 0.0032254219986498356
[2024-07-02 16:57:42,124][train.py][line:87][INFO] ---------------epoch 4---------------
lr: [0.0001]
[2024-07-02 16:59:06,152][train.py][line:105][INFO] [training]total_num: 142617.0,error: 2.2658334774227775
[2024-07-02 16:59:53,850][train.py][line:143][INFO] [testing]total_number: 142617,error: 81.95559154583987,total_acc: 0.06665404886007309
[2024-07-02 17:00:00,034][train.py][line:87][INFO] ---------------epoch 5---------------
lr: [0.0001]
[2024-07-02 17:01:18,535][train.py][line:105][INFO] [training]total_num: 142617.0,error: 2.1932668600316223
[2024-07-02 17:02:03,394][train.py][line:143][INFO] [testing]total_number: 142617,error: 5.379539870547747,total_acc: 0.03709936514496803
[2024-07-02 17:02:14,318][train.py][line:87][INFO] ---------------epoch 6---------------
lr: [0.0001]
[2024-07-02 17:03:34,211][train.py][line:105][INFO] [training]total_num: 142617.0,error: 2.08915015256551
[2024-07-02 17:04:19,231][train.py][line:143][INFO] [testing]total_number: 142617,error: 86.18147977972615,total_acc: 0.06551813334226608
[2024-07-02 17:04:19,236][train.py][line:87][INFO] ---------------epoch 7---------------
lr: [0.0001]
[2024-07-02 17:05:36,657][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.9879314742864953
[2024-07-02 17:06:21,854][train.py][line:143][INFO] [testing]total_number: 142617,error: 10.028991857886105,total_acc: 0.004782038740813732
[2024-07-02 17:06:21,859][train.py][line:87][INFO] ---------------epoch 8---------------
lr: [0.0001]
[2024-07-02 17:07:39,693][train.py][line:105][INFO] [training]total_num: 142617.0,error: 2.0544100166828536
[2024-07-02 17:08:25,037][train.py][line:143][INFO] [testing]total_number: 142617,error: 17.216885717027868,total_acc: 0.05180308222770691
[2024-07-02 17:08:25,041][train.py][line:87][INFO] ---------------epoch 9---------------
lr: [0.0001]
[2024-07-02 17:09:45,365][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.92530538467935
[2024-07-02 17:10:32,987][train.py][line:143][INFO] [testing]total_number: 142617,error: 12.092273647021079,total_acc: 0.013224230147898197
[2024-07-02 17:10:32,992][train.py][line:87][INFO] ---------------epoch 10---------------
lr: [0.0001]
[2024-07-02 17:11:55,858][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.8409937020984923
[2024-07-02 17:12:43,249][train.py][line:143][INFO] [testing]total_number: 142617,error: 60.4163670247574,total_acc: 0.002384007442742586
[2024-07-02 17:12:43,351][train.py][line:87][INFO] ---------------epoch 11---------------
lr: [0.0001]
[2024-07-02 17:14:00,879][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.7785033699509976
[2024-07-02 17:14:45,507][train.py][line:143][INFO] [testing]total_number: 142617,error: 8.964959888658674,total_acc: 0.0030220800545066595
[2024-07-02 17:14:45,511][train.py][line:87][INFO] ---------------epoch 12---------------
lr: [0.0001]
[2024-07-02 17:16:03,257][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.7272758074691958
[2024-07-02 17:16:48,507][train.py][line:143][INFO] [testing]total_number: 142617,error: 55.26206900067171,total_acc: 0.03518514707684517
[2024-07-02 17:16:48,511][train.py][line:87][INFO] ---------------epoch 13---------------
lr: [0.0001]
[2024-07-02 17:18:07,425][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.6577283999965822
[2024-07-02 17:18:53,654][train.py][line:143][INFO] [testing]total_number: 142617,error: 11.25497478445023,total_acc: 0.003281516255810857
[2024-07-02 17:18:53,659][train.py][line:87][INFO] ---------------epoch 14---------------
lr: [0.0001]
[2024-07-02 17:20:13,507][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.5907692341378608
[2024-07-02 17:21:02,344][train.py][line:143][INFO] [testing]total_number: 142617,error: 96.8607334731548,total_acc: 0.029666870832443237
[2024-07-02 17:21:02,348][train.py][line:87][INFO] ---------------epoch 15---------------
lr: [0.0001]
[2024-07-02 17:22:20,937][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.5592479935460666
[2024-07-02 17:23:07,622][train.py][line:143][INFO] [testing]total_number: 142617,error: 69.45116327021877,total_acc: 0.0024891842622309923
[2024-07-02 17:23:07,627][train.py][line:87][INFO] ---------------epoch 16---------------
lr: [0.0001]
[2024-07-02 17:24:25,674][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.5146784229161652
[2024-07-02 17:25:10,973][train.py][line:143][INFO] [testing]total_number: 142617,error: 28.74615868336265,total_acc: 0.019008953124284744
[2024-07-02 17:25:10,977][train.py][line:87][INFO] ---------------epoch 17---------------
lr: [0.0001]
[2024-07-02 17:26:29,272][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.434024613709458
[2024-07-02 17:27:14,118][train.py][line:143][INFO] [testing]total_number: 142617,error: 153.73012458547402,total_acc: 0.006331643555313349
[2024-07-02 17:27:14,123][train.py][line:87][INFO] ---------------epoch 18---------------
lr: [0.0001]
[2024-07-02 17:28:30,402][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.419773936897986
[2024-07-02 17:29:16,596][train.py][line:143][INFO] [testing]total_number: 142617,error: 9.687424631335897,total_acc: 0.0030220800545066595
[2024-07-02 17:29:16,600][train.py][line:87][INFO] ---------------epoch 19---------------
lr: [0.0001]
[2024-07-02 17:30:33,612][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.5552228522175457
[2024-07-02 17:31:17,918][train.py][line:143][INFO] [testing]total_number: 142617,error: 49.365758925937314,total_acc: 0.014710729010403156
[2024-07-02 17:31:17,922][train.py][line:87][INFO] ---------------epoch 20---------------
lr: [0.0001]
[2024-07-02 17:32:34,488][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.448832630067281
[2024-07-02 17:33:23,826][train.py][line:143][INFO] [testing]total_number: 142617,error: 75.22147325960016,total_acc: 0.03514307364821434
[2024-07-02 17:33:23,916][train.py][line:87][INFO] ---------------epoch 21---------------
lr: [0.0001]
[2024-07-02 17:34:45,291][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.3906021349901911
[2024-07-02 17:35:31,562][train.py][line:143][INFO] [testing]total_number: 142617,error: 82.24417970727497,total_acc: 0.035009849816560745
[2024-07-02 17:35:31,569][train.py][line:87][INFO] ---------------epoch 22---------------
lr: [0.0001]
[2024-07-02 17:36:50,641][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.3167497982285694
[2024-07-02 17:37:38,426][train.py][line:143][INFO] [testing]total_number: 142617,error: 48.9624744221542,total_acc: 0.03514307364821434
[2024-07-02 17:37:38,432][train.py][line:87][INFO] ---------------epoch 23---------------
lr: [0.0001]
[2024-07-02 17:39:00,812][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.3628597396267692
[2024-07-02 17:39:46,820][train.py][line:143][INFO] [testing]total_number: 142617,error: 65.45582678105076,total_acc: 0.03553573414683342
[2024-07-02 17:39:46,824][train.py][line:87][INFO] ---------------epoch 24---------------
lr: [0.0001]
[2024-07-02 17:41:05,402][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.3750692549603625
[2024-07-02 17:41:52,091][train.py][line:143][INFO] [testing]total_number: 142617,error: 106.2099094023429,total_acc: 0.002384007442742586
[2024-07-02 17:41:52,098][train.py][line:87][INFO] ---------------epoch 25---------------
lr: [0.0001]
[2024-07-02 17:43:09,958][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.2854205696678829
[2024-07-02 17:43:59,324][train.py][line:143][INFO] [testing]total_number: 142617,error: 13.151420142312393,total_acc: 0.02747919224202633
[2024-07-02 17:43:59,328][train.py][line:87][INFO] ---------------epoch 26---------------
lr: [0.0001]
[2024-07-02 17:45:18,265][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.1670939607085782
[2024-07-02 17:46:02,760][train.py][line:143][INFO] [testing]total_number: 142617,error: 40.54538181324974,total_acc: 0.058338064700365067
[2024-07-02 17:46:02,764][train.py][line:87][INFO] ---------------epoch 27---------------
lr: [0.0001]
[2024-07-02 17:47:21,924][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.1924419664042216
[2024-07-02 17:48:09,347][train.py][line:143][INFO] [testing]total_number: 142617,error: 25.402984084682164,total_acc: 0.00784618966281414
[2024-07-02 17:48:09,405][train.py][line:87][INFO] ---------------epoch 28---------------
lr: [0.0001]
[2024-07-02 17:49:27,766][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.1392347366922582
[2024-07-02 17:50:16,234][train.py][line:143][INFO] [testing]total_number: 142617,error: 59.1901704751464,total_acc: 0.03856482729315758
[2024-07-02 17:50:16,243][train.py][line:87][INFO] ---------------epoch 29---------------
lr: [0.0001]
[2024-07-02 17:51:33,968][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.078500895178673
[2024-07-02 17:52:19,518][train.py][line:143][INFO] [testing]total_number: 142617,error: 19.65026740560181,total_acc: 0.030354024842381477
[2024-07-02 17:52:19,523][train.py][line:87][INFO] ---------------epoch 30---------------
lr: [0.0001]
[2024-07-02 17:53:37,837][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.0880297602997562
[2024-07-02 17:54:24,287][train.py][line:143][INFO] [testing]total_number: 142617,error: 22.716655061457914,total_acc: 0.03948337212204933
[2024-07-02 17:54:24,299][train.py][line:87][INFO] ---------------epoch 31---------------
lr: [0.0001]
[2024-07-02 17:55:42,822][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.0583306023828203
[2024-07-02 17:56:28,283][train.py][line:143][INFO] [testing]total_number: 142617,error: 48.96259838979424,total_acc: 0.03249261900782585
[2024-07-02 17:56:28,288][train.py][line:87][INFO] ---------------epoch 32---------------
lr: [0.0001]
[2024-07-02 17:57:48,359][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.0154767076104827
[2024-07-02 17:58:37,282][train.py][line:143][INFO] [testing]total_number: 142617,error: 26.952656406863557,total_acc: 0.021133525297045708
[2024-07-02 17:58:37,361][train.py][line:87][INFO] ---------------epoch 33---------------
lr: [0.0001]
[2024-07-02 17:59:57,275][train.py][line:105][INFO] [training]total_num: 142617.0,error: 1.0078450894397528
[2024-07-02 18:00:46,030][train.py][line:143][INFO] [testing]total_number: 142617,error: 34.21914678196147,total_acc: 0.02380501665174961
[2024-07-02 18:00:46,034][train.py][line:87][INFO] ---------------epoch 34---------------
lr: [0.0001]
[2024-07-02 18:02:06,694][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.9664366984325616
[2024-07-02 18:02:59,997][train.py][line:143][INFO] [testing]total_number: 142617,error: 54.46550925099495,total_acc: 0.036328066140413284
[2024-07-02 18:03:00,001][train.py][line:87][INFO] ---------------epoch 35---------------
lr: [0.0001]
[2024-07-02 18:04:21,816][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.9335932236836796
[2024-07-02 18:05:09,353][train.py][line:143][INFO] [testing]total_number: 142617,error: 40.98681125540658,total_acc: 0.031209463253617287
[2024-07-02 18:05:09,357][train.py][line:87][INFO] ---------------epoch 36---------------
lr: [0.0001]
[2024-07-02 18:06:30,343][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.9729409445396864
[2024-07-02 18:07:24,987][train.py][line:143][INFO] [testing]total_number: 142617,error: 14.395601192414238,total_acc: 0.03484858199954033
[2024-07-02 18:07:24,991][train.py][line:87][INFO] ---------------epoch 37---------------
lr: [0.0001]
[2024-07-02 18:08:46,515][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.9225518971733788
[2024-07-02 18:09:36,078][train.py][line:143][INFO] [testing]total_number: 142617,error: 39.76199819494671,total_acc: 0.02478666603565216
[2024-07-02 18:09:36,165][train.py][line:87][INFO] ---------------epoch 38---------------
lr: [0.0001]
[2024-07-02 18:10:58,099][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.8551649193421346
[2024-07-02 18:11:48,357][train.py][line:143][INFO] [testing]total_number: 142617,error: 58.58041655745899,total_acc: 0.03531135991215706
[2024-07-02 18:11:48,361][train.py][line:87][INFO] ---------------epoch 39---------------
lr: [0.0001]
[2024-07-02 18:13:10,025][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.8296446680709485
[2024-07-02 18:13:59,022][train.py][line:143][INFO] [testing]total_number: 142617,error: 14.031732973409408,total_acc: 0.041299425065517426
[2024-07-02 18:13:59,026][train.py][line:87][INFO] ---------------epoch 40---------------
lr: [0.0001]
[2024-07-02 18:15:22,793][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.8167495845495715
[2024-07-02 18:16:17,127][train.py][line:143][INFO] [testing]total_number: 142617,error: 55.87891241631449,total_acc: 0.03514307364821434
[2024-07-02 18:16:17,133][train.py][line:87][INFO] ---------------epoch 41---------------
lr: [0.0001]
[2024-07-02 18:17:40,864][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.793911151627108
[2024-07-02 18:18:29,270][train.py][line:143][INFO] [testing]total_number: 142617,error: 174.08004151459542,total_acc: 0.008344026282429695
[2024-07-02 18:18:29,274][train.py][line:87][INFO] ---------------epoch 42---------------
lr: [0.0001]
[2024-07-02 18:19:53,312][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.7676547910828933
[2024-07-02 18:20:44,416][train.py][line:143][INFO] [testing]total_number: 142617,error: 126.86625708798812,total_acc: 0.03445592150092125
[2024-07-02 18:20:44,420][train.py][line:87][INFO] ---------------epoch 43---------------
lr: [0.0001]
[2024-07-02 18:22:06,769][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.7873981101291609
[2024-07-02 18:22:56,560][train.py][line:143][INFO] [testing]total_number: 142617,error: 32.83251037196813,total_acc: 0.02530553936958313
[2024-07-02 18:22:56,565][train.py][line:87][INFO] ---------------epoch 44---------------
lr: [0.0001]
[2024-07-02 18:24:20,816][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.7328605139840088
[2024-07-02 18:25:10,388][train.py][line:143][INFO] [testing]total_number: 142617,error: 178.40917255247953,total_acc: 0.035122040659189224
[2024-07-02 18:25:10,392][train.py][line:87][INFO] ---------------epoch 45---------------
lr: [0.0001]
[2024-07-02 18:26:31,729][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.7579984822018552
[2024-07-02 18:27:19,453][train.py][line:143][INFO] [testing]total_number: 142617,error: 160.4682330316921,total_acc: 0.03510100394487381
[2024-07-02 18:27:19,535][train.py][line:87][INFO] ---------------epoch 46---------------
lr: [0.0001]
[2024-07-02 18:28:39,391][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.6800855196712313
[2024-07-02 18:29:25,669][train.py][line:143][INFO] [testing]total_number: 142617,error: 41.9547770645489,total_acc: 0.03524123877286911
[2024-07-02 18:29:25,673][train.py][line:87][INFO] ---------------epoch 47---------------
lr: [0.0001]
[2024-07-02 18:30:44,065][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.7065956093070803
[2024-07-02 18:31:43,125][train.py][line:143][INFO] [testing]total_number: 142617,error: 75.47563987772018,total_acc: 0.00986558385193348
[2024-07-02 18:31:43,191][train.py][line:87][INFO] ---------------epoch 48---------------
lr: [0.0001]
[2024-07-02 18:33:03,815][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.667436046483429
[2024-07-02 18:33:53,643][train.py][line:143][INFO] [testing]total_number: 142617,error: 81.81042733000373,total_acc: 0.020425334572792053
[2024-07-02 18:33:53,647][train.py][line:87][INFO] ---------------epoch 49---------------
lr: [0.0001]
[2024-07-02 18:35:13,528][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.649016049405113
[2024-07-02 18:36:03,789][train.py][line:143][INFO] [testing]total_number: 142617,error: 90.23284826596021,total_acc: 0.034925710409879684
[2024-07-02 18:36:03,794][train.py][line:87][INFO] ---------------epoch 50---------------
lr: [0.0001]
[2024-07-02 18:37:23,622][train.py][line:105][INFO] [training]total_num: 142617.0,error: 0.6412300223748864
[2024-07-02 18:38:08,252][train.py][line:143][INFO] [testing]total_number: 142617,error: 50.71513566119032,total_acc: 0.029645834118127823
[2024-07-02 18:38:08,257][train.py][line:87][INFO] ---------------epoch 51---------------
lr: [0.0001]
