[2024-10-15 15:58:20,523][train.py][line:85][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0', train_name='HopeV1_3Loss', model_path=None, learning_rate=0.0005, min_learning_rate=1e-06, start_scheduler_step=10, weight_decay=1e-06, momentum=0.99, batch_size=512, class_num=230, epoch_num=200, model_save_path='/data/ylh/MyExps/MOFV2/checkpoints/HopeV1_3Loss', device='0,1,2,3', scheduler_T=None, num_workers=20, log_name='log/train//train_HopeV1_3Loss_2024_10_15_15:58:16.log')
[2024-10-15 15:58:20,525][train.py][line:86][INFO] ---------------model---------------
DataParallel(
  (module): HopeV1(
    (conv_module): ResTcn(
      (intensity_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (TCN): Sequential(
        (0): ResBlock1D(
          (pre): Conv1d(2, 32, kernel_size=(1,), stride=(1,), bias=False)
          (conv): Sequential(
            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (2): ResBlock1D(
          (pre): Identity()
          (conv): Sequential(
            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (4): ResBlock1D(
          (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
          (conv): Sequential(
            (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): ResBlock1D(
          (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
          (conv): Sequential(
            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (8): ResBlock1D(
          (pre): Identity()
          (conv): Sequential(
            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
        (10): ResBlock1D(
          (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
          (conv): Sequential(
            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
        (12): ResBlock1D(
          (pre): Identity()
          (conv): Sequential(
            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
        (14): ResBlock1D(
          (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
          (conv): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
        (16): ResBlock1D(
          (pre): Identity()
          (conv): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
        (18): ResBlock1D(
          (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
          (conv): Sequential(
            (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
        (20): Dropout(p=0.2, inplace=False)
        (21): ResBlock1D(
          (pre): Identity()
          (conv): Sequential(
            (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (22): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
        (23): Dropout(p=0.2, inplace=False)
        (24): ResBlock1D(
          (pre): Identity()
          (conv): Sequential(
            (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (25): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
        (26): Dropout(p=0.2, inplace=False)
        (27): ResBlock1D(
          (pre): Identity()
          (conv): Sequential(
            (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (28): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
        (29): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (att): AttentionModule(
      (embed): Embedding(850, 15)
      (patch_conv): PatchConvModule(
        (conv): Sequential(
          (0): Conv2d(1, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (1): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
          (2): Conv2d(2, 4, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (3): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
          (4): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (5): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
          (6): Conv2d(8, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (7): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
        )
      )
      (att): TransformerEncoder(
        (positionEnbeding): PositionEmbedding()
        (encoder_layers): ModuleList(
          (0-7): 8 x EncoderLayer(
            (mha): MultiHeadAttention(
              (WQ): Linear(in_features=32, out_features=32, bias=True)
              (WK): Linear(in_features=32, out_features=32, bias=True)
              (WV): Linear(in_features=32, out_features=32, bias=True)
              (scaled_dot_product_attn): ScaledDotProductAttention()
              (linear): Linear(in_features=32, out_features=32, bias=True)
            )
            (dropout1): Dropout(p=0.2, inplace=False)
            (layernorm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
            (ffn): FeedForwardNetwork(
              (linear1): Linear(in_features=32, out_features=256, bias=True)
              (linear2): Linear(in_features=256, out_features=32, bias=True)
              (relu): LeakyReLU(negative_slope=0.01)
            )
            (dropout2): Dropout(p=0.2, inplace=False)
            (layernorm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          )
        )
      )
    )
    (cls_sp): Sequential(
      (0): Linear(in_features=1056, out_features=512, bias=True)
      (1): Linear(in_features=512, out_features=230, bias=True)
    )
    (cls_cs): Sequential(
      (0): Linear(in_features=1056, out_features=256, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=256, out_features=64, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=64, out_features=7, bias=True)
    )
    (cls_lt): Sequential(
      (0): Linear(in_features=1056, out_features=256, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=256, out_features=64, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=64, out_features=6, bias=True)
    )
  )
)
[2024-10-15 15:58:20,526][train.py][line:87][INFO] ---------------device---------------
cuda:0
[2024-10-15 15:58:20,526][train.py][line:88][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 1e-06
)
[2024-10-15 15:58:20,526][train.py][line:89][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-10-15 15:58:20,526][train.py][line:90][INFO] ---------------seed---------------
3407
[2024-10-15 15:58:20,543][train.py][line:102][INFO] ---------------epoch 1---------------
lr: [0.0005]
[2024-10-15 16:02:24,806][train.py][line:130][INFO] [training]total_num: 142618.0,error: 250.32768593468032,error_sp: 3.201390131370171,error_cs: 1.0859329623359066,error_lt: 1.7310838691004506
[2024-10-15 16:04:34,652][train.py][line:171][INFO] [testing]total_number: 142618,error: 4.9672278274189345,total_acc: 0.04966413602232933
[2024-10-15 16:04:35,546][train.py][line:102][INFO] ---------------epoch 2---------------
lr: [0.0005]
[2024-10-15 16:08:34,453][train.py][line:130][INFO] [training]total_num: 142618.0,error: 251.52660436730284,error_sp: 2.5836476179269643,error_cs: 0.8248165662472065,error_lt: 1.7430566916098962
[2024-10-15 16:10:49,093][train.py][line:171][INFO] [testing]total_number: 142618,error: 7.863641467127767,total_acc: 0.04611619934439659
[2024-10-15 16:10:49,143][train.py][line:102][INFO] ---------------epoch 3---------------
lr: [0.0005]
