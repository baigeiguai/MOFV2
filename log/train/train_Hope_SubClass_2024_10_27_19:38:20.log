[2024-10-27 19:38:26,988][train_sub.py][line:56][INFO] cls num list:[5013 9433   75 9261 4497   18 2432  175 5626   61 2345  903 3526 9425
 9425   22   38 2148 9325  913   31   18  126   33    2   75   17    8
 4112   70  275   89 7400  155    5  694   58   21    0   98    0   38
 1812   36  313   72   15   37   10   54   26  590   70  256  151 1888
  496  353  133 4498 9396 5199  481    0  102   66    0    0   62  588
   72  214  157  143   28  472   61  421  133  126  116  705   16   47
  449  666  360 1914    3   51   45  978    4  105   46  927   47  101
    1    3    3   13   17   60    1   53   11   18   23  213    2   17
  138  624    3   20   32   94   16   55   87  344   78   47   30  112
   20   91   88  246   70   10   25   28   49   92   56   73  115   72
  126  273  113  388  385  715  617 4443    6   54   13  483   11  381
  249    2    9   51  185  128  516   29  242   48  384  312  912   12
  355  346   40   30  365   16   23  397   15  146  125   40   24   96
    1    7   18   47   21    7   22   88   65   59   38  181   10   57
   83  292   67   12   25   23   54   64  428   70   13    2   35   30
   29   24   33   14   21   21  163   70   48  146  127   77   38   16
  340   41   88   71   22   58]
[2024-10-27 19:38:26,992][train_sub.py][line:70][INFO] cluster_number:[25, 47, 1, 46, 22, 1, 12, 1, 28, 1, 11, 4, 17, 47, 47, 1, 1, 10, 46, 4, 1, 1, 1, 1, 1, 1, 1, 1, 20, 1, 1, 1, 37, 1, 1, 3, 1, 1, 0, 1, 0, 1, 9, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 9, 2, 1, 1, 22, 46, 25, 2, 0, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 2, 3, 1, 9, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 22, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
[2024-10-27 19:38:29,676][train_sub.py][line:100][INFO] ---------------args---------------
Namespace(data_path='/data/ylh/MyExps/MOFV2/data/All_Wrapped', train_name='Hope_SubClass', model_path=None, learning_rate=0.0005, min_learning_rate=1e-05, start_scheduler_step=0, weight_decay=4e-05, momentum=0.99, batch_size=256, class_num=230, epoch_num=150, model_save_path='/data/ylh/MyExps/MOFV2/checkpoints/Hope_SubClass', device='3', scheduler_T=None, num_workers=20, cluster_limit=200, warm_epoch=10, epoch_step=10, log_name='log/train//train_Hope_SubClass_2024_10_27_19:38:20.log', cls_num_list=array([5013, 9433,   75, 9261, 4497,   18, 2432,  175, 5626,   61, 2345,
        903, 3526, 9425, 9425,   22,   38, 2148, 9325,  913,   31,   18,
        126,   33,    2,   75,   17,    8, 4112,   70,  275,   89, 7400,
        155,    5,  694,   58,   21,    0,   98,    0,   38, 1812,   36,
        313,   72,   15,   37,   10,   54,   26,  590,   70,  256,  151,
       1888,  496,  353,  133, 4498, 9396, 5199,  481,    0,  102,   66,
          0,    0,   62,  588,   72,  214,  157,  143,   28,  472,   61,
        421,  133,  126,  116,  705,   16,   47,  449,  666,  360, 1914,
          3,   51,   45,  978,    4,  105,   46,  927,   47,  101,    1,
          3,    3,   13,   17,   60,    1,   53,   11,   18,   23,  213,
          2,   17,  138,  624,    3,   20,   32,   94,   16,   55,   87,
        344,   78,   47,   30,  112,   20,   91,   88,  246,   70,   10,
         25,   28,   49,   92,   56,   73,  115,   72,  126,  273,  113,
        388,  385,  715,  617, 4443,    6,   54,   13,  483,   11,  381,
        249,    2,    9,   51,  185,  128,  516,   29,  242,   48,  384,
        312,  912,   12,  355,  346,   40,   30,  365,   16,   23,  397,
         15,  146,  125,   40,   24,   96,    1,    7,   18,   47,   21,
          7,   22,   88,   65,   59,   38,  181,   10,   57,   83,  292,
         67,   12,   25,   23,   54,   64,  428,   70,   13,    2,   35,
         30,   29,   24,   33,   14,   21,   21,  163,   70,   48,  146,
        127,   77,   38,   16,  340,   41,   88,   71,   22,   58]))
[2024-10-27 19:38:29,678][train_sub.py][line:101][INFO] ---------------model---------------
HopeV1_Sub(
  (conv_module): ResTcn(
    (intensity_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (TCN): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(2, 32, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (2): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (10): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (12): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (14): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (16): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (18): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (20): Dropout(p=0.25, inplace=False)
      (21): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (22): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (23): Dropout(p=0.25, inplace=False)
      (24): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (25): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (26): Dropout(p=0.25, inplace=False)
      (27): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (28): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (29): Flatten(start_dim=1, end_dim=-1)
    )
  )
  (att): AttentionModule(
    (embed): Embedding(850, 15)
    (patch_conv): PatchConvModule(
      (conv): Sequential(
        (0): Conv2d(1, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (1): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
        (2): Conv2d(2, 4, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (3): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
        (4): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (5): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
        (6): Conv2d(8, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
      )
    )
    (att): TransformerEncoder(
      (positionEnbeding): PositionEmbedding()
      (encoder_layers): ModuleList(
        (0-7): 8 x EncoderLayer(
          (mha): MultiHeadAttention(
            (WQ): Linear(in_features=32, out_features=32, bias=True)
            (WK): Linear(in_features=32, out_features=32, bias=True)
            (WV): Linear(in_features=32, out_features=32, bias=True)
            (scaled_dot_product_attn): ScaledDotProductAttention()
            (linear): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout1): Dropout(p=0.25, inplace=False)
          (layernorm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (ffn): FeedForwardNetwork(
            (linear1): Linear(in_features=32, out_features=256, bias=True)
            (linear2): Linear(in_features=256, out_features=32, bias=True)
            (relu): LeakyReLU(negative_slope=0.01)
          )
          (dropout2): Dropout(p=0.25, inplace=False)
          (layernorm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
  )
  (projection): Sequential(
    (0): Linear(in_features=1056, out_features=512, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=512, out_features=256, bias=True)
  )
  (sp_cls): Sequential(
    (0): Linear(in_features=256, out_features=230, bias=True)
  )
  (cluster_cls): Sequential(
    (0): Linear(in_features=256, out_features=798, bias=True)
  )
)
[2024-10-27 19:38:29,678][train_sub.py][line:102][INFO] ---------------device---------------
cuda:3
[2024-10-27 19:38:29,678][train_sub.py][line:103][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 4e-05
)
[2024-10-27 19:38:29,678][train_sub.py][line:104][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-10-27 19:38:29,678][train_sub.py][line:105][INFO] ---------------seed---------------
3407
[2024-10-27 19:38:29,681][train_sub.py][line:116][INFO] ---------------epoch 1---------------
lr: [0.0005]
[2024-10-27 19:55:28,304][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 3.013585076964457
[2024-10-27 20:00:42,515][train_sub.py][line:219][INFO] test_acc:0.03107602149248123,test_err:5.742694141616958
[2024-10-27 20:00:43,413][train_sub.py][line:116][INFO] ---------------epoch 2---------------
lr: [0.0004998925407948922]
[2024-10-27 20:17:32,576][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.196672746143888
[2024-10-27 20:22:47,191][train_sub.py][line:219][INFO] test_acc:0.07489938288927078,test_err:4.084004266928601
[2024-10-27 20:22:47,589][train_sub.py][line:116][INFO] ---------------epoch 3---------------
lr: [0.000499623972317373]
[2024-10-27 20:39:43,593][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.949513591959485
[2024-10-27 20:44:59,404][train_sub.py][line:219][INFO] test_acc:0.0466911606490612,test_err:6.10221676907659
[2024-10-27 20:44:59,407][train_sub.py][line:116][INFO] ---------------epoch 4---------------
lr: [0.0004992481507964722]
[2024-10-27 21:01:55,974][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.7898626780424494
[2024-10-27 21:07:10,478][train_sub.py][line:219][INFO] test_acc:0.14475031197071075,test_err:3.691045532730745
[2024-10-27 21:07:10,863][train_sub.py][line:116][INFO] ---------------epoch 5---------------
lr: [0.0004987652410644177]
[2024-10-27 21:24:10,797][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.6750530985093885
[2024-10-27 21:29:25,031][train_sub.py][line:219][INFO] test_acc:0.06703221052885056,test_err:6.341145035293367
[2024-10-27 21:29:25,034][train_sub.py][line:116][INFO] ---------------epoch 6---------------
lr: [0.0004981754549258537]
[2024-10-27 21:46:27,211][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.5579787770479812
[2024-10-27 21:51:39,667][train_sub.py][line:219][INFO] test_acc:0.06516709178686142,test_err:6.112000601853521
[2024-10-27 21:51:39,670][train_sub.py][line:116][INFO] ---------------epoch 7---------------
lr: [0.0004974790510649301]
[2024-10-27 22:08:40,129][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.4674267860723653
[2024-10-27 22:13:52,155][train_sub.py][line:219][INFO] test_acc:0.3845377266407013,test_err:2.140209123812696
[2024-10-27 22:13:52,539][train_sub.py][line:116][INFO] ---------------epoch 8---------------
lr: [0.0004966763349318275]
[2024-10-27 22:30:54,379][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.4005918844626368
[2024-10-27 22:36:08,481][train_sub.py][line:219][INFO] test_acc:0.4601803421974182,test_err:1.77569331234074
[2024-10-27 22:36:08,868][train_sub.py][line:116][INFO] ---------------epoch 9---------------
lr: [0.0004957676586087712]
[2024-10-27 22:53:06,357][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.3254439879916475
[2024-10-27 22:58:20,982][train_sub.py][line:219][INFO] test_acc:0.1435442864894867,test_err:4.673726983501919
[2024-10-27 22:58:20,985][train_sub.py][line:116][INFO] ---------------epoch 10---------------
lr: [0.0004947534206555874]
[2024-10-27 23:15:20,724][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.2550168578983636
[2024-10-27 23:20:34,976][train_sub.py][line:219][INFO] test_acc:0.4776746332645416,test_err:1.7899095945354004
[2024-10-27 23:20:35,344][train_sub.py][line:116][INFO] ---------------epoch 11---------------
lr: [0.0004936340659348761]
[2024-10-27 23:20:35,344][train_sub.py][line:122][INFO] cluster starts
[2024-10-27 23:26:00,046][train_sub.py][line:125][INFO] cluster ends
[2024-10-27 23:43:01,348][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 4.3722804613865405
[2024-10-27 23:48:17,436][train_sub.py][line:219][INFO] test_acc:0.4176892042160034,test_err:2.127621134255736
[2024-10-27 23:48:17,439][train_sub.py][line:116][INFO] ---------------epoch 12---------------
lr: [0.0004924100854168722]
[2024-10-28 00:05:17,427][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 3.474304961474566
[2024-10-28 00:10:32,521][train_sub.py][line:219][INFO] test_acc:0.3230237364768982,test_err:2.5243258148992576
[2024-10-28 00:10:32,524][train_sub.py][line:116][INFO] ---------------epoch 13---------------
lr: [0.0004910820159640824]
[2024-10-28 00:27:36,258][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 3.2201674642528686
[2024-10-28 00:32:49,529][train_sub.py][line:219][INFO] test_acc:0.4449368119239807,test_err:1.9262760509352959
[2024-10-28 00:32:49,532][train_sub.py][line:116][INFO] ---------------epoch 14---------------
lr: [0.0004896504400957924]
[2024-10-28 00:49:51,964][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 3.0588875641532267
[2024-10-28 00:55:07,353][train_sub.py][line:219][INFO] test_acc:0.5964674949645996,test_err:1.28149824974037
[2024-10-28 00:55:07,745][train_sub.py][line:116][INFO] ---------------epoch 15---------------
lr: [0.00048811598573254687]
[2024-10-28 01:12:06,611][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.9199331028914366
[2024-10-28 01:17:18,999][train_sub.py][line:219][INFO] test_acc:0.26371145248413086,test_err:3.13654301024466
[2024-10-28 01:17:19,002][train_sub.py][line:116][INFO] ---------------epoch 16---------------
lr: [0.00048647932592071696]
[2024-10-28 01:34:22,588][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.840126901117277
[2024-10-28 01:39:35,572][train_sub.py][line:219][INFO] test_acc:0.5295825004577637,test_err:1.5110154368891298
[2024-10-28 01:39:35,575][train_sub.py][line:116][INFO] ---------------epoch 17---------------
lr: [0.0004847411785372695]
[2024-10-28 01:56:35,976][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.727274041022024
[2024-10-28 02:01:49,727][train_sub.py][line:219][INFO] test_acc:0.7297606468200684,test_err:0.8363234199396599
[2024-10-28 02:01:50,294][train_sub.py][line:116][INFO] ---------------epoch 18---------------
lr: [0.0004829023059748772]
[2024-10-28 02:18:51,552][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.644836187362671
[2024-10-28 02:24:02,656][train_sub.py][line:219][INFO] test_acc:0.6856077313423157,test_err:0.954233719396495
[2024-10-28 02:24:02,660][train_sub.py][line:116][INFO] ---------------epoch 19---------------
lr: [0.0004809635148074989]
[2024-10-28 02:41:03,716][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.5624438340518636
[2024-10-28 02:46:19,591][train_sub.py][line:219][INFO] test_acc:0.671394944190979,test_err:1.002714053343808
[2024-10-28 02:46:19,594][train_sub.py][line:116][INFO] ---------------epoch 20---------------
lr: [0.0004789256554365818]
[2024-10-28 03:03:17,242][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.4926387857792625
[2024-10-28 03:08:32,490][train_sub.py][line:219][INFO] test_acc:0.6450518369674683,test_err:1.1157902809774576
[2024-10-28 03:08:32,493][train_sub.py][line:116][INFO] ---------------epoch 21---------------
lr: [0.0004767896217180387]
[2024-10-28 03:08:32,493][train_sub.py][line:122][INFO] cluster starts
[2024-10-28 03:13:56,165][train_sub.py][line:125][INFO] cluster ends
[2024-10-28 03:31:00,564][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 3.234747211565681
[2024-10-28 03:36:13,205][train_sub.py][line:219][INFO] test_acc:0.7178196310997009,test_err:0.8695551762390735
[2024-10-28 03:36:13,208][train_sub.py][line:116][INFO] ---------------epoch 22---------------
lr: [0.0004745563505701653]
[2024-10-28 03:53:14,174][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.4464461737208896
[2024-10-28 03:58:28,963][train_sub.py][line:219][INFO] test_acc:0.2662777602672577,test_err:3.652881584554163
[2024-10-28 03:58:28,966][train_sub.py][line:116][INFO] ---------------epoch 23---------------
lr: [0.00047222682156266736]
[2024-10-28 04:15:29,111][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.2951027238240806
[2024-10-28 04:20:44,558][train_sub.py][line:219][INFO] test_acc:0.5678245425224304,test_err:1.469692000348161
[2024-10-28 04:20:44,561][train_sub.py][line:116][INFO] ---------------epoch 24---------------
lr: [0.0004698020564869813]
[2024-10-28 04:37:46,708][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.188565276216008
[2024-10-28 04:43:03,027][train_sub.py][line:219][INFO] test_acc:0.6818774342536926,test_err:0.9624564550035903
[2024-10-28 04:43:03,030][train_sub.py][line:116][INFO] ---------------epoch 25---------------
lr: [0.0004672831189080725]
[2024-10-28 05:00:02,162][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.0823047131193153
[2024-10-28 05:05:16,495][train_sub.py][line:219][INFO] test_acc:0.8029420971870422,test_err:0.5840222967386339
[2024-10-28 05:05:16,883][train_sub.py][line:116][INFO] ---------------epoch 26---------------
lr: [0.0004646711136979114]
[2024-10-28 05:22:19,983][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.013093195508458
[2024-10-28 05:27:32,863][train_sub.py][line:219][INFO] test_acc:0.8037975430488586,test_err:0.5867063271659543
[2024-10-28 05:27:33,709][train_sub.py][line:116][INFO] ---------------epoch 27---------------
lr: [0.00046196718655083075]
[2024-10-28 05:44:34,799][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.9522237910164728
[2024-10-28 05:49:48,714][train_sub.py][line:219][INFO] test_acc:0.6694806814193726,test_err:1.0307307646085766
[2024-10-28 05:49:48,717][train_sub.py][line:116][INFO] ---------------epoch 28---------------
lr: [0.00045917252348097557]
[2024-10-28 06:06:51,665][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.881781126008666
[2024-10-28 06:12:01,956][train_sub.py][line:219][INFO] test_acc:0.7818368077278137,test_err:0.6432598445858259
[2024-10-28 06:12:01,959][train_sub.py][line:116][INFO] ---------------epoch 29---------------
lr: [0.0004562883503020685]
[2024-10-28 06:29:03,405][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.8124794833976308
[2024-10-28 06:34:18,226][train_sub.py][line:219][INFO] test_acc:0.8063638806343079,test_err:0.5641160797624846
[2024-10-28 06:34:18,611][train_sub.py][line:116][INFO] ---------------epoch 30---------------
lr: [0.00045331593208971604]
[2024-10-28 06:51:19,072][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.7335396840580903
[2024-10-28 06:56:35,638][train_sub.py][line:219][INFO] test_acc:0.7597217559814453,test_err:0.7115052449516952
[2024-10-28 06:56:35,641][train_sub.py][line:116][INFO] ---------------epoch 31---------------
lr: [0.0004502565726264939]
[2024-10-28 06:56:35,641][train_sub.py][line:122][INFO] cluster starts
[2024-10-28 07:02:00,063][train_sub.py][line:125][INFO] cluster ends
[2024-10-28 07:19:04,119][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.7470748687303193
[2024-10-28 07:24:14,137][train_sub.py][line:219][INFO] test_acc:0.7784430980682373,test_err:0.6547177147172812
[2024-10-28 07:24:14,140][train_sub.py][line:116][INFO] ---------------epoch 32---------------
lr: [0.0004471116138300531]
[2024-10-28 07:41:14,223][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.8474638011293172
[2024-10-28 07:46:27,672][train_sub.py][line:219][INFO] test_acc:0.8170497417449951,test_err:0.5362471885166354
[2024-10-28 07:46:28,061][train_sub.py][line:116][INFO] ---------------epoch 33---------------
lr: [0.0004438824351644991]
[2024-10-28 08:03:23,250][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.7138268486146004
[2024-10-28 08:08:38,476][train_sub.py][line:219][INFO] test_acc:0.8424532413482666,test_err:0.4648298806799609
[2024-10-28 08:08:38,891][train_sub.py][line:116][INFO] ---------------epoch 34---------------
lr: [0.0004405704530353]
[2024-10-28 08:25:37,869][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.7019504701792125
[2024-10-28 08:30:53,051][train_sub.py][line:219][INFO] test_acc:0.8375941514968872,test_err:0.4619980347597317
[2024-10-28 08:30:53,440][train_sub.py][line:116][INFO] ---------------epoch 35---------------
lr: [0.0004371771201679926]
[2024-10-28 08:47:50,103][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.5293135143095447
[2024-10-28 08:53:05,367][train_sub.py][line:219][INFO] test_acc:0.8162924647331238,test_err:0.5525984000030731
[2024-10-28 08:53:05,370][train_sub.py][line:116][INFO] ---------------epoch 36---------------
lr: [0.00043370392497095483]
[2024-10-28 09:10:05,210][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.4637720097777664
[2024-10-28 09:15:13,992][train_sub.py][line:219][INFO] test_acc:0.8864519000053406,test_err:0.3393364944062354
[2024-10-28 09:15:14,376][train_sub.py][line:116][INFO] ---------------epoch 37---------------
lr: [0.0004301523908825267]
[2024-10-28 09:32:16,508][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.3989386415396112
[2024-10-28 09:37:30,774][train_sub.py][line:219][INFO] test_acc:0.8824622631072998,test_err:0.34694138701127236
[2024-10-28 09:37:30,777][train_sub.py][line:116][INFO] ---------------epoch 38---------------
lr: [0.00042652407570276655]
[2024-10-28 09:54:34,522][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.3326556443313544
[2024-10-28 09:59:40,814][train_sub.py][line:219][INFO] test_acc:0.8942700028419495,test_err:0.30727136561957497
[2024-10-28 09:59:41,191][train_sub.py][line:116][INFO] ---------------epoch 39---------------
lr: [0.0004228205709101319]
[2024-10-28 10:16:43,533][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.2787385844628871
[2024-10-28 10:21:56,155][train_sub.py][line:219][INFO] test_acc:0.8851547241210938,test_err:0.32917041781251605
[2024-10-28 10:21:56,158][train_sub.py][line:116][INFO] ---------------epoch 40---------------
lr: [0.0004190435009633892]
[2024-10-28 10:38:52,492][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.2293204916207165
[2024-10-28 10:44:07,372][train_sub.py][line:219][INFO] test_acc:0.9252128005027771,test_err:0.22385936366614476
[2024-10-28 10:44:07,742][train_sub.py][line:116][INFO] ---------------epoch 41---------------
lr: [0.000415194522589057]
[2024-10-28 10:44:07,743][train_sub.py][line:122][INFO] cluster starts
[2024-10-28 10:49:31,548][train_sub.py][line:125][INFO] cluster ends
[2024-10-28 11:06:32,252][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.394257525175703
[2024-10-28 11:11:40,676][train_sub.py][line:219][INFO] test_acc:0.525691032409668,test_err:2.1000462892735676
[2024-10-28 11:11:40,679][train_sub.py][line:116][INFO] ---------------epoch 42---------------
lr: [0.0004112753240546924]
[2024-10-28 11:28:42,964][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.4372536869031982
[2024-10-28 11:33:56,540][train_sub.py][line:219][INFO] test_acc:0.9125145673751831,test_err:0.2525916075731184
[2024-10-28 11:33:56,544][train_sub.py][line:116][INFO] ---------------epoch 43---------------
lr: [0.0004072876244283438]
[2024-10-28 11:50:59,791][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.300452732377582
[2024-10-28 11:56:08,077][train_sub.py][line:219][INFO] test_acc:0.7731282114982605,test_err:0.7170489446112325
[2024-10-28 11:56:08,080][train_sub.py][line:116][INFO] ---------------epoch 44---------------
lr: [0.0004032331728244925]
[2024-10-28 12:13:07,762][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.2223120264468654
[2024-10-28 12:18:23,935][train_sub.py][line:219][INFO] test_acc:0.9176120758056641,test_err:0.23149064129742536
[2024-10-28 12:18:23,939][train_sub.py][line:116][INFO] ---------------epoch 45---------------
lr: [0.00039911374763681263]
[2024-10-28 12:35:16,375][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.1545727255096572
[2024-10-28 12:40:31,305][train_sub.py][line:219][INFO] test_acc:0.8022059202194214,test_err:0.6335717474538533
[2024-10-28 12:40:31,307][train_sub.py][line:116][INFO] ---------------epoch 46---------------
lr: [0.0003949311557580889]
[2024-10-28 12:57:31,839][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.0698403106154506
[2024-10-28 13:02:45,437][train_sub.py][line:219][INFO] test_acc:0.9117642641067505,test_err:0.2541060000812421
[2024-10-28 13:02:45,441][train_sub.py][line:116][INFO] ---------------epoch 47---------------
lr: [0.0003906872317876324]
[2024-10-28 13:19:40,824][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.0280685693986955
[2024-10-28 13:24:56,497][train_sub.py][line:219][INFO] test_acc:0.9532808065414429,test_err:0.1414844075945543
[2024-10-28 13:24:56,879][train_sub.py][line:116][INFO] ---------------epoch 48---------------
lr: [0.0003863838372265404]
[2024-10-28 13:41:55,885][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.9618950641069788
[2024-10-28 13:47:04,455][train_sub.py][line:219][INFO] test_acc:0.5155800580978394,test_err:2.691105193802319
[2024-10-28 13:47:04,458][train_sub.py][line:116][INFO] ---------------epoch 49---------------
lr: [0.0003820228596611588]
[2024-10-28 14:04:06,246][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.9271217104995549
[2024-10-28 14:09:20,213][train_sub.py][line:219][INFO] test_acc:0.924848198890686,test_err:0.20560668762362275
[2024-10-28 14:09:20,216][train_sub.py][line:116][INFO] ---------------epoch 50---------------
lr: [0.0003776062119350975]
[2024-10-28 14:26:18,532][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8901671334620445
[2024-10-28 14:31:31,084][train_sub.py][line:219][INFO] test_acc:0.718731164932251,test_err:0.9908759900181818
[2024-10-28 14:31:31,087][train_sub.py][line:116][INFO] ---------------epoch 51---------------
lr: [0.0003731358313101679]
[2024-10-28 14:31:31,087][train_sub.py][line:122][INFO] cluster starts
[2024-10-28 14:36:56,506][train_sub.py][line:125][INFO] cluster ends
[2024-10-28 14:53:58,290][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 2.1200054728002105
[2024-10-28 14:59:13,287][train_sub.py][line:219][INFO] test_acc:0.6793532371520996,test_err:1.1330933274924888
[2024-10-28 14:59:13,774][train_sub.py][line:116][INFO] ---------------epoch 52---------------
lr: [0.00036861367861660876]
[2024-10-28 15:16:10,456][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.114019863708045
[2024-10-28 15:21:24,559][train_sub.py][line:219][INFO] test_acc:0.8705843687057495,test_err:0.4110211378172471
[2024-10-28 15:21:24,562][train_sub.py][line:116][INFO] ---------------epoch 53---------------
lr: [0.00036404173739297086]
[2024-10-28 15:38:22,717][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.994080014660367
[2024-10-28 15:43:37,166][train_sub.py][line:219][INFO] test_acc:0.9652568101882935,test_err:0.10617245764166575
[2024-10-28 15:43:37,538][train_sub.py][line:116][INFO] ---------------epoch 54---------------
lr: [0.0003594220130160408]
[2024-10-28 16:00:40,950][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.9096462145501141
[2024-10-28 16:05:53,484][train_sub.py][line:219][INFO] test_acc:0.9646678566932678,test_err:0.10687405389765324
[2024-10-28 16:05:53,487][train_sub.py][line:116][INFO] ---------------epoch 55---------------
lr: [0.0003547565318211844]
[2024-10-28 16:22:53,103][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8761114888293768
[2024-10-28 16:28:07,332][train_sub.py][line:219][INFO] test_acc:0.8764742016792297,test_err:0.39810830211528914
[2024-10-28 16:28:07,335][train_sub.py][line:116][INFO] ---------------epoch 56---------------
lr: [0.0003500473402134933]
[2024-10-28 16:45:05,522][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8020333611409723
[2024-10-28 16:50:19,675][train_sub.py][line:219][INFO] test_acc:0.9741056561470032,test_err:0.0810082769346854
[2024-10-28 16:50:20,285][train_sub.py][line:116][INFO] ---------------epoch 57---------------
lr: [0.00034529650377012846]
[2024-10-28 17:07:15,398][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.7541047391818843
[2024-10-28 17:12:31,241][train_sub.py][line:219][INFO] test_acc:0.9673463106155396,test_err:0.09562587312797809
[2024-10-28 17:12:31,244][train_sub.py][line:116][INFO] ---------------epoch 58---------------
lr: [0.0003405061063342509]
[2024-10-28 17:29:27,398][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.7184980453983429
[2024-10-28 17:34:41,893][train_sub.py][line:219][INFO] test_acc:0.9693166613578796,test_err:0.09087955564021655
[2024-10-28 17:34:41,896][train_sub.py][line:116][INFO] ---------------epoch 59---------------
lr: [0.0003356782491009373]
[2024-10-28 17:51:43,589][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.6898607720610916
[2024-10-28 17:56:57,940][train_sub.py][line:219][INFO] test_acc:0.9816853404045105,test_err:0.05912778998402158
[2024-10-28 17:56:58,326][train_sub.py][line:116][INFO] ---------------epoch 60---------------
lr: [0.000330815049695485]
[2024-10-28 18:13:53,723][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.6446492355250116
[2024-10-28 18:19:05,822][train_sub.py][line:219][INFO] test_acc:0.9766368865966797,test_err:0.07039627587229955
[2024-10-28 18:19:05,825][train_sub.py][line:116][INFO] ---------------epoch 61---------------
lr: [0.00032591864124450364]
[2024-10-28 18:19:05,826][train_sub.py][line:122][INFO] cluster starts
[2024-10-28 18:24:28,336][train_sub.py][line:125][INFO] cluster ends
[2024-10-28 18:41:28,697][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 1.95260901818566
[2024-10-28 18:46:44,547][train_sub.py][line:219][INFO] test_acc:0.9255704283714294,test_err:0.22290949291035558
[2024-10-28 18:46:44,549][train_sub.py][line:116][INFO] ---------------epoch 62---------------
lr: [0.00032099117144020694]
[2024-10-28 19:03:39,792][train_sub.py][line:142][INFO] [training]total_num: 142618.0,error: 0.8652243293741698
[2024-10-28 19:08:55,903][train_sub.py][line:219][INFO] test_acc:0.9658247828483582,test_err:0.10488895343157202
[2024-10-28 19:08:55,906][train_sub.py][line:116][INFO] ---------------epoch 63---------------
lr: [0.0003160348015983127]
