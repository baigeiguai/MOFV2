[2024-08-12 12:58:19,755][train.py][line:74][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0', train_name='RawEmbedConvNoTrain_extend', model_path='./checkpoints/RawEmbedConvNoTrain/RawEmbedConvNoTrain_epoch_7.pth', learning_rate=0.005, min_learning_rate=1e-06, start_scheduler_step=0, weight_decay=1e-06, momentum=0.99, batch_size=2048, class_num=230, epoch_num=100, model_save_path='./checkpoints/RawEmbedConvNoTrain_extend', device='0', scheduler_T=None, num_workers=10, log_name='log/train//train_RawEmbedConvNoTrain_extend_2024_08_12_12:58:12.log')
[2024-08-12 12:58:19,757][train.py][line:75][INFO] ---------------model---------------
RawEmbedConv(
  (embed): Embedding(8500, 32)
  (conv): ResTcn(
    (conv): Sequential(
      (0): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (2): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (10): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (12): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (14): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (16): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (18): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (20): Dropout(p=0.1, inplace=False)
      (21): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (22): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (23): Dropout(p=0.1, inplace=False)
      (24): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (25): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (26): Dropout(p=0.1, inplace=False)
      (27): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (28): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (29): Flatten(start_dim=1, end_dim=-1)
      (30): Linear(in_features=1024, out_features=230, bias=True)
    )
  )
)
[2024-08-12 12:58:19,759][train.py][line:76][INFO] ---------------device---------------
cuda:0
[2024-08-12 12:58:19,759][train.py][line:77][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 1e-06
)
[2024-08-12 12:58:19,759][train.py][line:78][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-08-12 12:58:19,759][train.py][line:79][INFO] ---------------seed---------------
3407
[2024-08-12 12:58:19,771][train.py][line:91][INFO] ---------------epoch 1---------------
lr: [0.005]
[2024-08-12 13:04:12,434][train.py][line:111][INFO] [training]total_num: 142618.0,error: 3.3009213738971286
[2024-08-12 13:06:27,618][train.py][line:153][INFO] [testing]total_number: 142618,error: 3.045150144232644,total_acc: 0.18964646756649017
[2024-08-12 13:06:27,967][train.py][line:91][INFO] ---------------epoch 2---------------
lr: [0.004997533599560762]
[2024-08-12 13:12:20,917][train.py][line:111][INFO] [training]total_num: 142618.0,error: 3.1173952056301966
[2024-08-12 13:14:36,767][train.py][line:153][INFO] [testing]total_number: 142618,error: 3.2681572470400067,total_acc: 0.15686659514904022
[2024-08-12 13:14:36,832][train.py][line:91][INFO] ---------------epoch 3---------------
lr: [0.004991371705284909]
[2024-08-12 13:20:28,850][train.py][line:111][INFO] [training]total_num: 142618.0,error: 3.070981012450324
[2024-08-12 13:22:44,311][train.py][line:153][INFO] [testing]total_number: 142618,error: 2.8478698200649686,total_acc: 0.2324531227350235
[2024-08-12 13:22:44,485][train.py][line:91][INFO] ---------------epoch 4---------------
lr: [0.0049827540531497]
[2024-08-12 13:28:36,574][train.py][line:111][INFO] [training]total_num: 142618.0,error: 2.8959351910485163
[2024-08-12 13:30:54,016][train.py][line:153][INFO] [testing]total_number: 142618,error: 2.6767591635386148,total_acc: 0.2728687822818756
[2024-08-12 13:31:15,898][train.py][line:91][INFO] ---------------epoch 5---------------
lr: [0.004971689145934162]
[2024-08-12 13:37:09,040][train.py][line:111][INFO] [training]total_num: 142618.0,error: 2.7064700623353324
[2024-08-12 13:39:26,312][train.py][line:153][INFO] [testing]total_number: 142618,error: 2.524890889724096,total_acc: 0.29543957114219666
[2024-08-12 13:39:26,478][train.py][line:91][INFO] ---------------epoch 6---------------
lr: [0.004958187901559507]
[2024-08-12 13:45:20,472][train.py][line:111][INFO] [training]total_num: 142618.0,error: 2.5740788910124035
[2024-08-12 13:47:35,908][train.py][line:153][INFO] [testing]total_number: 142618,error: 2.512785428100162,total_acc: 0.29946431517601013
[2024-08-12 13:47:36,071][train.py][line:91][INFO] ---------------epoch 7---------------
lr: [0.00494226364231267]
[2024-08-12 13:53:28,141][train.py][line:111][INFO] [training]total_num: 142618.0,error: 2.4535130626625485
[2024-08-12 13:55:42,987][train.py][line:153][INFO] [testing]total_number: 142618,error: 2.344305098056793,total_acc: 0.3393751084804535
[2024-08-12 13:55:43,164][train.py][line:91][INFO] ---------------epoch 8---------------
lr: [0.004923932081697]
[2024-08-12 14:01:35,697][train.py][line:111][INFO] [training]total_num: 142618.0,error: 2.3208774858050876
[2024-08-12 14:03:51,302][train.py][line:153][INFO] [testing]total_number: 142618,error: 2.083765283226967,total_acc: 0.3935197591781616
[2024-08-12 14:03:53,584][train.py][line:91][INFO] ---------------epoch 9---------------
lr: [0.004903211308923103]
[2024-08-12 14:09:45,977][train.py][line:111][INFO] [training]total_num: 142618.0,error: 3.202379771404796
[2024-08-12 14:12:02,666][train.py][line:153][INFO] [testing]total_number: 142618,error: 3.911775483025445,total_acc: 0.06608562916517258
[2024-08-12 14:12:02,748][train.py][line:91][INFO] ---------------epoch 10---------------
lr: [0.004880121771055105]
[2024-08-12 14:17:56,232][train.py][line:111][INFO] [training]total_num: 142618.0,error: 6261459.7073343955
[2024-08-12 14:20:12,483][train.py][line:153][INFO] [testing]total_number: 142618,error: 89003.56477864583,total_acc: 0.0004557629581540823
[2024-08-12 14:20:12,547][train.py][line:91][INFO] ---------------epoch 11---------------
lr: [0.004854686252829965]
[2024-08-12 14:26:04,991][train.py][line:111][INFO] [training]total_num: 142618.0,error: 6361.653722127278
[2024-08-12 14:28:21,449][train.py][line:153][INFO] [testing]total_number: 142618,error: 343.27832878960504,total_acc: 0.05338035896420479
[2024-08-12 14:28:21,523][train.py][line:91][INFO] ---------------epoch 12---------------
lr: [0.004826929854169753]
[2024-08-12 14:34:13,928][train.py][line:111][INFO] [training]total_num: 142618.0,error: 96.35259204440646
[2024-08-12 14:36:29,114][train.py][line:153][INFO] [testing]total_number: 142618,error: 35.20453829235501,total_acc: 0.018742375075817108
[2024-08-12 14:36:29,198][train.py][line:91][INFO] ---------------epoch 13---------------
lr: [0.004796879965409048]
[2024-08-12 14:42:23,258][train.py][line:111][INFO] [training]total_num: 142618.0,error: 26.925576051076252
[2024-08-12 14:44:38,792][train.py][line:153][INFO] [testing]total_number: 142618,error: 20.630639023251003,total_acc: 0.03567571938037872
[2024-08-12 14:44:38,867][train.py][line:91][INFO] ---------------epoch 14---------------
lr: [0.004764566240261942]
[2024-08-12 14:50:30,709][train.py][line:111][INFO] [training]total_num: 142618.0,error: 16.928942031330532
[2024-08-12 14:52:46,347][train.py][line:153][INFO] [testing]total_number: 142618,error: 13.946642319361368,total_acc: 0.049699194729328156
[2024-08-12 14:52:46,411][train.py][line:91][INFO] ---------------epoch 15---------------
lr: [0.004730020566555275]
[2024-08-12 14:58:39,108][train.py][line:111][INFO] [training]total_num: 142618.0,error: 12.485632538795471
[2024-08-12 15:00:54,110][train.py][line:153][INFO] [testing]total_number: 142618,error: 11.21726601653629,total_acc: 0.046971630305051804
[2024-08-12 15:00:54,185][train.py][line:91][INFO] ---------------epoch 16---------------
lr: [0.004693277034757]
[2024-08-12 15:06:46,306][train.py][line:111][INFO] [training]total_num: 142618.0,error: 10.214662988980612
[2024-08-12 15:09:01,646][train.py][line:153][INFO] [testing]total_number: 142618,error: 9.351303418477377,total_acc: 0.04032450169324875
[2024-08-12 15:09:01,720][train.py][line:91][INFO] ---------------epoch 17---------------
lr: [0.004654371904330738]
[2024-08-12 15:16:07,465][train.py][line:111][INFO] [training]total_num: 142618.0,error: 8.587617635726929
[2024-08-12 15:18:36,741][train.py][line:153][INFO] [testing]total_number: 142618,error: 7.929827239778307,total_acc: 0.041032690554857254
[2024-08-12 15:18:36,816][train.py][line:91][INFO] ---------------epoch 18---------------
lr: [0.004613343567949682]
[2024-08-12 15:24:29,751][train.py][line:111][INFO] [training]total_num: 142618.0,error: 7.372925632529789
[2024-08-12 15:26:46,134][train.py][line:153][INFO] [testing]total_number: 142618,error: 6.817314677768284,total_acc: 0.04242101311683655
[2024-08-12 15:26:46,209][train.py][line:91][INFO] ---------------epoch 19---------------
lr: [0.004570232513605179]
[2024-08-12 15:32:39,385][train.py][line:111][INFO] [training]total_num: 142618.0,error: 6.469461421171824
[2024-08-12 15:34:55,780][train.py][line:153][INFO] [testing]total_number: 142618,error: 6.123658385541704,total_acc: 0.04942573979496956
[2024-08-12 15:34:55,855][train.py][line:91][INFO] ---------------epoch 20---------------
lr: [0.00452508128464739]
[2024-08-12 15:40:50,635][train.py][line:111][INFO] [training]total_num: 142618.0,error: 5.874606377548641
[2024-08-12 15:43:06,635][train.py][line:153][INFO] [testing]total_number: 142618,error: 5.632051024172041,total_acc: 0.05374496802687645
[2024-08-12 15:43:06,699][train.py][line:91][INFO] ---------------epoch 21---------------
lr: [0.0044779344377974106]
[2024-08-12 15:48:59,188][train.py][line:111][INFO] [training]total_num: 142618.0,error: 5.4316888584031
[2024-08-12 15:51:15,893][train.py][line:153][INFO] [testing]total_number: 142618,error: 5.24928351243337,total_acc: 0.05722279101610184
[2024-08-12 15:51:15,978][train.py][line:91][INFO] ---------------epoch 22---------------
lr: [0.004428838499172301]
[2024-08-12 15:57:10,424][train.py][line:111][INFO] [training]total_num: 142618.0,error: 5.121849291854435
[2024-08-12 15:59:29,267][train.py][line:153][INFO] [testing]total_number: 142618,error: 5.007925358083513,total_acc: 0.06055336818099022
[2024-08-12 15:59:29,341][train.py][line:91][INFO] ---------------epoch 23---------------
lr: [0.0043778419183664215]
[2024-08-12 16:05:24,114][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.911057790120442
[2024-08-12 16:07:40,809][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.82854429880778,total_acc: 0.060953035950660706
[2024-08-12 16:07:40,885][train.py][line:91][INFO] ---------------epoch 24---------------
lr: [0.0043249950206343335]
[2024-08-12 16:13:33,472][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.7556061546007795
[2024-08-12 16:15:49,230][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.693129791153802,total_acc: 0.06200479716062546
[2024-08-12 16:15:49,304][train.py][line:91][INFO] ---------------epoch 25---------------
lr: [0.004270349957222484]
[2024-08-12 16:21:42,924][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.639045258363088
[2024-08-12 16:24:00,627][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.586183157232073,total_acc: 0.06231331080198288
[2024-08-12 16:24:00,692][train.py][line:91][INFO] ---------------epoch 26---------------
lr: [0.004213960653898645]
[2024-08-12 16:29:53,275][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.5424646271599665
[2024-08-12 16:32:10,727][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.508398678567675,total_acc: 0.06207491457462311
[2024-08-12 16:32:10,984][train.py][line:91][INFO] ---------------epoch 27---------------
lr: [0.00415588275772989]
[2024-08-12 16:38:03,612][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.463606039683024
[2024-08-12 16:40:20,858][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.426835768752628,total_acc: 0.06245354562997818
[2024-08-12 16:40:20,932][train.py][line:91][INFO] ---------------epoch 28---------------
lr: [0.004096173582161603]
[2024-08-12 16:46:13,878][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.393869956334432
[2024-08-12 16:48:29,960][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.367525173558129,total_acc: 0.0627550482749939
[2024-08-12 16:48:30,035][train.py][line:91][INFO] ---------------epoch 29---------------
lr: [0.0040348920504517174]
[2024-08-12 16:54:22,398][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.336237549781799
[2024-08-12 16:56:37,605][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.3085693385865955,total_acc: 0.06213100627064705
[2024-08-12 16:56:37,680][train.py][line:91][INFO] ---------------epoch 30---------------
lr: [0.003972098637515952]
[2024-08-12 17:02:29,765][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.286112520429823
[2024-08-12 17:04:44,713][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.264729102452596,total_acc: 0.06273401528596878
[2024-08-12 17:04:44,787][train.py][line:91][INFO] ---------------epoch 31---------------
lr: [0.003907855310241427]
[2024-08-12 17:10:38,770][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.2424698736932545
[2024-08-12 17:12:54,329][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.226387759049733,total_acc: 0.06271298229694366
[2024-08-12 17:12:54,404][train.py][line:91][INFO] ---------------epoch 32---------------
lr: [0.0038422254663275286]
[2024-08-12 17:18:46,534][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.202378074328105
[2024-08-12 17:21:01,616][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.18834666411082,total_acc: 0.06297942996025085
[2024-08-12 17:21:01,692][train.py][line:91][INFO] ---------------epoch 33---------------
lr: [0.003775273871714328]
[2024-08-12 17:26:54,870][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.170022785663605
[2024-08-12 17:29:10,127][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.154359486367968,total_acc: 0.06194870173931122
[2024-08-12 17:29:10,193][train.py][line:91][INFO] ---------------epoch 34---------------
lr: [0.00370706659666029]
[2024-08-12 17:35:03,077][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.142258779870139
[2024-08-12 17:37:18,703][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.136675218741099,total_acc: 0.06253067404031754
[2024-08-12 17:37:18,788][train.py][line:91][INFO] ---------------epoch 35---------------
lr: [0.003637670950532277]
[2024-08-12 17:43:11,770][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.115172955724928
[2024-08-12 17:45:27,587][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.102154367499882,total_acc: 0.062306299805641174
[2024-08-12 17:45:27,653][train.py][line:91][INFO] ---------------epoch 36---------------
lr: [0.003567155415372195]
[2024-08-12 17:51:20,581][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.0883696840869055
[2024-08-12 17:53:35,739][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.096666011545393,total_acc: 0.06201881915330887
[2024-08-12 17:53:35,804][train.py][line:91][INFO] ---------------epoch 37---------------
lr: [0.0034955895783057404]
[2024-08-12 17:59:28,986][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.069390743970871
[2024-08-12 18:01:44,661][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.063286638922161,total_acc: 0.06288126111030579
[2024-08-12 18:01:44,728][train.py][line:91][INFO] ---------------epoch 38---------------
lr: [0.0034230440628599283]
[2024-08-12 18:07:37,370][train.py][line:111][INFO] [training]total_num: 142618.0,error: 4.050525132152769
[2024-08-12 18:09:52,358][train.py][line:153][INFO] [testing]total_number: 142618,error: 4.041108753946093,total_acc: 0.0630425363779068
[2024-08-12 18:09:52,424][train.py][line:91][INFO] ---------------epoch 39---------------
lr: [0.003349590459257094]
