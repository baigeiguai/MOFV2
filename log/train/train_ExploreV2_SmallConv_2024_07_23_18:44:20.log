[2024-07-23 18:44:26,249][train.py][line:64][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/1/', train_name='ExploreV2_SmallConv', model_path=None, learning_rate=0.005, min_learning_rate=1e-06, start_scheduler_step=0, weight_decay=1e-06, momentum=0.99, batch_size=256, class_num=230, epoch_num=60, model_save_path='./checkpoints/ExploreV2_SmallConv', device='1', scheduler_T=None, num_workers=20, log_name='log/train//train_ExploreV2_SmallConv_2024_07_23_18:44:20.log')
[2024-07-23 18:44:26,251][train.py][line:65][INFO] ---------------model---------------
ExplorerV2(
  (predict_hkl_blocks): ModuleList(
    (0-31): 32 x Mamba(
      (in_proj): Linear(in_features=2, out_features=8, bias=False)
      (conv1d): Conv1d(4, 4, kernel_size=(4,), stride=(1,), padding=(3,), groups=4)
      (act): SiLU()
      (x_proj): Linear(in_features=4, out_features=65, bias=False)
      (dt_proj): Linear(in_features=1, out_features=4, bias=True)
      (out_proj): Linear(in_features=4, out_features=2, bias=False)
    )
  )
  (conv): ResTcn(
    (conv): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(2, 16, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (2): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): ResBlock1D(
        (pre): Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (10): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (12): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (14): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (16): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (18): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (20): Dropout(p=0, inplace=False)
      (21): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (22): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (23): Dropout(p=0, inplace=False)
      (24): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (25): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (26): Dropout(p=0, inplace=False)
      (27): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (28): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (29): Flatten(start_dim=1, end_dim=-1)
      (30): Linear(in_features=1024, out_features=230, bias=True)
    )
  )
)
[2024-07-23 18:44:26,251][train.py][line:66][INFO] ---------------device---------------
cuda:1
[2024-07-23 18:44:26,251][train.py][line:67][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 1e-06
)
[2024-07-23 18:44:26,251][train.py][line:68][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-07-23 18:44:26,251][train.py][line:69][INFO] ---------------seed---------------
3407
[2024-07-23 18:44:26,254][train.py][line:81][INFO] ---------------epoch 1---------------
lr: [0.005]
[2024-07-23 18:49:59,998][train.py][line:101][INFO] [training]total_num: 141865.0,error: 3.908916218276512
[2024-07-23 18:52:08,924][train.py][line:141][INFO] [testing]total_number: 141865,error: 3.786125143297699,total_acc: 0.06598526984453201
[2024-07-23 18:52:09,201][train.py][line:81][INFO] ---------------epoch 2---------------
lr: [0.0049931513914873065]
[2024-07-23 18:57:38,026][train.py][line:101][INFO] [training]total_num: 141865.0,error: 3.7790081265584785
[2024-07-23 18:59:47,732][train.py][line:141][INFO] [testing]total_number: 141865,error: 29.546606159723854,total_acc: 0.06563986837863922
[2024-07-23 18:59:47,741][train.py][line:81][INFO] ---------------epoch 3---------------
lr: [0.0049760615339446]
[2024-07-23 19:05:16,087][train.py][line:101][INFO] [training]total_num: 141865.0,error: 3.7766936394641815
[2024-07-23 19:07:25,640][train.py][line:141][INFO] [testing]total_number: 141865,error: 4.037010877735953,total_acc: 0.06513939052820206
[2024-07-23 19:07:25,649][train.py][line:81][INFO] ---------------epoch 4---------------
lr: [0.004952205057616861]
[2024-07-23 19:12:54,115][train.py][line:101][INFO] [training]total_num: 141865.0,error: 3.7771970767735152
[2024-07-23 19:15:03,332][train.py][line:141][INFO] [testing]total_number: 141865,error: 33.260473867721146,total_acc: 0.06513939052820206
[2024-07-23 19:15:03,343][train.py][line:81][INFO] ---------------epoch 5---------------
lr: [0.004921647312761654]
[2024-07-23 19:20:32,549][train.py][line:101][INFO] [training]total_num: 141865.0,error: 3.776063552236643
[2024-07-23 19:22:44,467][train.py][line:141][INFO] [testing]total_number: 141865,error: 49.0456438389886,total_acc: 0.06602051109075546
[2024-07-23 19:22:44,746][train.py][line:81][INFO] ---------------epoch 6---------------
lr: [0.004884472017161477]
[2024-07-23 19:28:14,228][train.py][line:101][INFO] [training]total_num: 141865.0,error: 3.774936081905125
[2024-07-23 19:30:23,160][train.py][line:141][INFO] [testing]total_number: 141865,error: 3.782828259082842,total_acc: 0.06513939052820206
[2024-07-23 19:30:23,438][train.py][line:81][INFO] ---------------epoch 7---------------
lr: [0.004840781026550559]
[2024-07-23 19:35:52,963][train.py][line:101][INFO] [training]total_num: 141865.0,error: 3.7752461257914023
[2024-07-23 19:38:04,831][train.py][line:141][INFO] [testing]total_number: 141865,error: 3.944840232174529,total_acc: 0.06598526984453201
[2024-07-23 19:38:04,842][train.py][line:81][INFO] ---------------epoch 8---------------
lr: [0.004790694055323915]
[2024-07-23 19:43:33,954][train.py][line:101][INFO] [training]total_num: 141865.0,error: 3.7742779229230896
