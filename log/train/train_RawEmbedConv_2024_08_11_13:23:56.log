[2024-08-11 13:24:17,334][train.py][line:74][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0', train_name='RawEmbedConv', model_path=None, learning_rate=0.005, min_learning_rate=1e-06, start_scheduler_step=0, weight_decay=1e-06, momentum=0.99, batch_size=128, class_num=230, epoch_num=100, model_save_path='./checkpoints/RawEmbedConv', device='3', scheduler_T=None, num_workers=20, log_name='log/train//train_RawEmbedConv_2024_08_11_13:23:56.log')
[2024-08-11 13:24:17,337][train.py][line:75][INFO] ---------------model---------------
RawEmbedConv(
  (embed): Embedding(8500, 32)
  (conv): ResTcn(
    (conv): Sequential(
      (0): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (2): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (10): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (12): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (14): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (16): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (18): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (20): Dropout(p=0.1, inplace=False)
      (21): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (22): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (23): Dropout(p=0.1, inplace=False)
      (24): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (25): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (26): Dropout(p=0.1, inplace=False)
      (27): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (28): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (29): Flatten(start_dim=1, end_dim=-1)
      (30): Linear(in_features=1024, out_features=230, bias=True)
    )
  )
)
[2024-08-11 13:24:17,338][train.py][line:76][INFO] ---------------device---------------
cuda:3
[2024-08-11 13:24:17,338][train.py][line:77][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 1e-06
)
[2024-08-11 13:24:17,338][train.py][line:78][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-08-11 13:24:17,338][train.py][line:79][INFO] ---------------seed---------------
3407
[2024-08-11 13:24:17,356][train.py][line:91][INFO] ---------------epoch 1---------------
lr: [0.005]
[2024-08-11 13:39:04,118][train.py][line:111][INFO] [training]total_num: 142618.0,error: 3.532335599334026
[2024-08-11 13:45:12,326][train.py][line:151][INFO] [testing]total_number: 142618,error: 3.5288475458877957,total_acc: 0.1123771220445633
[2024-08-11 13:45:12,908][train.py][line:91][INFO] ---------------epoch 2---------------
lr: [0.004997533599560762]
[2024-08-11 13:59:42,746][train.py][line:111][INFO] [training]total_num: 142618.0,error: 2.914181230548429
[2024-08-11 14:06:46,190][train.py][line:151][INFO] [testing]total_number: 142618,error: 7.4957209953504425,total_acc: 0.030115412548184395
[2024-08-11 14:06:46,196][train.py][line:91][INFO] ---------------epoch 3---------------
lr: [0.004991371705284909]
[2024-08-11 14:20:40,872][train.py][line:111][INFO] [training]total_num: 142618.0,error: 2.4581757274050573
[2024-08-11 14:27:21,378][train.py][line:151][INFO] [testing]total_number: 142618,error: 9.774394920470975,total_acc: 0.06620482355356216
[2024-08-11 14:27:21,491][train.py][line:91][INFO] ---------------epoch 4---------------
lr: [0.0049827540531497]
[2024-08-11 14:40:39,029][train.py][line:111][INFO] [training]total_num: 142618.0,error: 2.1450392510262652
[2024-08-11 14:48:04,300][train.py][line:151][INFO] [testing]total_number: 142618,error: 10.173258728968325,total_acc: 0.03535318002104759
[2024-08-11 14:48:04,307][train.py][line:91][INFO] ---------------epoch 5---------------
lr: [0.004971689145934162]
[2024-08-11 15:02:09,475][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.9351231004669271
[2024-08-11 15:08:17,727][train.py][line:151][INFO] [testing]total_number: 142618,error: 7.178823543419961,total_acc: 0.027086341753602028
[2024-08-11 15:08:17,732][train.py][line:91][INFO] ---------------epoch 6---------------
lr: [0.004958187901559507]
[2024-08-11 15:22:16,904][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.7861622341354018
[2024-08-11 15:29:42,696][train.py][line:151][INFO] [testing]total_number: 142618,error: 7.07278816955959,total_acc: 0.0331234484910965
[2024-08-11 15:29:42,705][train.py][line:91][INFO] ---------------epoch 7---------------
lr: [0.00494226364231267]
[2024-08-11 15:43:43,662][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.6634669846523729
[2024-08-11 15:51:07,427][train.py][line:151][INFO] [testing]total_number: 142618,error: 8.998580888614468,total_acc: 0.024849597364664078
[2024-08-11 15:51:07,433][train.py][line:91][INFO] ---------------epoch 8---------------
lr: [0.004923932081697]
[2024-08-11 16:04:44,014][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.5500160960254143
[2024-08-11 16:12:20,222][train.py][line:151][INFO] [testing]total_number: 142618,error: 15.424794566874601,total_acc: 0.06617677956819534
[2024-08-11 16:12:20,228][train.py][line:91][INFO] ---------------epoch 9---------------
lr: [0.004903211308923103]
[2024-08-11 16:25:51,611][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.450701743496554
[2024-08-11 16:32:55,639][train.py][line:151][INFO] [testing]total_number: 142618,error: 8.793835901008206,total_acc: 0.028678007423877716
[2024-08-11 16:32:55,645][train.py][line:91][INFO] ---------------epoch 10---------------
lr: [0.004880121771055105]
[2024-08-11 16:46:20,823][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.3651554498295924
[2024-08-11 16:53:20,800][train.py][line:151][INFO] [testing]total_number: 142618,error: 20.597473351851754,total_acc: 0.06274803727865219
[2024-08-11 16:53:20,808][train.py][line:91][INFO] ---------------epoch 11---------------
lr: [0.004854686252829965]
[2024-08-11 17:08:03,757][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.301891082086284
[2024-08-11 17:15:28,000][train.py][line:151][INFO] [testing]total_number: 142618,error: 8.776310830171276,total_acc: 0.018412822857499123
[2024-08-11 17:15:28,085][train.py][line:91][INFO] ---------------epoch 12---------------
lr: [0.004826929854169753]
[2024-08-11 17:30:01,728][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.2145505761190547
[2024-08-11 17:37:26,588][train.py][line:151][INFO] [testing]total_number: 142618,error: 30.951737387791713,total_acc: 0.06497076153755188
[2024-08-11 17:37:26,639][train.py][line:91][INFO] ---------------epoch 13---------------
lr: [0.004796879965409048]
[2024-08-11 17:51:32,336][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.1434470324148196
[2024-08-11 17:58:45,002][train.py][line:151][INFO] [testing]total_number: 142618,error: 10.302750480841405,total_acc: 0.03290608525276184
[2024-08-11 17:58:45,008][train.py][line:91][INFO] ---------------epoch 14---------------
lr: [0.004764566240261942]
[2024-08-11 18:13:03,533][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.0957889512987822
[2024-08-11 18:19:55,962][train.py][line:151][INFO] [testing]total_number: 142618,error: 11.519898776788043,total_acc: 0.024863621219992638
[2024-08-11 18:19:55,968][train.py][line:91][INFO] ---------------epoch 15---------------
lr: [0.004730020566555275]
[2024-08-11 18:33:14,835][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.0484368390706966
[2024-08-11 18:40:21,140][train.py][line:151][INFO] [testing]total_number: 142618,error: 10.150236659908886,total_acc: 0.06859582662582397
[2024-08-11 18:40:21,146][train.py][line:91][INFO] ---------------epoch 16---------------
lr: [0.004693277034757]
[2024-08-11 18:54:26,746][train.py][line:111][INFO] [training]total_num: 142618.0,error: 1.003145252801511
[2024-08-11 19:01:01,960][train.py][line:151][INFO] [testing]total_number: 142618,error: 3.9841935590187214,total_acc: 0.22935393452644348
[2024-08-11 19:01:02,598][train.py][line:91][INFO] ---------------epoch 17---------------
lr: [0.004654371904330738]
[2024-08-11 19:15:05,297][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.9383972525702394
[2024-08-11 19:21:02,795][train.py][line:151][INFO] [testing]total_number: 142618,error: 9.518800183747231,total_acc: 0.02186259813606739
[2024-08-11 19:21:02,800][train.py][line:91][INFO] ---------------epoch 18---------------
lr: [0.004613343567949682]
[2024-08-11 19:34:35,502][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.8754682203468858
[2024-08-11 19:42:20,983][train.py][line:151][INFO] [testing]total_number: 142618,error: 13.307771273175488,total_acc: 0.06403820216655731
[2024-08-11 19:42:20,991][train.py][line:91][INFO] ---------------epoch 19---------------
lr: [0.004570232513605179]
[2024-08-11 19:56:00,785][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.8450483212771411
[2024-08-11 20:02:36,641][train.py][line:151][INFO] [testing]total_number: 142618,error: 16.653607321081694,total_acc: 0.04534490779042244
[2024-08-11 20:02:36,693][train.py][line:91][INFO] ---------------epoch 20---------------
lr: [0.00452508128464739]
[2024-08-11 20:15:09,894][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.812818350391041
[2024-08-11 20:21:18,583][train.py][line:151][INFO] [testing]total_number: 142618,error: 12.851364039274689,total_acc: 0.0714285746216774
[2024-08-11 20:21:18,590][train.py][line:91][INFO] ---------------epoch 21---------------
lr: [0.0044779344377974106]
[2024-08-11 20:35:01,400][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.7613384213559693
[2024-08-11 20:40:20,656][train.py][line:151][INFO] [testing]total_number: 142618,error: 2.395474709021696,total_acc: 0.4478607177734375
[2024-08-11 20:40:21,035][train.py][line:91][INFO] ---------------epoch 22---------------
lr: [0.004428838499172301]
[2024-08-11 20:52:54,169][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.7382687096745966
[2024-08-11 20:57:45,786][train.py][line:151][INFO] [testing]total_number: 142618,error: 4.908096348594118,total_acc: 0.16779087483882904
[2024-08-11 20:57:45,792][train.py][line:91][INFO] ---------------epoch 23---------------
lr: [0.0043778419183664215]
[2024-08-11 21:10:21,341][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.6842345954204092
[2024-08-11 21:15:13,561][train.py][line:151][INFO] [testing]total_number: 142618,error: 39.44345669716782,total_acc: 0.060476236045360565
[2024-08-11 21:15:13,567][train.py][line:91][INFO] ---------------epoch 24---------------
lr: [0.0043249950206343335]
[2024-08-11 21:27:54,566][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.6883491723010682
[2024-08-11 21:32:59,541][train.py][line:151][INFO] [testing]total_number: 142618,error: 9.927978404771997,total_acc: 0.07320254296064377
[2024-08-11 21:32:59,546][train.py][line:91][INFO] ---------------epoch 25---------------
lr: [0.004270349957222484]
[2024-08-11 21:45:37,937][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.6237082592184393
[2024-08-11 21:50:42,265][train.py][line:151][INFO] [testing]total_number: 142618,error: 11.29779493692393,total_acc: 0.02998219057917595
[2024-08-11 21:50:42,272][train.py][line:91][INFO] ---------------epoch 26---------------
lr: [0.004213960653898645]
[2024-08-11 22:03:17,415][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.5991987025938736
[2024-08-11 22:08:17,340][train.py][line:151][INFO] [testing]total_number: 142618,error: 4.600275671154181,total_acc: 0.21990913152694702
[2024-08-11 22:08:17,347][train.py][line:91][INFO] ---------------epoch 27---------------
lr: [0.00415588275772989]
[2024-08-11 22:20:51,174][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.5658643358083774
[2024-08-11 22:25:49,926][train.py][line:151][INFO] [testing]total_number: 142618,error: 5.132196631385038,total_acc: 0.17225736379623413
[2024-08-11 22:25:49,932][train.py][line:91][INFO] ---------------epoch 28---------------
lr: [0.004096173582161603]
[2024-08-11 22:38:26,754][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.5342493427730601
[2024-08-11 22:44:12,826][train.py][line:151][INFO] [testing]total_number: 142618,error: 14.549164099299812,total_acc: 0.07546032220125198
[2024-08-11 22:44:12,832][train.py][line:91][INFO] ---------------epoch 29---------------
lr: [0.0040348920504517174]
[2024-08-11 22:57:40,163][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.502655815065383
[2024-08-11 23:05:03,041][train.py][line:151][INFO] [testing]total_number: 142618,error: 23.019781848870238,total_acc: 0.0715688094496727
[2024-08-11 23:05:03,046][train.py][line:91][INFO] ---------------epoch 30---------------
lr: [0.003972098637515952]
[2024-08-11 23:18:33,247][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.4999453383493762
[2024-08-11 23:23:31,743][train.py][line:151][INFO] [testing]total_number: 142618,error: 28.691205658527636,total_acc: 0.06631000339984894
[2024-08-11 23:23:31,750][train.py][line:91][INFO] ---------------epoch 31---------------
lr: [0.003907855310241427]
[2024-08-11 23:35:44,256][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.45543570167318104
[2024-08-11 23:40:45,417][train.py][line:151][INFO] [testing]total_number: 142618,error: 44.845963979888616,total_acc: 0.05907389149069786
[2024-08-11 23:40:45,500][train.py][line:91][INFO] ---------------epoch 32---------------
lr: [0.0038422254663275286]
[2024-08-11 23:53:01,676][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.4883774187756304
[2024-08-11 23:58:02,500][train.py][line:151][INFO] [testing]total_number: 142618,error: 15.246594511098108,total_acc: 0.06580515950918198
[2024-08-11 23:58:02,507][train.py][line:91][INFO] ---------------epoch 33---------------
lr: [0.003775273871714328]
[2024-08-12 00:10:40,528][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.4219557353904423
[2024-08-12 00:15:46,811][train.py][line:151][INFO] [testing]total_number: 142618,error: 13.382388336635207,total_acc: 0.058449845761060715
[2024-08-12 00:15:46,818][train.py][line:91][INFO] ---------------epoch 34---------------
lr: [0.00370706659666029]
[2024-08-12 00:28:23,832][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.38696861561939794
[2024-08-12 00:33:29,734][train.py][line:151][INFO] [testing]total_number: 142618,error: 13.394970045115107,total_acc: 0.06227124109864235
[2024-08-12 00:33:29,740][train.py][line:91][INFO] ---------------epoch 35---------------
lr: [0.003637670950532277]
[2024-08-12 00:46:08,057][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.3804887603132092
[2024-08-12 00:51:30,030][train.py][line:151][INFO] [testing]total_number: 142618,error: 0.5930100690636259,total_acc: 0.8080256581306458
[2024-08-12 00:51:30,490][train.py][line:91][INFO] ---------------epoch 36---------------
lr: [0.003567155415372195]
[2024-08-12 01:05:23,559][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.3605691155397268
[2024-08-12 01:10:32,563][train.py][line:151][INFO] [testing]total_number: 142618,error: 33.766945205119825,total_acc: 0.03789844363927841
[2024-08-12 01:10:32,627][train.py][line:91][INFO] ---------------epoch 37---------------
lr: [0.0034955895783057404]
[2024-08-12 01:23:16,511][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.33267704813270943
[2024-08-12 01:28:19,042][train.py][line:151][INFO] [testing]total_number: 142618,error: 6.276024589098547,total_acc: 0.18964646756649017
[2024-08-12 01:28:19,050][train.py][line:91][INFO] ---------------epoch 38---------------
lr: [0.0034230440628599283]
[2024-08-12 01:40:59,712][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.3192147715041991
[2024-08-12 01:46:07,184][train.py][line:151][INFO] [testing]total_number: 142618,error: 13.868586441216049,total_acc: 0.028979511931538582
[2024-08-12 01:46:07,189][train.py][line:91][INFO] ---------------epoch 39---------------
lr: [0.003349590459257094]
[2024-08-12 01:59:43,063][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.3041129819685205
[2024-08-12 02:07:49,183][train.py][line:151][INFO] [testing]total_number: 142618,error: 31.87410193158127,total_acc: 0.03622964769601822
[2024-08-12 02:07:49,190][train.py][line:91][INFO] ---------------epoch 40---------------
lr: [0.0032753012537540733]
[2024-08-12 02:22:25,483][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.2964193900152975
[2024-08-12 02:29:13,398][train.py][line:151][INFO] [testing]total_number: 142618,error: 18.208771004122553,total_acc: 0.08340462297201157
[2024-08-12 02:29:13,403][train.py][line:91][INFO] ---------------epoch 41---------------
lr: [0.0032002497570962395]
[2024-08-12 02:43:18,189][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.27629457830642323
[2024-08-12 02:50:25,143][train.py][line:151][INFO] [testing]total_number: 142618,error: 61.98159365582064,total_acc: 0.04024737328290939
[2024-08-12 02:50:25,149][train.py][line:91][INFO] ---------------epoch 42---------------
lr: [0.0031245100321568584]
[2024-08-12 03:04:06,132][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.2564859592026065
[2024-08-12 03:12:08,280][train.py][line:151][INFO] [testing]total_number: 142618,error: 22.894686599907455,total_acc: 0.08389543741941452
[2024-08-12 03:12:08,286][train.py][line:91][INFO] ---------------epoch 43---------------
lr: [0.003048156820833086]
[2024-08-12 03:27:14,578][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.24549128813297216
[2024-08-12 03:32:38,541][train.py][line:151][INFO] [testing]total_number: 142618,error: 16.956590715085074,total_acc: 0.022942405194044113
[2024-08-12 03:32:38,547][train.py][line:91][INFO] ---------------epoch 44---------------
lr: [0.002971265470270641]
[2024-08-12 03:48:36,206][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.24280265093299278
[2024-08-12 03:56:17,488][train.py][line:151][INFO] [testing]total_number: 142618,error: 0.20305688788464826,total_acc: 0.9284873008728027
[2024-08-12 03:56:17,976][train.py][line:91][INFO] ---------------epoch 45---------------
lr: [0.002893911858489748]
[2024-08-12 04:09:53,386][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.23357100420513296
[2024-08-12 04:18:19,107][train.py][line:151][INFO] [testing]total_number: 142618,error: 19.172168623375068,total_acc: 0.07291506230831146
[2024-08-12 04:18:19,113][train.py][line:91][INFO] ---------------epoch 46---------------
lr: [0.0028161723194856775]
[2024-08-12 04:33:04,795][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.21612973824910284
[2024-08-12 04:41:54,602][train.py][line:151][INFO] [testing]total_number: 142618,error: 21.463645699813288,total_acc: 0.024905692785978317
[2024-08-12 04:41:54,612][train.py][line:91][INFO] ---------------epoch 47---------------
lr: [0.0027381235678775244]
[2024-08-12 04:57:05,694][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.2011638849431578
[2024-08-12 05:04:51,924][train.py][line:151][INFO] [testing]total_number: 142618,error: 9.234779156089992,total_acc: 0.07725532352924347
[2024-08-12 05:04:52,040][train.py][line:91][INFO] ---------------epoch 48---------------
lr: [0.0026598426231794034]
[2024-08-12 05:20:25,975][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.19455853729329495
[2024-08-12 05:30:42,666][train.py][line:151][INFO] [testing]total_number: 142618,error: 1.4687338708085937,total_acc: 0.7013069987297058
[2024-08-12 05:30:42,916][train.py][line:91][INFO] ---------------epoch 49---------------
lr: [0.002581406733768574]
[2024-08-12 05:46:35,124][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.18037625275446498
[2024-08-12 05:56:10,348][train.py][line:151][INFO] [testing]total_number: 142618,error: 23.20639162139757,total_acc: 0.07319553196430206
[2024-08-12 05:56:10,554][train.py][line:91][INFO] ---------------epoch 50---------------
lr: [0.0025028933006251692]
[2024-08-12 06:13:14,622][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.1752407087315578
[2024-08-12 06:23:13,357][train.py][line:151][INFO] [testing]total_number: 142618,error: 22.780631432622116,total_acc: 0.08147639036178589
[2024-08-12 06:23:13,515][train.py][line:91][INFO] ---------------epoch 51---------------
lr: [0.0024243798009185463]
[2024-08-12 06:38:15,055][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.16423904597957575
[2024-08-12 06:46:59,994][train.py][line:151][INFO] [testing]total_number: 142618,error: 2.50979100843394,total_acc: 0.5642696022987366
[2024-08-12 06:47:00,081][train.py][line:91][INFO] ---------------epoch 52---------------
lr: [0.0023459437115152058]
[2024-08-12 07:01:36,929][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.15399476125862815
[2024-08-12 07:10:08,588][train.py][line:151][INFO] [testing]total_number: 142618,error: 3.985952959086055,total_acc: 0.4379180669784546
[2024-08-12 07:10:08,666][train.py][line:91][INFO] ---------------epoch 53---------------
lr: [0.002267662432483375]
[2024-08-12 07:26:20,478][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.1462023771320864
[2024-08-12 07:34:39,538][train.py][line:151][INFO] [testing]total_number: 142618,error: 7.14948973152208,total_acc: 0.251609206199646
[2024-08-12 07:34:39,628][train.py][line:91][INFO] ---------------epoch 54---------------
lr: [0.0021896132106692073]
[2024-08-12 07:49:31,616][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.14308995416862255
[2024-08-12 07:58:00,963][train.py][line:151][INFO] [testing]total_number: 142618,error: 23.34475464300445,total_acc: 0.052538949996232986
[2024-08-12 07:58:01,067][train.py][line:91][INFO] ---------------epoch 55---------------
lr: [0.0021118730634194253]
[2024-08-12 08:12:44,614][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.13723694082901555
[2024-08-12 08:23:04,390][train.py][line:151][INFO] [testing]total_number: 142618,error: 26.692530472086084,total_acc: 0.05219537392258644
[2024-08-12 08:23:04,612][train.py][line:91][INFO] ---------------epoch 56---------------
lr: [0.0020345187025249604]
[2024-08-12 08:37:58,220][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.12819738399829078
[2024-08-12 08:47:11,088][train.py][line:151][INFO] [testing]total_number: 142618,error: 1.2919025971573226,total_acc: 0.7216830849647522
[2024-08-12 08:47:11,096][train.py][line:91][INFO] ---------------epoch 57---------------
lr: [0.0019576264584598496]
[2024-08-12 09:03:14,890][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.11761276487892405
[2024-08-12 09:12:31,555][train.py][line:151][INFO] [testing]total_number: 142618,error: 52.43694814159051,total_acc: 0.047238077968358994
[2024-08-12 09:12:31,569][train.py][line:91][INFO] ---------------epoch 58---------------
lr: [0.001881272204989142]
[2024-08-12 09:26:41,354][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.11410748287407349
[2024-08-12 09:32:40,014][train.py][line:151][INFO] [testing]total_number: 142618,error: 38.14091643000876,total_acc: 0.048331908881664276
[2024-08-12 09:32:40,022][train.py][line:91][INFO] ---------------epoch 59---------------
lr: [0.0018055312842190899]
[2024-08-12 09:46:16,264][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.11145187596878914
[2024-08-12 09:55:26,693][train.py][line:151][INFO] [testing]total_number: 142618,error: 28.087680808188328,total_acc: 0.07177916169166565
[2024-08-12 09:55:26,763][train.py][line:91][INFO] ---------------epoch 60---------------
lr: [0.001730478432162224]
[2024-08-12 10:10:40,394][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.0936109293458823
[2024-08-12 10:18:46,866][train.py][line:151][INFO] [testing]total_number: 142618,error: 3.0574934012930055,total_acc: 0.4967535734176636
[2024-08-12 10:18:46,875][train.py][line:91][INFO] ---------------epoch 61---------------
lr: [0.0016561877048890889]
[2024-08-12 10:32:41,594][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.09799211306171864
[2024-08-12 10:40:20,623][train.py][line:151][INFO] [testing]total_number: 142618,error: 0.10178334848189226,total_acc: 0.9637212753295898
[2024-08-12 10:40:21,151][train.py][line:91][INFO] ---------------epoch 62---------------
lr: [0.001582732405337639]
[2024-08-12 10:54:39,863][train.py][line:111][INFO] [training]total_num: 142618.0,error: 0.09383858942873809
[2024-08-12 11:02:45,640][train.py][line:151][INFO] [testing]total_number: 142618,error: 5.444778808578518,total_acc: 0.39330941438674927
[2024-08-12 11:02:45,646][train.py][line:91][INFO] ---------------epoch 63---------------
lr: [0.0015101850108501264]
