[2024-09-17 18:49:20,930][test.py][line:34][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0', batch_size=128, model_path='/data/ylh/MyExps/MOFV2/checkpoints/AtLSmall/AtLSmall_epoch_14.pth', device='0', mode='test', top_k=5, parallel_model=False, test_name='AtLSmall', num_workers=20, log_name='log/test/test_AtLSmall_2024_09_17_18:49:12.log')
[2024-09-17 18:49:20,931][test.py][line:35][INFO] ---------------model---------------
AtLSmall(
  (embed): Embedding(8501, 31, padding_idx=0)
  (att): TransformerEncoder(
    (positionEnbeding): PositionEmbedding()
    (encoder_layers): ModuleList(
      (0-7): 8 x EncoderLayer(
        (mha): MultiHeadAttention(
          (WQ): Linear(in_features=320, out_features=320, bias=True)
          (WK): Linear(in_features=320, out_features=320, bias=True)
          (WV): Linear(in_features=320, out_features=320, bias=True)
          (scaled_dot_product_attn): ScaledDotProductAttention()
          (linear): Linear(in_features=320, out_features=320, bias=True)
        )
        (dropout1): Dropout(p=0.0, inplace=False)
        (layernorm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (ffn): FeedForwardNetwork(
          (linear1): Linear(in_features=320, out_features=512, bias=True)
          (linear2): Linear(in_features=512, out_features=320, bias=True)
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (dropout2): Dropout(p=0.0, inplace=False)
        (layernorm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=320, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=230, bias=True)
  )
)
[2024-09-17 18:49:20,931][test.py][line:36][INFO] ---------------device---------------
cuda:0
[2024-09-17 18:49:20,931][test.py][line:37][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-09-17 18:52:44,037][test.py][line:78][INFO] ---------------performance---------------
total_num:142729
error:4.995103
total_acc:0.06317567080259323
f1_score:0.002013719640672207
top5_acc:0.25666823983192444
head_acc:0.07969303911853494
medium_acc:4.094836441794278e-05
tail_add:0.0

[2024-09-17 18:52:44,037][test.py][line:89][INFO] ---------------per_class_acc---------------
[0.07221225, 0.6258215, 0.0, 0.026560139, 0.0073382254, 0.0, 0.0, 0.0, 0.0035542918, 0.0, 0.00085251493, 0.0, 0.0051034875, 0.024188414, 0.0003182686, 0.0, 0.0, 0.0060521415, 0.096933305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16862586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00787756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0010964912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
