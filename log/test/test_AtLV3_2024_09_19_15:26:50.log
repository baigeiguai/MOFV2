[2024-09-19 15:26:57,548][test.py][line:34][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped_Short/0/', batch_size=128, model_path='/data/ylh/MyExps/MOFV2/checkpoints/AtLV3/AtLV3_epoch_56.pth', device='2', mode='test', top_k=5, parallel_model=False, test_name='AtLV3', num_workers=20, log_name='log/test/test_AtLV3_2024_09_19_15:26:50.log')
[2024-09-19 15:26:57,551][test.py][line:35][INFO] ---------------model---------------
AtLV3(
  (embed): Embedding(851, 63)
  (att): TransformerEncoder(
    (positionEnbeding): PositionEmbedding()
    (encoder_layers): ModuleList(
      (0-15): 16 x EncoderLayer(
        (mha): MultiHeadAttention(
          (WQ): Linear(in_features=64, out_features=64, bias=True)
          (WK): Linear(in_features=64, out_features=64, bias=True)
          (WV): Linear(in_features=64, out_features=64, bias=True)
          (scaled_dot_product_attn): ScaledDotProductAttention()
          (linear): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0, inplace=False)
        (layernorm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (ffn): FeedForwardNetwork(
          (linear1): Linear(in_features=64, out_features=512, bias=True)
          (linear2): Linear(in_features=512, out_features=64, bias=True)
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (dropout2): Dropout(p=0, inplace=False)
        (layernorm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=64, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=230, bias=True)
  )
)
[2024-09-19 15:26:57,551][test.py][line:36][INFO] ---------------device---------------
cuda:2
[2024-09-19 15:26:57,551][test.py][line:37][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-09-19 15:33:22,428][test.py][line:78][INFO] ---------------performance---------------
total_num:142729
error:3.215570
total_acc:0.33408066630363464
f1_score:0.18025845289230347
top5_acc:0.716294527053833
head_acc:0.3694829779201903
medium_acc:0.20756725768836046
tail_add:0.15728023084826262

[2024-09-19 15:33:22,428][test.py][line:89][INFO] ---------------per_class_acc---------------
[0.45741072, 0.42113632, 0.013157895, 0.34776506, 0.23549032, 0.055555556, 0.12823674, 0.09659091, 0.3047805, 0.032786883, 0.1743393, 0.11061947, 0.095832154, 0.4423934, 0.24846171, 0.0, 0.0, 0.20437616, 0.6144113, 0.108315095, 0.0, 0.0, 0.10236221, 0.0, 0.0, 0.065789476, 0.0, 0.0, 0.17067833, 0.056338027, 0.13405797, 0.0, 0.34873664, 0.032258064, 0.0, 0.09798271, 0.016949153, 0.0, 0.0, 0.12244898, 0.0, 0.10526316, 0.17484832, 0.027027028, 0.060702875, 0.041666668, 0.13333334, 0.027027028, 0.0, 0.074074075, 0.0, 0.07783418, 0.1971831, 0.0078125, 0.01986755, 0.14399153, 0.06639839, 0.09039548, 0.037593983, 0.24494332, 0.596424, 0.40076923, 0.11434511, 0.0, 0.1262136, 0.060606062, 0.0, 0.0, 0.0952381, 0.18707483, 0.027777778, 0.1627907, 0.025477707, 0.2027972, 0.0, 0.20338982, 0.032258064, 0.1567696, 0.08208955, 0.05511811, 0.06896552, 0.34985834, 0.0625, 0.041666668, 0.093541205, 0.2012012, 0.24930748, 0.36240208, 0.0, 0.17307693, 0.022222223, 0.16768916, 0.0, 0.13207547, 0.021276595, 0.21767241, 0.104166664, 0.4509804, 0.0, 0.0, 0.0, 0.07692308, 0.0, 0.032786883, 1.0, 0.018867925, 0.0, 0.05263158, 0.08695652, 0.065727696, 0.0, 0.0, 0.2733813, 0.184, 0.0, 0.0952381, 0.121212125, 0.11702128, 0.0625, 0.035714287, 0.06896552, 0.12463768, 0.44871795, 0.42553192, 0.36666667, 0.071428575, 0.0, 0.24175824, 0.28089887, 0.20731707, 0.27142859, 0.0, 0.0, 0.035714287, 0.04, 0.13043478, 0.03508772, 0.08219178, 0.11304348, 0.1388889, 0.0952381, 0.1941392, 0.1754386, 0.31958762, 0.29015544, 0.27653632, 0.27228525, 0.55007875, 0.33333334, 0.055555556, 0.0, 0.1594203, 0.0, 0.18848167, 0.15261044, 0.0, 0.0, 0.07692308, 0.07027027, 0.2734375, 0.19767442, 0.06896552, 0.33744857, 0.18367347, 0.22077923, 0.41853034, 0.23464912, 0.0, 0.14647888, 0.18731989, 0.0, 0.032258064, 0.22677596, 0.0625, 0.083333336, 0.18341708, 0.4, 0.23129252, 0.072, 0.05, 0.04, 0.28865978, 0.0, 0.0, 0.0, 0.041666668, 0.4090909, 0.0, 0.0, 0.03409091, 0.1969697, 0.47457626, 0.13157895, 0.24861878, 0.0, 0.46551725, 0.3690476, 0.6917808, 0.41791046, 0.30769232, 0.04, 0.125, 0.23636363, 0.234375, 0.7972028, 0.112676054, 0.0, 0.0, 0.51428574, 0.61290324, 0.51724136, 0.041666668, 0.3939394, 0.14285715, 0.09090909, 0.13636364, 0.5276074, 0.43661973, 0.16666667, 0.6369863, 0.47244096, 0.35897437, 0.39473686, 0.3125, 0.75, 0.14285715, 0.5681818, 0.4027778, 0.13636364, 0.45762712]
