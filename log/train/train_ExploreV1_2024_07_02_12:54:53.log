[2024-07-02 12:54:55,207][train.py][line:65][INFO] ---------------args---------------
Namespace(data_path='../MOF/data/Pymatgen_Wrapped/3/', train_name='ExploreV1', model_path=None, learning_rate=0.0001, min_learning_rate=1e-06, start_scheduler_step=25, weight_decay=1e-05, momentum=0.99, batch_size=256, class_num=230, epoch_num=200, model_save_path='./checkpoints/ExploreV1_4', device='3', scheduler_T=None, num_workers=20, log_name='log/train//train_ExploreV1_2024_07_02_12:54:53.log')
[2024-07-02 12:54:55,209][train.py][line:66][INFO] ---------------model---------------
ExplorerV1(
  (selective_block): BiMamba(
    (layers): ModuleList(
      (0-3): 4 x ResidualBlock(
        (mixer): MambaBlock(
          (in_proj): Linear(in_features=1, out_features=4, bias=False)
          (conv1d): Conv1d(2, 2, kernel_size=(4,), stride=(1,), padding=(3,), groups=2)
          (x_proj): Linear(in_features=2, out_features=33, bias=False)
          (dt_proj): Linear(in_features=1, out_features=2, bias=True)
          (out_proj): Linear(in_features=2, out_features=1, bias=False)
        )
        (norm): RMSNorm()
      )
    )
    (norm_f): RMSNorm()
  )
  (conv): ResTcn(
    (conv): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(2, 32, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (2): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (3): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (4): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (5): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (6): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (7): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (8): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (10): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (12): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (14): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (16): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (18): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (20): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (21): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (22): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (23): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (24): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (25): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (mlp): Linear(in_features=1024, out_features=230, bias=True)
  )
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): Linear(in_features=512, out_features=230, bias=True)
  )
)
[2024-07-02 12:54:55,209][train.py][line:67][INFO] ---------------device---------------
cuda:3
[2024-07-02 12:54:55,209][train.py][line:68][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 1e-05
)
[2024-07-02 12:54:55,209][train.py][line:69][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-07-02 12:54:55,212][train.py][line:81][INFO] ---------------epoch 1---------------
lr: [0.0001]
[2024-07-02 12:56:20,187][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.942000720940583
[2024-07-02 12:57:21,247][train.py][line:136][INFO] [testing]total_number: 142619,error: 11.34459448875265,total_acc: 0.05472622811794281
[2024-07-02 12:57:21,523][train.py][line:81][INFO] ---------------epoch 2---------------
lr: [0.0001]
[2024-07-02 12:58:44,821][train.py][line:98][INFO] [training]total_num: 142619.0,error: 3.8325318715251084
[2024-07-02 12:59:46,222][train.py][line:136][INFO] [testing]total_number: 142619,error: 3.584434482222753,total_acc: 0.10152223706245422
[2024-07-02 12:59:46,487][train.py][line:81][INFO] ---------------epoch 3---------------
lr: [0.0001]
[2024-07-02 13:01:10,035][train.py][line:98][INFO] [training]total_num: 142619.0,error: 3.5184043240039906
[2024-07-02 13:02:11,412][train.py][line:136][INFO] [testing]total_number: 142619,error: 3.4007455753096454,total_acc: 0.13952559232711792
[2024-07-02 13:02:11,678][train.py][line:81][INFO] ---------------epoch 4---------------
lr: [0.0001]
[2024-07-02 13:03:35,205][train.py][line:98][INFO] [training]total_num: 142619.0,error: 3.284807195477452
[2024-07-02 13:04:36,720][train.py][line:136][INFO] [testing]total_number: 142619,error: 3.2675842900648187,total_acc: 0.16294462978839874
[2024-07-02 13:04:37,007][train.py][line:81][INFO] ---------------epoch 5---------------
lr: [0.0001]
[2024-07-02 13:06:01,407][train.py][line:98][INFO] [training]total_num: 142619.0,error: 3.1169827394451657
[2024-07-02 13:07:02,670][train.py][line:136][INFO] [testing]total_number: 142619,error: 3.027446685107887,total_acc: 0.1941957175731659
[2024-07-02 13:07:02,946][train.py][line:81][INFO] ---------------epoch 6---------------
lr: [0.0001]
[2024-07-02 13:08:26,827][train.py][line:98][INFO] [training]total_num: 142619.0,error: 3.016584390444113
[2024-07-02 13:09:28,222][train.py][line:136][INFO] [testing]total_number: 142619,error: 2.9422332259780126,total_acc: 0.20982477068901062
[2024-07-02 13:09:28,532][train.py][line:81][INFO] ---------------epoch 7---------------
lr: [0.0001]
[2024-07-02 13:10:52,501][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.872725396291584
[2024-07-02 13:11:53,858][train.py][line:136][INFO] [testing]total_number: 142619,error: 2.843154470125834,total_acc: 0.2132745236158371
[2024-07-02 13:11:54,136][train.py][line:81][INFO] ---------------epoch 8---------------
lr: [0.0001]
[2024-07-02 13:13:17,564][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.91555333179785
[2024-07-02 13:14:18,761][train.py][line:136][INFO] [testing]total_number: 142619,error: 2.8798125821647913,total_acc: 0.22030724585056305
[2024-07-02 13:14:19,035][train.py][line:81][INFO] ---------------epoch 9---------------
lr: [0.0001]
[2024-07-02 13:15:42,477][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.7326216921738697
[2024-07-02 13:16:43,792][train.py][line:136][INFO] [testing]total_number: 142619,error: 2.6750119746999537,total_acc: 0.2585349678993225
[2024-07-02 13:16:44,062][train.py][line:81][INFO] ---------------epoch 10---------------
lr: [0.0001]
[2024-07-02 13:18:07,249][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.6326705910635333
[2024-07-02 13:19:08,663][train.py][line:136][INFO] [testing]total_number: 142619,error: 2.6735123903193374,total_acc: 0.2641162872314453
[2024-07-02 13:19:08,944][train.py][line:81][INFO] ---------------epoch 11---------------
lr: [0.0001]
[2024-07-02 13:20:32,172][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.6505011620250998
[2024-07-02 13:21:33,202][train.py][line:136][INFO] [testing]total_number: 142619,error: 2.57320566295732,total_acc: 0.28505319356918335
[2024-07-02 13:21:33,462][train.py][line:81][INFO] ---------------epoch 12---------------
lr: [0.0001]
[2024-07-02 13:22:56,649][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.4873905701840178
[2024-07-02 13:23:57,492][train.py][line:136][INFO] [testing]total_number: 142619,error: 2.3796450419628874,total_acc: 0.3253563642501831
[2024-07-02 13:23:57,762][train.py][line:81][INFO] ---------------epoch 13---------------
lr: [0.0001]
[2024-07-02 13:25:20,934][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.4135123594855585
[2024-07-02 13:26:22,145][train.py][line:136][INFO] [testing]total_number: 142619,error: 2.195857507751343,total_acc: 0.36213967204093933
[2024-07-02 13:26:22,528][train.py][line:81][INFO] ---------------epoch 14---------------
lr: [0.0001]
[2024-07-02 13:27:45,560][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.21791506046099
[2024-07-02 13:28:46,568][train.py][line:136][INFO] [testing]total_number: 142619,error: 2.2779501515922815,total_acc: 0.3481513559818268
[2024-07-02 13:28:46,571][train.py][line:81][INFO] ---------------epoch 15---------------
lr: [0.0001]
[2024-07-02 13:30:09,710][train.py][line:98][INFO] [training]total_num: 142619.0,error: 2.1828719834063914
[2024-07-02 13:31:11,212][train.py][line:136][INFO] [testing]total_number: 142619,error: 1.927120051274063,total_acc: 0.43218645453453064
[2024-07-02 13:31:11,471][train.py][line:81][INFO] ---------------epoch 16---------------
lr: [0.0001]
[2024-07-02 13:32:34,913][train.py][line:98][INFO] [training]total_num: 142619.0,error: 1.9504736253978512
[2024-07-02 13:33:36,288][train.py][line:136][INFO] [testing]total_number: 142619,error: 1.9228694857435022,total_acc: 0.43277543783187866
[2024-07-02 13:33:36,551][train.py][line:81][INFO] ---------------epoch 17---------------
lr: [0.0001]
[2024-07-02 13:34:59,634][train.py][line:98][INFO] [training]total_num: 142619.0,error: 1.8909894301958963
[2024-07-02 13:36:00,755][train.py][line:136][INFO] [testing]total_number: 142619,error: 1.7202271871955683,total_acc: 0.4864639341831207
[2024-07-02 13:36:01,015][train.py][line:81][INFO] ---------------epoch 18---------------
lr: [0.0001]
[2024-07-02 13:37:24,107][train.py][line:98][INFO] [training]total_num: 142619.0,error: 1.6626468119046367
[2024-07-02 13:38:25,186][train.py][line:136][INFO] [testing]total_number: 142619,error: 1.4872403401643672,total_acc: 0.5455654859542847
[2024-07-02 13:38:25,472][train.py][line:81][INFO] ---------------epoch 19---------------
lr: [0.0001]
[2024-07-02 13:39:48,621][train.py][line:98][INFO] [training]total_num: 142619.0,error: 1.5362122997324517
[2024-07-02 13:40:49,783][train.py][line:136][INFO] [testing]total_number: 142619,error: 1.3902178313715239,total_acc: 0.5732826590538025
[2024-07-02 13:40:50,086][train.py][line:81][INFO] ---------------epoch 20---------------
lr: [0.0001]
[2024-07-02 13:42:13,237][train.py][line:98][INFO] [training]total_num: 142619.0,error: 1.3582843599167276
[2024-07-02 13:43:14,257][train.py][line:136][INFO] [testing]total_number: 142619,error: 1.155736303075831,total_acc: 0.6414783596992493
[2024-07-02 13:43:14,531][train.py][line:81][INFO] ---------------epoch 21---------------
lr: [0.0001]
[2024-07-02 13:44:37,741][train.py][line:98][INFO] [training]total_num: 142619.0,error: 1.1796374081085759
[2024-07-02 13:45:38,687][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.9542472618268737,total_acc: 0.6992616653442383
[2024-07-02 13:45:38,985][train.py][line:81][INFO] ---------------epoch 22---------------
lr: [0.0001]
[2024-07-02 13:47:02,201][train.py][line:98][INFO] [training]total_num: 142619.0,error: 1.0617802463313366
[2024-07-02 13:48:03,150][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.9452938255688823,total_acc: 0.6964569687843323
[2024-07-02 13:48:03,411][train.py][line:81][INFO] ---------------epoch 23---------------
lr: [0.0001]
[2024-07-02 13:49:26,774][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.8251364988321108
[2024-07-02 13:50:28,129][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.8544182944910746,total_acc: 0.7254924178123474
[2024-07-02 13:50:28,401][train.py][line:81][INFO] ---------------epoch 24---------------
lr: [0.0001]
[2024-07-02 13:51:51,618][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.6662481359556212
[2024-07-02 13:52:52,879][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.545009416785646,total_acc: 0.8221134543418884
[2024-07-02 13:52:53,148][train.py][line:81][INFO] ---------------epoch 25---------------
lr: [0.0001]
[2024-07-02 13:54:16,491][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.5706476665874745
[2024-07-02 13:55:17,604][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.4668892266374108,total_acc: 0.8448944687843323
[2024-07-02 13:55:17,872][train.py][line:81][INFO] ---------------epoch 26---------------
lr: [0.0001]
[2024-07-02 13:56:41,103][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.444900004470602
[2024-07-02 13:57:42,089][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.45655584722387454,total_acc: 0.8501041531562805
[2024-07-02 13:57:42,351][train.py][line:81][INFO] ---------------epoch 27---------------
lr: [9.998404856757448e-05]
[2024-07-02 13:59:05,442][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.37561207550003173
[2024-07-02 14:00:06,580][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.49403578235853646,total_acc: 0.8449856042861938
[2024-07-02 14:00:06,583][train.py][line:81][INFO] ---------------epoch 28---------------
lr: [9.994417866080335e-05]
[2024-07-02 14:01:29,745][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.3036943260738824
[2024-07-02 14:02:31,048][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.31616256155522793,total_acc: 0.8977766036987305
[2024-07-02 14:02:31,331][train.py][line:81][INFO] ---------------epoch 29---------------
lr: [9.98883798072465e-05]
[2024-07-02 14:03:54,928][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.26433229521709556
[2024-07-02 14:04:56,026][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.2647567715310881,total_acc: 0.913608968257904
[2024-07-02 14:04:56,290][train.py][line:81][INFO] ---------------epoch 30---------------
lr: [9.981666998763073e-05]
[2024-07-02 14:06:19,448][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.26860581849642257
[2024-07-02 14:07:20,722][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.30430056934793154,total_acc: 0.9034209847450256
[2024-07-02 14:07:20,725][train.py][line:81][INFO] ---------------epoch 31---------------
lr: [9.972907231021598e-05]
[2024-07-02 14:08:44,340][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.2073593502930293
[2024-07-02 14:09:45,921][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.3482419240374303,total_acc: 0.8914800882339478
[2024-07-02 14:09:45,924][train.py][line:81][INFO] ---------------epoch 32---------------
lr: [9.962561500334795e-05]
[2024-07-02 14:11:09,275][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.19475690726230435
[2024-07-02 14:12:11,350][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.2944025850280168,total_acc: 0.9067866206169128
[2024-07-02 14:12:11,353][train.py][line:81][INFO] ---------------epoch 33---------------
lr: [9.950633140636083e-05]
[2024-07-02 14:13:34,786][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.19007963631037914
[2024-07-02 14:14:36,111][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.22558767356123802,total_acc: 0.9293922781944275
[2024-07-02 14:14:36,384][train.py][line:81][INFO] ---------------epoch 34---------------
lr: [9.93712599588324e-05]
[2024-07-02 14:15:59,802][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.4755271311704043
[2024-07-02 14:17:02,180][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.23459932137056128,total_acc: 0.9260757565498352
[2024-07-02 14:17:02,183][train.py][line:81][INFO] ---------------epoch 35---------------
lr: [9.922044418819656e-05]
[2024-07-02 14:18:25,744][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.15746319437307035
[2024-07-02 14:19:27,754][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.20433922171103933,total_acc: 0.9349806308746338
[2024-07-02 14:19:28,057][train.py][line:81][INFO] ---------------epoch 36---------------
lr: [9.905393269571507e-05]
[2024-07-02 14:20:52,282][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.1462644683329243
[2024-07-02 14:21:53,557][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.35084112537100065,total_acc: 0.8924897909164429
[2024-07-02 14:21:53,561][train.py][line:81][INFO] ---------------epoch 37---------------
lr: [9.887177914081493e-05]
[2024-07-02 14:23:16,766][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.15457664282516914
[2024-07-02 14:24:18,645][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.21921625320885516,total_acc: 0.9314677715301514
[2024-07-02 14:24:18,698][train.py][line:81][INFO] ---------------epoch 38---------------
lr: [9.867404222379538e-05]
[2024-07-02 14:25:42,394][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.12747979555601016
[2024-07-02 14:26:43,761][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.2017070230621686,total_acc: 0.9362216591835022
[2024-07-02 14:26:44,033][train.py][line:81][INFO] ---------------epoch 39---------------
lr: [9.846078566691062e-05]
[2024-07-02 14:28:07,375][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.127566919536561
[2024-07-02 14:29:08,386][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.3506110919943304,total_acc: 0.895778238773346
[2024-07-02 14:29:08,389][train.py][line:81][INFO] ---------------epoch 40---------------
lr: [9.823207819383371e-05]
[2024-07-02 14:30:31,601][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.13487759143351874
[2024-07-02 14:31:33,404][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.17524539388580815,total_acc: 0.9445375204086304
[2024-07-02 14:31:33,684][train.py][line:81][INFO] ---------------epoch 41---------------
lr: [9.798799350750923e-05]
[2024-07-02 14:32:58,694][train.py][line:98][INFO] [training]total_num: 142619.0,error: 0.11278917512638455
[2024-07-02 14:34:00,557][train.py][line:136][INFO] [testing]total_number: 142619,error: 0.17063059358022023,total_acc: 0.9462764263153076
[2024-07-02 14:34:00,993][train.py][line:81][INFO] ---------------epoch 42---------------
lr: [9.772861026640093e-05]
