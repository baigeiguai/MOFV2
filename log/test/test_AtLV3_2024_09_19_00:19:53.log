[2024-09-19 00:19:58,417][test.py][line:34][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped_Short/0/', batch_size=128, model_path='/data/ylh/MyExps/MOFV2/checkpoints/AtLV3/AtLV3_epoch_175.pth', device='2', mode='test', top_k=5, parallel_model=False, test_name='AtLV3', num_workers=20, log_name='log/test/test_AtLV3_2024_09_19_00:19:53.log')
[2024-09-19 00:19:58,419][test.py][line:35][INFO] ---------------model---------------
AtLV3(
  (embed): Embedding(851, 63)
  (att): TransformerEncoder(
    (positionEnbeding): PositionEmbedding()
    (encoder_layers): ModuleList(
      (0-7): 8 x EncoderLayer(
        (mha): MultiHeadAttention(
          (WQ): Linear(in_features=64, out_features=64, bias=True)
          (WK): Linear(in_features=64, out_features=64, bias=True)
          (WV): Linear(in_features=64, out_features=64, bias=True)
          (scaled_dot_product_attn): ScaledDotProductAttention()
          (linear): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0, inplace=False)
        (layernorm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (ffn): FeedForwardNetwork(
          (linear1): Linear(in_features=64, out_features=128, bias=True)
          (linear2): Linear(in_features=128, out_features=64, bias=True)
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (dropout2): Dropout(p=0, inplace=False)
        (layernorm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=64, out_features=230, bias=True)
  )
)
[2024-09-19 00:19:58,419][test.py][line:36][INFO] ---------------device---------------
cuda:2
[2024-09-19 00:19:58,419][test.py][line:37][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-09-19 00:21:50,378][test.py][line:78][INFO] ---------------performance---------------
total_num:142729
error:2.270240
total_acc:0.36154529452323914
f1_score:0.1537170261144638
top5_acc:0.7530494928359985
head_acc:0.4072077464716175
medium_acc:0.19884525671356498
tail_add:0.13114443037966972

[2024-09-19 00:21:50,379][test.py][line:89][INFO] ---------------per_class_acc---------------
[0.44903252, 0.5377358, 0.0, 0.44817534, 0.31532133, 0.0, 0.06781751, 0.056818184, 0.44286475, 0.0, 0.15089513, 0.15486726, 0.06209243, 0.415871, 0.308084, 0.65217394, 0.0, 0.20158286, 0.6594467, 0.06892779, 0.0, 0.0, 0.023622047, 0.0, 0.0, 0.013157895, 0.0, 0.0, 0.11378556, 0.0, 0.02173913, 0.0, 0.33522496, 0.038709678, 0.0, 0.1887608, 0.0, 0.045454547, 0.0, 0.020408163, 0.0, 0.13157895, 0.17429675, 0.0, 0.019169329, 0.0, 0.2, 0.0, 0.0, 0.12962963, 0.0, 0.065989845, 0.0, 0.0, 0.0066225166, 0.054526206, 0.0020120724, 0.07909604, 0.0, 0.2505001, 0.6262239, 0.47403845, 0.16008316, 0.0, 0.106796116, 0.0, 0.0, 0.0, 0.06349207, 0.15646258, 0.013888889, 0.10232558, 0.0, 0.10489511, 0.0, 0.16737288, 0.016129032, 0.14251782, 0.02238806, 0.0, 0.0, 0.45184135, 0.0, 0.0, 0.08685969, 0.16666667, 0.17728531, 0.3691906, 0.0, 0.115384616, 0.022222223, 0.18813907, 0.0, 0.10377359, 0.0, 0.17349137, 0.0625, 0.3137255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016393442, 0.0, 0.0, 0.0, 0.0, 0.04347826, 0.065727696, 0.0, 0.0, 0.17985612, 0.096, 0.0, 0.0952381, 0.0, 0.010638298, 0.0, 0.0, 0.06896552, 0.04057971, 0.525641, 0.61702126, 0.6, 0.09821428, 0.0, 0.23076923, 0.07865169, 0.26422763, 0.47142857, 0.0, 0.0, 0.0, 0.0, 0.06521739, 0.0, 0.01369863, 0.08695652, 0.15277778, 0.11111111, 0.124542125, 0.0877193, 0.3041237, 0.26165804, 0.35893854, 0.36142626, 0.67251855, 0.33333334, 0.0, 0.0, 0.21118012, 0.0, 0.12565444, 0.064257026, 0.0, 0.0, 0.01923077, 0.048648648, 0.1875, 0.2751938, 0.20689656, 0.30041152, 0.30612245, 0.22337662, 0.34824282, 0.30372807, 0.0, 0.14647888, 0.06051873, 0.0, 0.032258064, 0.07377049, 0.0, 0.0, 0.15829146, 0.46666667, 0.027210884, 0.016, 0.0, 0.0, 0.28865978, 0.0, 0.0, 0.0, 0.020833334, 0.4090909, 0.0, 0.0, 0.011363637, 0.34848484, 0.55932206, 0.0, 0.29281768, 0.1, 0.37931034, 0.1904762, 0.69863015, 0.35820895, 0.07692308, 0.04, 0.0, 0.12727273, 0.25, 0.7785548, 0.12676056, 0.0, 0.33333334, 0.42857143, 0.32258064, 0.31034482, 0.041666668, 0.060606062, 0.071428575, 0.09090909, 0.0, 0.607362, 0.4084507, 0.16666667, 0.65753424, 0.4566929, 0.4871795, 0.28947368, 0.0625, 0.84411764, 0.26190478, 0.375, 0.4722222, 0.0, 0.33898306]
