[2024-09-19 00:19:06,589][test.py][line:34][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/2', batch_size=128, model_path='/data/ylh/MyExps/MOFV2/checkpoints/AtLV3/AtLV3_epoch_175.pth', device='2', mode='test', top_k=5, parallel_model=False, test_name='AtLV3', num_workers=20, log_name='log/test/test_AtLV3_2024_09_19_00:19:01.log')
[2024-09-19 00:19:06,590][test.py][line:35][INFO] ---------------model---------------
AtLV3(
  (embed): Embedding(851, 63)
  (att): TransformerEncoder(
    (positionEnbeding): PositionEmbedding()
    (encoder_layers): ModuleList(
      (0-7): 8 x EncoderLayer(
        (mha): MultiHeadAttention(
          (WQ): Linear(in_features=64, out_features=64, bias=True)
          (WK): Linear(in_features=64, out_features=64, bias=True)
          (WV): Linear(in_features=64, out_features=64, bias=True)
          (scaled_dot_product_attn): ScaledDotProductAttention()
          (linear): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0, inplace=False)
        (layernorm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (ffn): FeedForwardNetwork(
          (linear1): Linear(in_features=64, out_features=128, bias=True)
          (linear2): Linear(in_features=128, out_features=64, bias=True)
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (dropout2): Dropout(p=0, inplace=False)
        (layernorm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=64, out_features=230, bias=True)
  )
)
[2024-09-19 00:19:06,590][test.py][line:36][INFO] ---------------device---------------
cuda:2
[2024-09-19 00:19:06,590][test.py][line:37][INFO] ---------------lossfn---------------
CrossEntropyLoss()
