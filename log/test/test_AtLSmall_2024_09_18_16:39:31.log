[2024-09-18 16:39:35,554][test.py][line:34][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/2', batch_size=128, model_path='/data/ylh/MyExps/MOFV2/checkpoints/AtLSmall/AtLSmall_epoch_40.pth', device='2', mode='test', top_k=5, parallel_model=False, test_name='AtLSmall', num_workers=20, log_name='log/test/test_AtLSmall_2024_09_18_16:39:31.log')
[2024-09-18 16:39:35,556][test.py][line:35][INFO] ---------------model---------------
AtLSmall(
  (embed): Embedding(8501, 15, padding_idx=0)
  (att): TransformerEncoder(
    (positionEnbeding): PositionEmbedding()
    (encoder_layers): ModuleList(
      (0-7): 8 x EncoderLayer(
        (mha): MultiHeadAttention(
          (WQ): Linear(in_features=160, out_features=160, bias=True)
          (WK): Linear(in_features=160, out_features=160, bias=True)
          (WV): Linear(in_features=160, out_features=160, bias=True)
          (scaled_dot_product_attn): ScaledDotProductAttention()
          (linear): Linear(in_features=160, out_features=160, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (layernorm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
        (ffn): FeedForwardNetwork(
          (linear1): Linear(in_features=160, out_features=256, bias=True)
          (linear2): Linear(in_features=256, out_features=160, bias=True)
          (relu): LeakyReLU(negative_slope=0.01)
        )
        (dropout2): Dropout(p=0.1, inplace=False)
        (layernorm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (cls): Sequential(
    (0): Linear(in_features=160, out_features=200, bias=True)
    (1): Linear(in_features=200, out_features=230, bias=True)
  )
)
[2024-09-18 16:39:35,556][test.py][line:36][INFO] ---------------device---------------
cuda:2
[2024-09-18 16:39:35,556][test.py][line:37][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-09-18 16:42:50,043][test.py][line:78][INFO] ---------------performance---------------
total_num:141939
error:4.049810
total_acc:0.3282114267349243
f1_score:0.15993726253509521
top5_acc:0.7086635828018188
head_acc:0.364244646296671
medium_acc:0.20106841663006128
tail_add:0.14016324583238776

[2024-09-18 16:42:50,043][test.py][line:89][INFO] ---------------per_class_acc---------------
[0.40643334, 0.3359358, 0.0, 0.3897019, 0.3539288, 0.0, 0.15902519, 0.1590909, 0.39604136, 0.033333335, 0.15308748, 0.19354838, 0.1769275, 0.463579, 0.36038926, 0.6818182, 0.0, 0.31482354, 0.5786481, 0.14459161, 0.032258064, 0.0, 0.072, 0.0, 0.0, 0.05263158, 0.0, 0.0, 0.13346322, 0.04225352, 0.083636366, 0.011111111, 0.29771405, 0.09677419, 0.2, 0.14697406, 0.03448276, 0.045454547, 0.0, 0.071428575, 0.0, 0.15789473, 0.23578134, 0.054054055, 0.051446944, 0.11111111, 0.13333334, 0.0, 0.0, 0.12962963, 0.0, 0.098305084, 0.014285714, 0.04330709, 0.006666667, 0.13212574, 0.04032258, 0.08238637, 0.030303031, 0.20236501, 0.46092248, 0.32864845, 0.12108559, 0.0, 0.1262136, 0.015384615, 0.0, 0.0, 0.06349207, 0.12349914, 0.028169014, 0.098130845, 0.057692308, 0.08391608, 0.0, 0.12288135, 0.016129032, 0.09263658, 0.07462686, 0.09448819, 0.0862069, 0.34560907, 0.0625, 0.041666668, 0.100222714, 0.0962406, 0.24930748, 0.35062894, 0.0, 0.09615385, 0.022727273, 0.33333334, 0.0, 0.13207547, 0.08510638, 0.14054054, 0.0, 0.42156863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08196721, 1.0, 0.0, 0.0, 0.0, 0.04347826, 0.103286386, 0.0, 0.05882353, 0.21582733, 0.20352565, 0.0, 0.0952381, 0.09090909, 0.031914894, 0.0625, 0.071428575, 0.14942528, 0.093023255, 0.17948718, 0.40425533, 0.53333336, 0.125, 0.0, 0.16483517, 0.101123594, 0.10612245, 0.27142859, 0.2, 0.0, 0.035714287, 0.04, 0.12087912, 0.03508772, 0.15068494, 0.052173913, 0.041666668, 0.176, 0.13553114, 0.18421052, 0.20103092, 0.20207255, 0.35244754, 0.2564935, 0.5202794, 0.33333334, 0.055555556, 0.0, 0.23395444, 0.0, 0.105540894, 0.11646587, 0.0, 0.0, 0.07692308, 0.16216215, 0.21875, 0.22093023, 0.03448276, 0.3415638, 0.26530612, 0.2935065, 0.35897437, 0.30515915, 0.07692308, 0.2259887, 0.09798271, 0.025, 0.0, 0.17534247, 0.0625, 0.083333336, 0.12342569, 0.14285715, 0.034013607, 0.048, 0.05, 0.04, 0.26804122, 0.0, 0.0, 0.0, 0.041666668, 0.36363637, 0.0, 0.09090909, 0.011363637, 0.1969697, 0.47457626, 0.05263158, 0.18333334, 0.0, 0.5, 0.3452381, 0.6712329, 0.52238804, 0.0, 0.16, 0.041666668, 0.3272727, 0.34375, 0.6293706, 0.2535211, 0.15384616, 0.0, 0.14285715, 0.32258064, 0.37931034, 0.041666668, 0.121212125, 0.14285715, 0.045454547, 0.045454547, 0.4785276, 0.46478873, 0.14583333, 0.53424656, 0.47244096, 0.5769231, 0.21052632, 0.0625, 0.63529414, 0.1904762, 0.2159091, 0.4722222, 0.22727273, 0.23728813]
