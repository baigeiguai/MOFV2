[2024-09-11 16:23:19,398][train.py][line:68][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0/', train_name='NewConv', model_path=None, learning_rate=0.0005, min_learning_rate=1e-06, start_scheduler_step=0, weight_decay=1e-06, momentum=0.99, batch_size=8192, class_num=230, epoch_num=200, model_save_path='/data/ylh/MyExps/MOFV2/checkpoints/NewConv', device='4,6', scheduler_T=None, num_workers=20, log_name='log/train//train_NewConv_2024_09_11_16:23:15.log')
[2024-09-11 16:23:19,399][train.py][line:69][INFO] ---------------model---------------
DataParallel(
  (module): NewConv(
    (conv): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(20, 32, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (2): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (3): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (4): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (5): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (6): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (7): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (8): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (10): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (12): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (14): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (16): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (18): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (cls): Linear(in_features=1024, out_features=230, bias=True)
  )
)
[2024-09-11 16:23:19,399][train.py][line:70][INFO] ---------------device---------------
cuda:4
[2024-09-11 16:23:19,400][train.py][line:71][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 1e-06
)
[2024-09-11 16:23:19,400][train.py][line:72][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-09-11 16:23:19,400][train.py][line:73][INFO] ---------------seed---------------
3407
[2024-09-11 16:23:19,403][train.py][line:85][INFO] ---------------epoch 1---------------
lr: [0.0005]
[2024-09-11 16:25:50,775][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.81873135731138
[2024-09-11 16:27:14,294][train.py][line:146][INFO] [testing]total_number: 142618,error: 4.379410316204202,total_acc: 0.03361427038908005
[2024-09-11 16:27:15,051][train.py][line:85][INFO] ---------------epoch 2---------------
lr: [0.0004999384415069868]
[2024-09-11 16:29:53,554][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.574140976215231
[2024-09-11 16:31:18,080][train.py][line:146][INFO] [testing]total_number: 142618,error: 3.9624757520083724,total_acc: 0.06614172458648682
[2024-09-11 16:31:18,370][train.py][line:85][INFO] ---------------epoch 3---------------
lr: [0.0004997845709043126]
[2024-09-11 16:33:58,302][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.532840293029259
[2024-09-11 16:35:27,849][train.py][line:146][INFO] [testing]total_number: 142618,error: 4.181265436369797,total_acc: 0.06614172458648682
[2024-09-11 16:35:27,904][train.py][line:85][INFO] ---------------epoch 4---------------
lr: [0.0004995692082490166]
[2024-09-11 16:37:56,058][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.4963077265640785
[2024-09-11 16:39:23,818][train.py][line:146][INFO] [testing]total_number: 142618,error: 5.438246809203049,total_acc: 0.06614172458648682
[2024-09-11 16:39:23,873][train.py][line:85][INFO] ---------------epoch 5---------------
lr: [0.0004992924066757998]
[2024-09-11 16:41:58,793][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.4066573586957207
[2024-09-11 16:43:25,760][train.py][line:146][INFO] [testing]total_number: 142618,error: 12.117781704869763,total_acc: 0.0011990071507170796
[2024-09-11 16:43:25,811][train.py][line:85][INFO] ---------------epoch 6---------------
lr: [0.0004989542344784963]
[2024-09-11 16:45:54,308][train.py][line:103][INFO] [training]total_num: 142618.0,error: 3.3799378214211298
[2024-09-11 16:47:40,180][train.py][line:146][INFO] [testing]total_number: 142618,error: 7.731112496606235,total_acc: 0.0011849836446344852
[2024-09-11 16:47:40,272][train.py][line:85][INFO] ---------------epoch 7---------------
lr: [0.0004985547750932208]
