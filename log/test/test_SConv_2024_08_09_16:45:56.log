[2024-08-09 16:46:16,412][test.py][line:34][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0', batch_size=128, model_path='checkpoints/SConv/SConv_epoch_65.pth', device='3', mode='test', top_k=5, parallel_model=False, test_name='SConv', num_workers=20, log_name='log/test/test_SConv_2024_08_09_16:45:56.log')
[2024-08-09 16:46:16,415][test.py][line:35][INFO] ---------------model---------------
SResTcn(
  (embed): Embedding(8500, 16)
  (conv): ModuleList(
    (0): SConvBlock(
      (resblock): ResBlock1D(
        (pre): Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (1): SConvBlock(
      (resblock): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (2): SConvBlock(
      (resblock): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (3): SConvBlock(
      (resblock): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): MaxPool1d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
    (4): SConvBlock(
      (resblock): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (5): SConvBlock(
      (resblock): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
    )
    (6): SConvBlock(
      (resblock): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
    )
    (7-8): 2 x SConvBlock(
      (resblock): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (9): SConvBlock(
      (resblock): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
    (10-12): 3 x SConvBlock(
      (resblock): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (pooling): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
    )
  )
  (linear): Linear(in_features=1024, out_features=230, bias=True)
)
[2024-08-09 16:46:16,419][test.py][line:36][INFO] ---------------device---------------
cuda:3
[2024-08-09 16:46:16,420][test.py][line:37][INFO] ---------------lossfn---------------
CrossEntropyLoss()
[2024-08-09 16:51:06,035][test.py][line:78][INFO] ---------------performance---------------
total_num:142729
error:4.820840
total_acc:0.41534656286239624
f1_score:0.2959668040275574
top5_acc:0.7631805539131165
head_acc:0.43798474814496996
medium_acc:0.3383972793515482
tail_add:0.2836148115112468

[2024-08-09 16:51:06,036][test.py][line:89][INFO] ---------------per_class_acc---------------
[0.40454817, 0.4223023, 0.013157895, 0.47559923, 0.4029353, 0.11111111, 0.19934237, 0.2215909, 0.4263373, 0.09836066, 0.29965898, 0.2699115, 0.21321236, 0.40430725, 0.35508168, 0.65217394, 0.078947365, 0.31471136, 0.702552, 0.24617068, 0.0625, 0.05263158, 0.2913386, 0.23529412, 0.0, 0.21052632, 0.1764706, 0.11111111, 0.279115, 0.12676056, 0.20652173, 0.1, 0.39278474, 0.16129032, 0.2, 0.2925072, 0.050847456, 0.22727273, 0.0, 0.18367347, 0.0, 0.36842105, 0.3149476, 0.1891892, 0.12779553, 0.18055555, 0.26666668, 0.054054055, 0.0, 0.2037037, 0.03846154, 0.2250423, 0.32394367, 0.0625, 0.119205296, 0.18793012, 0.12273642, 0.22881356, 0.15789473, 0.34963325, 0.6193061, 0.4501923, 0.24948025, 0.0, 0.36893204, 0.030303031, 0.0, 0.0, 0.3015873, 0.25340137, 0.2777778, 0.2883721, 0.12738854, 0.3216783, 0.06896552, 0.33474576, 0.09677419, 0.26365796, 0.11940298, 0.18897638, 0.0862069, 0.47733712, 0.25, 0.0625, 0.2962138, 0.3018018, 0.44598338, 0.47467363, 0.0, 0.25, 0.044444446, 0.34560326, 0.0, 0.17924528, 0.06382979, 0.3275862, 0.20833333, 0.54901963, 0.0, 0.0, 0.0, 0.0, 0.05882353, 0.3442623, 1.0, 0.0754717, 0.0, 0.2631579, 0.04347826, 0.27230048, 0.0, 0.0, 0.4028777, 0.2384, 0.0, 0.14285715, 0.21212122, 0.25531915, 0.25, 0.16071428, 0.3448276, 0.27826086, 0.5, 0.7446808, 0.6333333, 0.25, 0.04761905, 0.3846154, 0.37078652, 0.33739838, 0.6, 0.1, 0.04, 0.2857143, 0.08, 0.41304347, 0.10526316, 0.23287672, 0.24347825, 0.2638889, 0.26190478, 0.32234433, 0.32456142, 0.34536082, 0.3341969, 0.48184356, 0.42949757, 0.66936755, 0.33333334, 0.018518519, 0.0, 0.26708075, 0.09090909, 0.21465969, 0.27309236, 0.0, 0.22222222, 0.13461539, 0.2054054, 0.3984375, 0.4127907, 0.37931034, 0.4691358, 0.40816328, 0.43636364, 0.5623003, 0.4725877, 0.0, 0.2140845, 0.3631124, 0.1, 0.0, 0.30327868, 0.0625, 0.083333336, 0.38442212, 0.46666667, 0.33333334, 0.144, 0.15, 0.12, 0.4226804, 0.0, 0.14285715, 0.15789473, 0.104166664, 0.72727275, 0.0, 0.27272728, 0.14772727, 0.43939394, 0.5254237, 0.34210527, 0.3922652, 0.2, 0.67241377, 0.54761904, 0.8184931, 0.6567164, 0.3846154, 0.2, 0.25, 0.36363637, 0.421875, 0.7529138, 0.33802816, 0.15384616, 0.33333334, 0.2857143, 0.61290324, 0.51724136, 0.45833334, 0.21212122, 0.42857143, 0.13636364, 0.13636364, 0.77300614, 0.52112675, 0.27083334, 0.739726, 0.6614173, 0.6923077, 0.42105263, 0.5, 0.81764704, 0.5952381, 0.70454544, 0.45833334, 0.18181819, 0.42372882]
