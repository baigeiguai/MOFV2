[2024-10-27 20:33:56,577][train_con.py][line:74][INFO] ---------------args---------------
Namespace(data_path='./data/Pymatgen_Wrapped/0', train_name='Hope_Con', model_path=None, learning_rate=0.0005, min_learning_rate=1e-05, start_scheduler_step=10, weight_decay=0.0005, momentum=0.99, batch_size=128, class_num=230, epoch_num=200, model_save_path='/data/ylh/MyExps/MOFV2/checkpoints/Hope_Con', device='2', scheduler_T=None, num_workers=20, log_name='log/train//train_Hope_Con_2024_10_27_20:33:49.log')
[2024-10-27 20:33:56,579][train_con.py][line:75][INFO] ---------------model---------------
HopeV1_Con(
  (conv_module): ResTcn(
    (intensity_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (TCN): Sequential(
      (0): ResBlock1D(
        (pre): Conv1d(2, 32, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (2): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (4): ResBlock1D(
        (pre): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (6): ResBlock1D(
        (pre): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (8): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (9): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (10): ResBlock1D(
        (pre): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (11): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (12): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (13): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (14): ResBlock1D(
        (pre): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (15): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))
      (16): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (17): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (18): ResBlock1D(
        (pre): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (19): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (20): Dropout(p=0.25, inplace=False)
      (21): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (22): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (23): Dropout(p=0.25, inplace=False)
      (24): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (25): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (26): Dropout(p=0.25, inplace=False)
      (27): ResBlock1D(
        (pre): Identity()
        (conv): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): LeakyReLU(negative_slope=0.01)
      )
      (28): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))
      (29): Flatten(start_dim=1, end_dim=-1)
    )
  )
  (att): AttentionModule(
    (embed): Embedding(850, 15)
    (patch_conv): PatchConvModule(
      (conv): Sequential(
        (0): Conv2d(1, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (1): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
        (2): Conv2d(2, 4, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (3): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
        (4): Conv2d(4, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (5): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 1))
        (6): Conv2d(8, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)
      )
    )
    (att): TransformerEncoder(
      (positionEnbeding): PositionEmbedding()
      (encoder_layers): ModuleList(
        (0-7): 8 x EncoderLayer(
          (mha): MultiHeadAttention(
            (WQ): Linear(in_features=32, out_features=32, bias=True)
            (WK): Linear(in_features=32, out_features=32, bias=True)
            (WV): Linear(in_features=32, out_features=32, bias=True)
            (scaled_dot_product_attn): ScaledDotProductAttention()
            (linear): Linear(in_features=32, out_features=32, bias=True)
          )
          (dropout1): Dropout(p=0.25, inplace=False)
          (layernorm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (ffn): FeedForwardNetwork(
            (linear1): Linear(in_features=32, out_features=256, bias=True)
            (linear2): Linear(in_features=256, out_features=32, bias=True)
            (relu): LeakyReLU(negative_slope=0.01)
          )
          (dropout2): Dropout(p=0.25, inplace=False)
          (layernorm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
  )
  (cls_sp): Sequential(
    (0): Linear(in_features=1056, out_features=230, bias=True)
  )
  (cls_cs): Sequential(
    (0): Linear(in_features=1056, out_features=7, bias=True)
  )
  (cls_lt): Sequential(
    (0): Linear(in_features=1056, out_features=6, bias=True)
  )
)
[2024-10-27 20:33:56,579][train_con.py][line:76][INFO] ---------------device---------------
cuda:2
[2024-10-27 20:33:56,580][train_con.py][line:77][INFO] ---------------optimizer---------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.0005
)
[2024-10-27 20:33:56,580][train_con.py][line:78][INFO] ---------------seed---------------
3407
[2024-10-27 20:33:56,583][train_con.py][line:90][INFO] ---------------epoch 1---------------
lr: [0.0005]
[2024-10-27 20:56:31,486][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.38751926955361227,error_cls: 6.164975296213443,error_sc: 0.38751926955361227
[2024-10-27 21:03:59,057][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.39495275293236404,total_cls_acc: 0.0006941620376892388
[2024-10-27 21:03:59,926][train_con.py][line:90][INFO] ---------------epoch 2---------------
lr: [0.0005]
[2024-10-27 21:26:26,254][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.37154613784328433,error_cls: 3.001922512117909,error_sc: 0.3583281652633342
[2024-10-27 21:33:56,145][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.3804459097235734,total_cls_acc: 0.06604355573654175
[2024-10-27 21:33:56,516][train_con.py][line:90][INFO] ---------------epoch 3---------------
lr: [0.0005]
[2024-10-27 21:56:23,398][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.35444397200973243,error_cls: 2.4927732930737676,error_sc: 0.3328446828460233
[2024-10-27 22:03:50,220][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.377744727243257,total_cls_acc: 0.004228077828884125
[2024-10-27 22:03:50,629][train_con.py][line:90][INFO] ---------------epoch 4---------------
lr: [0.0005]
[2024-10-27 22:26:16,998][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.34214055685271916,error_cls: 2.1745912123276474,error_sc: 0.314235212537522
[2024-10-27 22:33:47,340][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.3773904177223885,total_cls_acc: 0.05725083872675896
[2024-10-27 22:33:47,710][train_con.py][line:90][INFO] ---------------epoch 5---------------
lr: [0.0005]
[2024-10-27 22:56:13,396][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.3370625767774199,error_cls: 2.009574618821876,error_sc: 0.3029296724307545
[2024-10-27 23:03:41,323][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.3020421341045065,total_cls_acc: 0.4019758999347687
[2024-10-27 23:03:41,691][train_con.py][line:90][INFO] ---------------epoch 6---------------
lr: [0.0005]
[2024-10-27 23:26:07,359][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.3366832143652725,error_cls: 1.8956036441814825,error_sc: 0.29671088829529146
[2024-10-27 23:33:42,318][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.31823708351698193,total_cls_acc: 0.2114880383014679
[2024-10-27 23:33:42,366][train_con.py][line:90][INFO] ---------------epoch 7---------------
lr: [0.0005]
[2024-10-27 23:56:11,581][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.33599423536470535,error_cls: 1.797072283864127,error_sc: 0.29080624695943325
[2024-10-28 00:03:40,025][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.3103299835447252,total_cls_acc: 0.34661123156547546
[2024-10-28 00:03:40,033][train_con.py][line:90][INFO] ---------------epoch 8---------------
lr: [0.0005]
[2024-10-28 00:26:06,702][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.33313468711478794,error_cls: 1.6905569406135377,error_sc: 0.2839017625883248
[2024-10-28 00:33:33,225][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.3345060101557381,total_cls_acc: 0.2096509486436844
[2024-10-28 00:33:33,233][train_con.py][line:90][INFO] ---------------epoch 9---------------
lr: [0.0005]
[2024-10-28 00:55:59,803][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.3316712964527778,error_cls: 1.60270575886822,error_sc: 0.2787115348845112
[2024-10-28 01:03:24,450][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.28738150187332545,total_cls_acc: 0.4924483597278595
[2024-10-28 01:03:24,839][train_con.py][line:90][INFO] ---------------epoch 10---------------
lr: [0.0005]
[2024-10-28 01:25:52,399][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.32995198813813287,error_cls: 1.5195441563360017,error_sc: 0.2738979089411823
[2024-10-28 01:33:20,361][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2901736366287363,total_cls_acc: 0.46331459283828735
[2024-10-28 01:33:20,367][train_con.py][line:90][INFO] ---------------epoch 11---------------
lr: [0.0005]
[2024-10-28 01:55:46,662][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.3297013503820788,error_cls: 1.460561562451834,error_sc: 0.270182393107831
[2024-10-28 02:03:16,551][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.3480767007014766,total_cls_acc: 0.0764629989862442
[2024-10-28 02:03:16,559][train_con.py][line:90][INFO] ---------------epoch 12---------------
lr: [0.0004999330217352866]
[2024-10-28 02:25:44,056][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.3270950095187592,error_cls: 1.3846673628558284,error_sc: 0.26554318175328023
[2024-10-28 02:33:14,642][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.287267005742059,total_cls_acc: 0.4664838910102844
[2024-10-28 02:33:15,017][train_con.py][line:90][INFO] ---------------epoch 13---------------
lr: [0.0004997656069723435]
[2024-10-28 02:55:41,567][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.3252122882875914,error_cls: 1.3217802159322927,error_sc: 0.2616015721474854
[2024-10-28 03:03:11,376][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.32489822687913383,total_cls_acc: 0.2821032404899597
[2024-10-28 03:03:11,383][train_con.py][line:90][INFO] ---------------epoch 14---------------
lr: [0.000499531294042919]
[2024-10-28 03:25:38,757][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.32337819665881945,error_cls: 1.2640143976131157,error_sc: 0.25798637786352907
[2024-10-28 03:33:06,717][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.31191916160695354,total_cls_acc: 0.41175025701522827
[2024-10-28 03:33:06,727][train_con.py][line:90][INFO] ---------------epoch 15---------------
lr: [0.0004992301470020729]
[2024-10-28 03:55:32,959][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.32075817748150576,error_cls: 1.2062592083834502,error_sc: 0.2541075597848568
[2024-10-28 04:03:00,643][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.44220551659337376,total_cls_acc: 0.052132271230220795
[2024-10-28 04:03:00,654][train_con.py][line:90][INFO] ---------------epoch 16---------------
lr: [0.0004988622481766419]
[2024-10-28 04:25:27,486][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.31790381397625567,error_cls: 1.1512676829136677,error_sc: 0.2503337635102532
[2024-10-28 04:32:54,879][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2529885766692228,total_cls_acc: 0.6410831809043884
[2024-10-28 04:32:55,263][train_con.py][line:90][INFO] ---------------epoch 17---------------
lr: [0.0004984276981427311]
[2024-10-28 04:55:21,568][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.31526706404752614,error_cls: 1.0997667946218916,error_sc: 0.2470496938908481
[2024-10-28 05:02:48,015][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.24308029429684622,total_cls_acc: 0.7066358923912048
[2024-10-28 05:02:48,393][train_con.py][line:90][INFO] ---------------epoch 18---------------
lr: [0.000497926615698217]
[2024-10-28 05:25:15,141][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.3126726156396472,error_cls: 1.0529800461474623,error_sc: 0.24390088038447957
[2024-10-28 05:32:44,663][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.27531506934970906,total_cls_acc: 0.5704889893531799
[2024-10-28 05:32:44,672][train_con.py][line:90][INFO] ---------------epoch 19---------------
lr: [0.0004973591378302678]
[2024-10-28 05:55:12,553][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.3107763102745841,error_cls: 1.020420034347431,error_sc: 0.24059175511288267
[2024-10-28 06:02:41,064][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.30260202178389445,total_cls_acc: 0.43729403614997864
[2024-10-28 06:02:41,071][train_con.py][line:90][INFO] ---------------epoch 20---------------
lr: [0.0004967254196778915]
[2024-10-28 06:25:07,375][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.30651991631250625,error_cls: 0.9670122597951644,error_sc: 0.23718647453843053
[2024-10-28 06:32:33,472][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.25514379046037594,total_cls_acc: 0.6357893347740173
[2024-10-28 06:32:33,480][train_con.py][line:90][INFO] ---------------epoch 21---------------
lr: [0.0004960256344895213]
[2024-10-28 06:55:00,546][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.30554734184319926,error_cls: 0.9429293526625782,error_sc: 0.23472712309692242
[2024-10-28 07:02:28,951][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2541627863747627,total_cls_acc: 0.6313719153404236
[2024-10-28 07:02:28,958][train_con.py][line:90][INFO] ---------------epoch 22---------------
lr: [0.0004952599735756512]
[2024-10-28 07:24:57,854][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.30230193391455523,error_cls: 0.9040461058572212,error_sc: 0.23170625704969508
[2024-10-28 07:32:25,620][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.31584660256382313,total_cls_acc: 0.42554235458374023
[2024-10-28 07:32:25,627][train_con.py][line:90][INFO] ---------------epoch 23---------------
lr: [0.0004944286462565302]
[2024-10-28 07:54:53,004][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.29688289707333193,error_cls: 0.8533034762293232,error_sc: 0.22811181851461887
[2024-10-28 08:02:19,212][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2938587441313235,total_cls_acc: 0.4431418180465698
[2024-10-28 08:02:19,220][train_con.py][line:90][INFO] ---------------epoch 24---------------
lr: [0.0004935318798049381]
[2024-10-28 08:24:46,443][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.29445205316833406,error_cls: 0.8258531318370917,error_sc: 0.2253999363000074
[2024-10-28 08:32:12,231][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2742116995859881,total_cls_acc: 0.5557292699813843
[2024-10-28 08:32:12,239][train_con.py][line:90][INFO] ---------------epoch 25---------------
lr: [0.0004925699193840478]
[2024-10-28 08:54:39,130][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.2942540875661659,error_cls: 0.809962755907079,error_sc: 0.22393018202054601
[2024-10-28 09:02:07,383][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.3616614040142684,total_cls_acc: 0.20708465576171875
[2024-10-28 09:02:07,390][train_con.py][line:90][INFO] ---------------epoch 26---------------
lr: [0.0004915430279804011]
[2024-10-28 09:24:33,480][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.28719604858912084,error_cls: 0.7549890095587843,error_sc: 0.2203684829079613
[2024-10-28 09:32:01,818][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2755921751689645,total_cls_acc: 0.5468524098396301
[2024-10-28 09:32:02,318][train_con.py][line:90][INFO] ---------------epoch 27---------------
lr: [0.0004904514863320079]
[2024-10-28 09:54:28,877][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.2856485135886345,error_cls: 0.7375965785588854,error_sc: 0.21811604672694163
[2024-10-28 10:01:53,321][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2341994750743175,total_cls_acc: 0.7182964086532593
[2024-10-28 10:01:53,702][train_con.py][line:90][INFO] ---------------epoch 28---------------
lr: [0.0004892955928515954]
[2024-10-28 10:24:20,307][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.28171288500396996,error_cls: 0.7046467350083532,error_sc: 0.21570586089702604
[2024-10-28 10:31:47,667][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.3988953264762367,total_cls_acc: 0.05332426354289055
[2024-10-28 10:31:47,674][train_con.py][line:90][INFO] ---------------epoch 29---------------
lr: [0.0004880756635450231]
[2024-10-28 10:54:13,340][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.2776409128239542,error_cls: 0.6754978180143192,error_sc: 0.21287350573656733
[2024-10-28 11:01:41,348][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2079367430281752,total_cls_acc: 0.8190410733222961
[2024-10-28 11:01:41,734][train_con.py][line:90][INFO] ---------------epoch 30---------------
lr: [0.0004867920319248896]
[2024-10-28 11:24:08,736][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.2753569439595636,error_cls: 0.6543379089635563,error_sc: 0.21108531720912332
[2024-10-28 11:31:38,534][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.34916923184876647,total_cls_acc: 0.18707315623760223
[2024-10-28 11:31:38,541][train_con.py][line:90][INFO] ---------------epoch 31---------------
lr: [0.0004854450489193513]
[2024-10-28 11:54:04,931][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.27038021569455106,error_cls: 0.6227361520201946,error_sc: 0.20819974622541268
[2024-10-28 12:01:33,885][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.34608169155858104,total_cls_acc: 0.24801918864250183
[2024-10-28 12:01:33,892][train_con.py][line:90][INFO] ---------------epoch 32---------------
lr: [0.0004840350827761827]
[2024-10-28 12:24:01,188][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.26640750311757994,error_cls: 0.596980779860648,error_sc: 0.20576979382254493
[2024-10-28 12:31:27,891][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2193026018424824,total_cls_acc: 0.729438066482544
[2024-10-28 12:31:27,898][train_con.py][line:90][INFO] ---------------epoch 33---------------
lr: [0.0004825625189620976]
[2024-10-28 12:53:53,981][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.2636139181631798,error_cls: 0.5749289631420463,error_sc: 0.20431582275042584
[2024-10-28 13:01:20,314][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.3501803910999353,total_cls_acc: 0.2333015501499176
[2024-10-28 13:01:20,321][train_con.py][line:90][INFO] ---------------epoch 34---------------
lr: [0.00048102776005736733]
[2024-10-28 13:23:47,528][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.2602079444678092,error_cls: 0.5527779326940281,error_sc: 0.20239471413821938
[2024-10-28 13:31:11,838][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.22115564113348546,total_cls_acc: 0.7735559344291687
[2024-10-28 13:31:11,847][train_con.py][line:90][INFO] ---------------epoch 35---------------
lr: [0.0004794312256457571]
[2024-10-28 13:53:38,155][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.25581473046657566,error_cls: 0.5265029450909903,error_sc: 0.20037256892644092
[2024-10-28 14:01:05,533][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.26050959407916324,total_cls_acc: 0.6456968784332275
[2024-10-28 14:01:05,540][train_con.py][line:90][INFO] ---------------epoch 36---------------
lr: [0.0004777733521998142]
[2024-10-28 14:23:32,777][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.249775134588938,error_cls: 0.4987253264954583,error_sc: 0.19696752250235042
[2024-10-28 14:30:58,709][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.2653502975778527,total_cls_acc: 0.6408868432044983
[2024-10-28 14:30:58,716][train_con.py][line:90][INFO] ---------------epoch 37---------------
lr: [0.00047605459296154077]
[2024-10-28 14:53:25,632][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.24933584101874953,error_cls: 0.49139417368115423,error_sc: 0.1962010818727797
[2024-10-28 15:00:53,539][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.1821730859469091,total_cls_acc: 0.8983718752861023
[2024-10-28 15:00:53,923][train_con.py][line:90][INFO] ---------------epoch 38---------------
lr: [0.00047427541781847944]
[2024-10-28 15:23:19,828][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.24311434902984586,error_cls: 0.46107469168561904,error_sc: 0.1936386873658016
[2024-10-28 15:30:47,087][train_con.py][line:161][INFO] [testing]total_number: 142618,sc_error: 0.22075410895224143,total_cls_acc: 0.7829656600952148
[2024-10-28 15:30:47,094][train_con.py][line:90][INFO] ---------------epoch 39---------------
lr: [0.00047243631317525]
[2024-10-28 15:53:12,535][train_con.py][line:118][INFO] [training]total_num: 142618.0,error: 0.24111114698854716,error_cls: 0.4470553901889415,error_sc: 0.19280323869579313
